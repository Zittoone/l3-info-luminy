pour les articles homonymes , voir arbre ( homonymie ) . vous pouvez partager vos connaissances en l ’ améliorant ( comment ? ) selon les recommandations des projets correspondants . un arbre de décision est un outil d&apos; aide à la décision représentant un ensemble de choix sous la forme graphique d&apos; un arbre . les différentes décisions possibles sont situées aux extrémités des branches ( les « feuilles » de l&apos; arbre ) , et sont atteints en fonction de décisions prises à chaque étape . l&apos; arbre de décision est un outil utilisé dans des domaines variés tels que la sécurité , la fouille de données , la médecine , etc. il a l&apos; avantage d&apos; être lisible et rapide à exécuter . il s&apos; agit de plus d&apos; une représentation calculable automatiquement par des algorithmes d&apos; apprentissage supervisé . les arbres de décision sont utilisés dans des domaines d&apos; aide à la décision ( par exemple l&apos; informatique décisionnelle ) ou l&apos; exploration de données . ils décrivent comment répartir une population d&apos; individus ( clients d&apos; une entreprise , utilisateurs d&apos; un réseau social , … ) en groupes homogènes selon un ensemble de variables discriminantes ( âge , temps passé sur un site web , catégorie socio-professionnelle , … ) et en fonction d&apos; un objectif fixé ( aussi appelé « variable d&apos; intérêt » ou « variable de sortie » ; par exemple : chiffre d&apos; affaires , probabilité de cliquer sur une publicité , … ) . par exemple , l&apos; arbre de décision ci-dessous ( tiré de l&apos; ouvrage de quilanr . quinlan : c4.5 : programs for machine learning , morgan kaufmann publishers inc . , 1993 . ) illustre le cas où l&apos; on cherche à prédire le comportement de sportifs ( la variable à prédire jouer prenant l&apos; une des deux valeurs « oui » ou « non » ) en fonction de données météorologiques ( ensoleillement , température , humidité ou vent ) , appelées variables prédictives . chaque nœud de l ’ arbre décrit la distribution de la variable jouer à prédire . dans le cas du premier nœud , la racine de l ’ arbre , nous constatons qu ’ il y a 14 observations dans notre fichier : 9 cas où une partie a eu lieu ( jouer = oui ) et 5 où aucune partie n&apos; a eu lieu ( jouer = non ) . ce premier nœud a plusieurs fils construits en utilisant la variable ensoleillement : le plus à gauche ( ensoleillement = soleil ) comporte 5 observations , le suivant ( ensoleillement = couvert ) en comporte 4 , et ainsi de suite . la suite de décisions continue jusqu&apos; à ce que , dans l&apos; idéal , les observations dans un nœud soient toutes « oui » ou toutes « non » . on dit alors que le nœud est homogène . le processus de décision s&apos; arrête aux feuilles de l ’ arbre . dans l&apos; arbre ci-dessus , toutes les feuilles sont homogènes , c&apos; est-à-dire que les variables prédictives utilisées permettent de prédire complètement ( sur ce fichier de données ) si une partie va avoir lieu ou non . ( notons qu&apos; il serait possible de construire l&apos; arbre selon un ordre différent des variables de météo , par exemple en considérant l&apos; humidité plutôt que l&apos; ensoleillement à la première décision ) . l&apos; arbre se lit intuitivement de haut en bas , ce qui se traduit en termes de règles logiques sans perte d ’ informations : par exemple , la feuille la plus à gauche se lit : « si ensoleillement = soleil et humidité &lt; 77,5 % alors jouer = oui » . article détaillé : arbre de décision ( apprentissage ) . un avantage majeur des arbres de décision est qu&apos; ils peuvent être calculés automatiquement à partir de bases de données par des algorithmes d ’ apprentissage supervisé . ces algorithmes sélectionnent automatiquement les variables discriminantes à partir de données non-structurées et potentiellement volumineuses . ils peuvent ainsi permettre d&apos; extraire des règles logiques de cause à effet ( des déterminismes ) qui n&apos; apparaissaient pas initialement dans les données brutes . certains formalismes alternatifs proposent d&apos; ajouter des règles de transition plus complexes dans chaque nœud . ces formalismes sont alors utiles non pas pour l ’ apprentissage automatique mais pour la construction incrémentale de bases de connaissances , quand on dispose d&apos; un expert dans le domaine d&apos; application visé . on peut citer les règles dé-roulées ( ripple down rules ) template : article , les edag ( exception directed acyclic graphs ) template : article , ou les nœuds de situation ( nos ) du logiciel libre edinos . par ailleurs , un autre usage en apprentissage automatique consiste à construire non pas un arbre mais une forêt d&apos; arbres de décision . une décision est alors prise en faisant « voter » l&apos; ensemble des arbres et en choisissant la réponse majoritaire ( pour un choix discret ) ou la moyenne des réponses ( pour une variable continue ) .
