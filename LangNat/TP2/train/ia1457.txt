cette liste indique les principaux projets et réalisations marquants dans le domaine de l ’ intelligence artificielle . la quasi-totalité de ces travaux ont été accomplis aux états-unis , et il est à noter que nombre d ’ entre eux ont été financés par l ’ armée américaine . l ’ un des principaux financeurs de ces travaux fut la darpa ( defense advanced research projects agency ) , célèbre pour avoir initié le réseau arpanet , qui a donné naissance à internet . la liste est organisée par ordre chronologique . article détaillé : logic theorist . ce programme informatique est considéré comme le premier relevant de l ’ intelligence artificielle . il a été développé par allen newell et herbert simon , avec l ’ assistance de cliff shaw . logic theorist est un programme de démonstration de théorèmes , fondé sur une recherche sélective . une hypothèse de base donnée , peut subir toute une gamme de manipulations élémentaires conformes aux lois de la logique . le résultat obtenu peut passer à son tour par une série de manipulations . la répétition de cette procédure crée une structure arborescente , sous forme « d ’ arbre de recherche » . l ’ exploration de celui-ci permet d ’ aboutir au résultat recherché , après un nombre indéfini d ’ opérations . le problème à surmonter est de trouver le chemin qui mène de l ’ hypothèse de base au résultat recherché . logic theorist comportait une liste de règles empiriques appropriées , les heuristiques , qui permettaient de sélectionner laquelle des branches de l ’ arbre de recherche était la plus susceptible de mener au but . une fois programmé sur une machine de la rand , logic theorist démontra 38 des 52 premiers théorèmes du 2e chapitre des « principia mathematica » de bertrand russell et alfred north whitehead . le théorème 2.85 faisait même l ’ objet d ’ une démonstration plus élégante que celle des auteurs , au grand contentement de russell . pour marquer la portée de ce dernier résultat , allen newell et herbert simon décidèrent de publier cette démonstration dans le « journal of symbolic logic » , en faisant cosigner cette publication par logic theorist . lors de la conférence de dartmouth de 1956 , considérée comme la rencontre fondatrice de l ’ intelligence artificielle en tant que discipline scientifique , logic theorist fut le seul programme opérationnel présenté . il est par ailleurs considéré comme le lointain précurseur des logiciels de traitement formel des équations . article détaillé : information processing language . dans le cadre de la réalisation de logic theorist , le résultat le plus important pour le développement de l ’ intelligence artificielle , a été l ’ invention d ’ un langage de programmation spécifique nommé ipl . ce langage fut le premier à employer la technique de programmation dite de traitement des listes . les auteurs de logic theorist pensaient que les langages existant à l ’ époque , comme le fortran , n ’ étaient pas appropriés pour un tel projet . en effet , ceux-ci exigeaient que les ensembles de nombres et de symboles manipulés soient définis au préalable . au contraire , les auteurs de logic theorist estimaient que la pensée est fondée d ’ une part sur la création , la modification et la destruction de structures de symboles en interaction , et d ’ autre part sur le caractère associatif de la mémoire humaine . la technique de traitement de liste est une tentative pour bénéficier de ces deux caractéristiques . les idées d ’ allen newell et de herbert simon inspirèrent john mccarthy lorsque celui-ci inventa son propre langage d ’ ia : le lisp . article détaillé : general problem solver . partant du constat que les humains ne raisonnent pas comme logic theorist , allen newell et herbert simon s ’ inspirèrent d ’ expériences de psychologie sur les méthodes de résolution de problèmes par des humains , pour créer gps . celui-ci avait l ’ originalité d ’ être fondé sur une organisation et un ensemble de règles heuristiques ne renfermant aucune référence à une tâche particulière , d ’ où le qualificatif de système général de résolution de problèmes . gps employait l ’ analyse fins / moyens , qui fonctionnait comme un principe de rétroaction , détectant puis réduisant les différences entre un état de faits et le but recherché . cette méthode de résolution était couplée à la capacité à décomposer un problème en plusieurs sous-problèmes . gps fut employé pour résoudre des casse-têtes , des intégrations symboliques , et des décryptages de codes secrets . article détaillé : sad sam . créé par robert k. lindsay , sad sam provient de l ’ étude de l ’ apprentissage verbal . ce programme était capable de définir des liens de parenté entre des personnes citées dans des phrases formulées en langage courant , en construisant peu à peu l ’ équivalent d ’ un arbre généalogique interne . sad sam était donc capable de relier une nouvelle information à d ’ autres faits déjà enregistrés , pour en tirer des conclusions qui n ’ avaient pas été apprises . à ce titre , certains chercheurs ont estimé que sad sam présentait les premières ébauches de compréhension au sens humain du terme . article détaillé : lisp . en s ’ inspirant du langage ipl , john mccarthy inventa au massachusetts institute of technology ( mit ) le lisp , qui devint le langage universel de l ’ ia . en effet , les qualités du lisp en matière de gestion de mémoire et de représentation lui permirent de supplanter ses concurrents comme l ’ ipl ou le comit . toutefois , dans les conditions de l ’ informatique des années 1960 , où la taille des mémoires était faible , l ’ encombrement en espace mémoire des langages de traitements de listes a freiné leur adoption . de plus , les premiers lisps étaient interprétés et non compilés , donc trop lents . le lisp ne devint attractif qu ’ à partir de 1970 , lorsque la compilation efficace de programmes lisp devint possible ( voir maclisp ) . article détaillé : perceptron. une couche de cellules d ’ association , constituant la couche de neurones formels proprement dits , selon la définition de mcculloch et pitts. une couche de cellules de décisions , qui représentent la réponse de sortie du perceptron . grâce à une procédure inventée par frank rosenblatt , l ’ apprentissage du perceptron se fait par correction d ’ erreur , en modifiant les coefficients de poids des signaux entre les cellules . en 1969 , marvin lee minsky et seymour papert publièrent un ouvrage intitulé perceptrons , qui démontrait certaines limitations de ces modèles . en particulier , le perceptron ne peut pas effectuer l ’ opération binaire de parité ( ou exclusif ou xor ) . l ’ autorité de ces auteurs , ainsi que le décès accidentel de frank rosenblatt , entraîna un quasi-arrêt des recherches dans ce domaine pendant près de 15 ans , jusqu ’ à l ’ apparition des réseau de neurones multicouche ( on parle aussi parfois de perceptron multicouche ) . les demandes d ’ identification , renforcées par le terrorisme , assurent un marché immense à cette technique . article détaillé : geometry theorem prover . ce programme a été financé par ibm et conçu par herbert gelernter . gtp fonctionnait de manière rétrograde à partir du théorème à démontrer , pour remonter par des raisonnements intermédiaires à des théorèmes ou des axiomes connus . lors de cette phase , le programme s ’ aidait d ’ une figure géométrique décrite à partir des coordonnées de ses points . pour élaguer l ’ arbre de recherche , gtp cherchait uniquement à démontrer les propriétés qui semblaient vérifiées sur le schéma , comme le font inconsciemment les humains . gtp était ainsi capable de faire des démonstrations nécessitant jusqu ’ à 10 étapes . plus important , il fut le premier programme capable de faire référence à un modèle , dans la mesure où la figure géométrique était utilisée comme une représentation interne . à la suite de la notoriété de gtp et d ’ autres programmes d ’ ia , ibm décida d ’ arrêter ces études d ’ une part en raison de la pression des actionnaires et du service marketing , qui s ’ alarmaient d ’ une image trop inquiétante des ordinateurs dans l ’ esprit du grand public . gtp garde une belle performance à son actif : il découvrit la première démonstration géométrique considérée comme plus élégante que celles des manuels scolaires de son époque . au problème « dans un triangle , l ’ angle b est égal à l ’ angle c. démontrez que le côté ab est égal au côté bc » , il apporta une démonstration non pas en considérant les deux sous-triangles découpés par la hauteur , mais par : « considérons les triangles abc et acb : ces deux triangles sont semblables et possèdent des côtés correspondants bc et cb égaux . ils sont donc égaux et ab est en conséquence égal à bc » . la démonstration a surpris par son approche non intuitive . article détaillé : symbolic automatic integrator . james slagle appliqua la méthodologie de logic theorist au domaine de l ’ intégration symbolique , en la transposant ainsi de la logique à l ’ algèbre , grâce à la mise au point de procédures d ’ exploration des arbres et / ou . confronté à des sujets d ’ examens posés aux étudiants du mit de 1re année , saint parvint à résoudre 84 problèmes sur 86 . ce programme a été perfectionné par joel moses en 1966 sous le nom de sin ( symbolic intégration ) , avant de donner naissance en 1969 à macsyma , qui a inspiré nombre de logiciels de traitement formel des équations aujourd ’ hui employés ( dont un descendant en ligne droite toujours en développement : maxima , ou encore mathematica ) . article détaillé : analogy . tom evans a créé ce programme en se fondant sur l ’ idée que le cerveau humain , devant une situation donnée , ne raisonne pas selon les voies de la logique , mais en essayant de trouver des ressemblances avec des problèmes déjà rencontrés . il a tenté de simuler l ’ aptitude à chercher des ressemblances avec ce logiciel capable de trouver des analogies entre des figures géométriques employées dans les tests d ’ intelligence . article détaillé : student . daniel bobrow a inventé ce programme , capable de faire une analyse syntaxique de textes simples , pour résoudre des problèmes algébriques du type « trouvez l ’ âge du capitaine » . ce programme de bertram raphael pouvait interpréter des dialogues simples , en cherchant des analogies avec des modèles de phrases . cette technique lui permettait de déduire des relations entre les personnes ou les objets cités dans ces phrases , en posant des questions à un opérateur . toutefois , les capacités de sir , comme celles de student étaient très limitées . les informations traitées concernaient un domaine très restreint , et les programmes butaient rapidement sur des ambigüités . article détaillé : shakey le robot . créé dans le laboratoire du stanford rechearch institute , shakey fut le premier robot ayant fait l ’ objet de publicité dans le grand public , à la suite d ’ un reportage très sensationnaliste de la revue life , qui l ’ avait baptisé la première personne électronique . shakey était également censé pouvoir circuler sur la lune pendant plusieurs mois sans recevoir une seule directive de la terre ! shakey était un cube monté sur roues , équipé d ’ un bras , d ’ une caméra vidéo , d ’ un télémètre et d ’ antennes de liaison radio . il se déplaçait dans un micromonde constitué de 7 pièces reliées par 8 portes , contenant des boîtes carrées . celles-ci étaient contournées , déplacées ou empilées en fonction des instructions que le robot recevait par un clavier . shakey avait une procédure de contrôle nommée strips , qui était un perfectionnement du general problem solver , et qui constituait sa principale innovation . le projet shakey avait pour objectif de créer un robot capable d ’ enchaîner une série d ’ actions : circuler dans une pièce pour trouver un bloc , le déplacer au sommet d ’ une plate-forme après avoir poussé un plan incliné contre elle , et ainsi de suite . en fait , shakey devint seulement capable de réaliser ces actions de façon indépendante , avec une forte probabilité d ’ échec . constatant que les objectifs du projet étaient hors de portée , la darpa mit fin au financement de ces travaux . ce langage de programmation fut inventé par carl hewitt à partir de lisp , selon une approche antagoniste du gps et de ses méthodes de résolution de problèmes fondées sur la logique et les procédures uniformes de démonstration de théorèmes . planner permettait en quelques instructions de fixer des buts à un programme ( chercher un cube rouge placé sous une pyramide ) , des plans et des assertions de façon automatique , sans avoir besoin de programmer des itérations et des marches arrières comme avec lisp . mais planner présentait l ’ inconvénient de ne pas faire de distinction entre les connaissances contenues dans ces procédures , et l ’ exploitation de ces connaissances par ces mêmes procédures . les programmes étaient donc un mélange inextricable de connaissances et de procédures . ce manque de structuration a été critiqué et a conduit à l ’ abandon des langages de type planner . marvin lee minsky estime toutefois que l ’ intelligence naturelle est organisée selon des principes similaires à planner , avec des agents indépendants hiérarchisés , selon sa théorie de la société de l ’ esprit . article détaillé : shrdlu . le nom de shrdlu est devenu un mythe de l ’ intelligence artificielle . programmé avec le langage planner , ce logiciel était la modélisation d ’ un micro-monde de blocs et de pyramides de couleurs diverses , avec une boîte pour les ranger . un bras virtuel permettait à un utilisateur de manipuler ces objets . l ’ opérateur pouvait donner des ordres et poser des questions , alors que shrdlu répondait en décrivant l ’ emplacement des objets , et les motifs des manipulations effectuées . shrdlu affichait également sur un écran une image de son micro-monde . terry winograd avait nommé son programme en référence au magazine mad , qui l ’ employait pour désigner des monstres ( etaoin shrdlu est la configuration de la première ligne d&apos; une linotype anglo-américaine , pour une française : « élaoin sdrètu » ; il ne s&apos; agit pas des lettres les plus employées en anglais , comme cela est parfois indiqué ) . le fait que l ’ utilisateur et shrdlu échangeaient des informations constructives , et que ce dernier pouvait expliciter ses motivations , fit une forte impression . les partisans des micro-mondes espéraient pouvoir enrichir et complexifier progressivement les mondes simulés pour les rapprocher de la réalité , ou bien fusionner plusieurs micro-mondes pour les étendre . cette approche fut un échec , car il est vite apparu qu ’ il n ’ est pas possible d ’ aller vers un monde plus proche du réel sans prise en compte du « sens commun » dans le programme . eugène charniak prit pour exemple en 1972 le cas d ’ une tirelire-cochonnet pour enfants . un programme de type micro-monde ne peut pas se contenter d ’ une définition tirée d ’ un dictionnaire . il faut avoir une description de la taille , de la forme , des couleurs et du poids de l ’ objet , tout en sachant que ces paramètres peuvent fortement varier . la notion d ’ argent implique de définir ce que sont l ’ économie et l ’ épargne . l ’ utilisation de cet objet simple se révèle complexe à décrire : mettre de l ’ argent , secouer le cochonnet pour en interpréter le bruit , retirer l ’ argent en mettant le cochonnet à l ’ envers et en employant un couteau , voire utiliser le cochonnet comme une figurine animée . la complexité du savoir à mettre en œuvre est très éloignée de la simplification propre aux micro-mondes . article détaillé : prolog . le langage « programmation en logique » est un moteur d ’ inférence conçu initialement par a. colmerauer et p. roussel pour l ’ interprétation du langage naturel , mais il est couramment utilisé pour des problèmes d ’ intelligence artificielle . prolog est un langage déclaratif , cela signifie que plutôt que d ’ être constitué de la solution à un problème , un programme consiste en une base de faits d ’ une part , et d ’ un ensemble de relations logiques d ’ autre part . pour exécuter le programme , il faut poser une question , et prolog donne la réponse calculée en appliquant les règles sur la base de faits . prolog s ’ adaptait si bien à la réalisation d ’ applications de combinatoires telles que celles requises par les agences de voyage , par exemple , qu ’ il fit dire à philippe kahn : « qu ’ on ne parle plus désormais d ’ intelligence artificielle ! c ’ était un nom du passé pour un domaine de recherche . nous sommes aujourd ’ hui à l ’ époque des réalisations , et on va réaliser maintenant des applications professionnelles programmées en prolog comme on en programmait hier en cobol » . l ’ avenir lui donna tort sur le court terme .
