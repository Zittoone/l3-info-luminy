ne pas confondre avec la méthode de nelder-mead qui s&apos; applique aux problèmes d&apos; optimisation non linéaires . l&apos; algorithme du simplexe est un algorithme de résolution des problèmes d&apos; optimisation linéaire . il a été introduit par george dantzig à partir de 1947 . c&apos; est probablement le premier algorithme permettant de minimiser une fonction sur un ensemble défini par des inégalitéstemplate : citation étrangère george dantzig ( 1990 ) . . de ce fait , il a beaucoup contribué au démarrage de l&apos; optimisation numérique . l&apos; algorithme du simplexe a longtemps été la méthode la plus utilisée pour résoudre les problèmes d&apos; optimisation linéaire . depuis les années 1985-90 , il est concurrencé par les méthodes de points intérieurs , mais garde une place de choix dans certaines circonstances ( en particulier si l&apos; on a une idée des contraintes d&apos; inégalité actives en la solution ) . le nom de l&apos; algorithme est dérivé de la notion de simplexe et a été suggéré par motzkinmurty ( 1983 ) , commentaire 2.2 . . en réalité , l&apos; algorithme n&apos; utilise pas de simplexes , mais certaines interprétations de l&apos; ensemble admissible du problème renvoient au concept de simplexe . connaissances supposées : l&apos; algèbre linéaire , le calcul différentiel , le vocabulaire de l&apos; optimisation mathématique. x \ in { \ mathcal a } _ p. \ end { array } \ right . l&apos; ensemble admissible { \ mathcal a } _ p peut être défini de manières variées . \ { x \ in \ r ^ n : ax \ leqslant b , ~ -ax \ leqslant-b , ~ -x \ leqslant0 \ } . où x a été décomposé en u-v avec u \ geqslant0 et v \ geqslant0 et les composantes de s sont appelées des variables d&apos; écart. x \ geqslant0 . \ end { array } \ right . { \ mathcal a } _ p : = \ { x \ in \ r ^ n : ax = b , ~ x \ geqslant0 \ } . c&apos; est-à-dire que ses lignes sont linéairement indépendantes . on peut montrer que lorsque le problème ( p _ l ) a une solution , il a une solution sur un sommet du polyèdre convexe { \ mathcal a } _ p. on sait comment calculer tous ces sommets , qui sont en nombre fini , si bien que le problème de résoudre ( p _ l ) pourrait être de sélectionner le sommet qui donne à la fonction à minimiser sa plus petite valeur . cependant , le nombre fini de sommets est en général très grand et dépend souvent exponentiellement des dimensions n et m du problème , si bien que cette approche ne pourrait être utilisée que pour résoudre des problèmes de petite dimension . l&apos; algorithme du simplexe va rechercher une solution parmi les sommets de { \ mathcal a } _ p , mais en n&apos; en calculant qu&apos; une partie d&apos; entre eux , en éliminant séquentiellement les sommets donnant à la fonction-coût une valeur supérieure à celle obtenue à l&apos; itéré courant . l&apos; algorithme du simplexe est géométriquement très simple : chaque itération consiste à passer d&apos; un sommet ( face de dimension 0 ) du polyèdre convexe { \ mathcal a } _ p à un sommet adjacent en suivant une arête ( face de dimension 1 ) particulière de ce polyèdre , de manière à faire décroître la fonction-coût . s&apos; il n&apos; y a pas de sommet le long de l&apos; arête sélectionnée ( parce que cette arête a une longueur infinie ) , le problème sera non borné ( la valeur minimale de la fonction-coût sera - \ infty ) . il est bien de garder cette idée générale à l&apos; esprit car la description algébrique d&apos; une itération est relativement longue et doit prendre en compte quelques cas particuliers ( problème non borné et pas nul ) qui distraient . i ^ 0 ( x ) : = \ { i : x _ i = 0 \ } . x _ b = a _ { \ bullet b } ^ { -1 } ( b - a _ { \ bullet n } x _ n ) . c ^ \ top x = c ^ \ top _ b a _ { \ bullet b } ^ { -1 } ( b - a _ { \ bullet n } x _ n ) + c ^ \ top _ n x _ n. r = c _ n - a ^ \ top _ n a _ { \ bullet b } ^ { - \ top } c _ b. dans l&apos; algorithme du simplexe , ce coût réduit sert , d&apos; une part , à détecter l&apos; optimalité éventuelle de l&apos; itéré courant \ hat { x } et , d&apos; autre part , à sélectionner une arête de { \ mathcal a } _ p le long de laquelle la fonction-coût décroît lorsque \ hat { x } n&apos; est pas optimal . proposition — un sommet \ hat { x } de { \ mathcal a } _ p est solution du problème ( p _ l ) si , et seulement si , il existe une base d&apos; indices b \ subset &#91; \ ! &#91; 1 , n &#93; \ ! &#93; associée à \ hat { x } telle que le coût réduit r \ geqslant0. x \ geqslant0 . \ end { array } \ right. d _ n = e ^ j _ n. d _ b = - a _ { \ bullet b } ^ { -1 } a _ { \ bullet n } e ^ j _ n. c ^ { \ top } d = r _ j &lt; 0 . si r a plusieurs composantes strictement négatives , il semble donc raisonnable de choisir l&apos; indice j parmi ceux donnant la composante de r la plus négative . c&apos; est ce que l&apos; on appelle la règle du coût réduit minimal . cette règle ne garantit cependant pas l&apos; efficacité globale de l&apos; algorithme qui est principalement liée au nombre total d&apos; itérations , c&apos; est-à-dire au nombre de sommets visités ( aspect global ) , ce qui ne peut se déduire d&apos; un calcul de dérivée ( aspect local ) . d&apos; autres règles existent ( comme celles introduites par les règles d&apos; anti-cyclage décrites à la section règles d&apos; anti-cyclage ) et les algorithmes du simplexe diffèrent en particulier par l&apos; heuristique adoptée à cette étape . il est intéressant d&apos; observer que le déplacement porté par la direction d se fait le long d&apos; une arête de { \ mathcal a } _ p. proposition — soient d défini comme ci-dessus et d : = \ { \ hat { x } + \ alpha d \ in { \ mathcal a } _ p : \ alpha \ geqslant 0 \ } . alors soit d est réduit au sommet \ { \ hat { x } \ } , soit d est une arête de { \ mathcal a } _ p. \ hat { \ alpha } = \ min \ left \ { - \ frac { \ hat { x } _ i } { d _ i } : i \ in b , ~ d _ i &lt; 0 \ right \ } . b _ + = \ left ( b \ cup \ { j \ } \ right ) \ setminus \ { k \ } . proposition — l&apos; ensemble b _ + est une base d&apos; indices . l&apos; opération de mise à jour de la base d&apos; indices b en b _ + , qui consiste à lui adjoindre l&apos; indice j et à lui ôter l&apos; indice k , est parfois appelée pivotage et la règle déterminant le choix des indices j et k est alors appelée règle de pivotage . progrès ou stagnationdeux situations peuvent maintenant se présenter . nous énonçons ci-dessous quelques règles d&apos; anti-cyclage et renvoyons le lecteur aux articles qui les introduisent pour une démonstration de leur propriété d&apos; anti-cyclage . ces articles sont souvent difficiles à comprendre , si l&apos; on n&apos; est pas familier avec le jargon développé par les spécialistes de l&apos; algorithme du simplexe , en particulier avec la description de l&apos; algorithme sous forme de tableau . la règle de bland ( en ) catégorie : article contenant un appel à traduction en anglaisr . g. bland ( 1977 ) , template : langue , template : langue , 2 , 103 – 107. consiste à faire entrer dans la base b _ + le plus petit indice j \ in n tel que le coût réduit r _ j &lt; 0 ( voir ci-dessus ) et à en faire sortir le plus petit indice k \ in \ operatorname { arg \ , min } \ { - \ hat { x } _ i / d _ i : i \ in b , d _ i &lt; 0 \ } ( voir ci-dessus ) . on peut résumer l&apos; algorithme décrit ci-dessus comme suit . algorithme du simplexe révisé — on suppose au départ que l&apos; on dispose d&apos; un sommet \ hat { x } de { \ mathcal a } _ p et d&apos; une base d&apos; indices associée b. une itération calcule un nouveau sommet \ hat { x } _ + et une nouvelle base d&apos; indices b _ + , à moins qu&apos; il ne soit observé que \ hat { x } est solution ou que le problème est non borné . on a le résultat de convergence finie suivant . convergence de l&apos; algorithme du simplexe révisé — si le problème d&apos; optimisation linéaire , écrit sous la forme standard ( p _ l ) , est réalisable ( c&apos; est-à-dire { \ mathcal a } _ p \ ne \ varnothing ) , l&apos; algorithme du simplexe révisé décrit ci-dessus termine après un nombre fini d&apos; étapes , soit en déterminant que le problème ( p _ l ) est non borné , soit en en trouvant une solution-sommet . pour utiliser l&apos; algorithme du simplexe , il faut disposer d&apos; un itéré initial qui est un sommet de l&apos; ensemble admissible { \ mathcal a } _ p : = \ { x \ in \ r ^ n : ax = b , ~ x \ geqslant0 \ } . nous présentons dans cette section plusieurs manières de faire face à cette exigence . comme son nom l&apos; indique , la technique des deux phases décompose la résolution d&apos; un problème d&apos; optimisation linéaire en deux étapes . la phase / étape i consiste à résoudre un problème d&apos; optimisation linéaire auxiliaire , dont on connait un sommet , par l&apos; algorithme du simplexe . la solution de ce problème auxiliaire fournit un sommet du problème ( p _ l ) ( si { \ mathcal a } _ p \ ne \ varnothing ) ou indique que ce problème n&apos; a pas de point admissible . dans la phase ii , on résout le problème ( p _ l ) par l&apos; algorithme du simplexe , à partir du sommet obtenu dans la première phase . \ end { array } \ right. où d est la matrice diagonale définie par d _ { ii } = 1 si b _ i \ geqslant 0 et d _ { ii } = -1 sinon . on peut utiliser pour cela l&apos; algorithme du simplexe , démarrant en ( 0 , d b ) , qui est un sommet de son ensemble admissibleproposition — le point ( 0 , d b ) est un sommet de l&apos; ensemble admissible du problème ci-dessus , lequel a toujours une solution . si ce problème est résolu par l&apos; algorithme du simplexe en partant de ce point , il obtient pour solution un point ( \ hat { x } , \ hat { z } ) . si \ hat { z } \ ne0 , le problème ( p _ l ) n&apos; est pas réalisable . si \ hat { z } = 0 , \ hat { x } est un sommet de l&apos; ensemble admissible de ( p _ l ) . \ end { array } \ right. x \ geqslant 0 , \ quad z \ geqslant 0 . \ end { array } \ right . ce dernier problème est équivalent à ( p _ l ) . dès lors , selon la théorie de la pénalisation exacte , si m est supérieur à la norme \ ell _ \ infty ( norme duale de la norme \ ell _ 1 pour le produit scalaire euclidien ) de tout multiplicateur optimal associé à la contrainte z = 0 dans ce dernier problème , et si { \ mathcal a } _ p \ ne \ varnothing , alors toute solution ( \ hat { x } , \ hat { z } ) du problème ( p _ { l , m } ) sera telle que \ hat { z } = 0 et donc \ hat { x } sera solution de ( p _ l ) . en termes géométriques , l&apos; ensemble des inégalités linéaires définit un polytope dans l&apos; espace à n dimensions ( polygone en 2 dimensions et polyèdre en 3 dimensions ) et il s&apos; agit de trouver le sommet optimal pour la fonction de coût donnée . en effet , la fonction que l&apos; on cherche à minimiser étant linéaire sur le polytope , elle y est en particulier concave . or une fonction concave et minorée sur un polytope admet un minimum en un des sommets du polytope . la recherche d&apos; un point de minimum peut donc se restreindre aux sommets du polytope ( qui peuvent être très nombreux néanmoins ) . l&apos; idée de l&apos; algorithme consiste à partir d&apos; un sommet quelconque du polytope et , à chaque itération , d&apos; aller à un sommet adjacent s&apos; il est possible d&apos; en trouver un meilleur pour la fonction objectif . s&apos; il n&apos; y en a pas , l&apos; algorithme s&apos; arrête en concluant que le sommet courant est optimal . en général , il y a plusieurs sommets adjacents au sommet courant qui sont meilleurs pour l&apos; objectif . il faut en sélectionner un seul , la règle de sélection est appelée règle de pivotage. n arêtes arrivent à i. calculer la matrice ai-1 . pour k = 1 à n , regarder le signe de φ.colk &#91; ai-1 &#93; . si ce signe est négatif ou nul pour tout k , terminer. φ a son minimum en ce sommet i , sous les contraintes a x ≤ b. si ce signe est strictement positif pour un k , soit u = colk &#91; ai-1 &#93; et aller au point suivant . chercher le sommet le plus proche sur la demi-droite xi + r * + u. pour tout h ∈ { 1 , … , f } \ i , quand ahu ≠ 0 , calculer \ lambda _ h = \ frac { b _ h-a _ h x _ i } { a _ h u } \ in \ mathbb { r } . s&apos; il y a un h avec λh &gt; 0 , prendre le plus petit de ces λh &gt; 0 . assigner { h } ∪ i \ { k } à i et aller au point précédent . sinon terminer . cette arête du polytope est infinie ; en la suivant on trouve \ min _ { x \ in \ mathbb { r } ^ n , \ , ax \ leq b } \ ; \ varphi ( x ) = - \ infty . il a été montré pour les principales règles de pivotage employées que l&apos; algorithme du simplexe pouvait prendre un temps de calcul exponentiel . en particulier , on ne sait pas s&apos; il existe une règle de pivotage qui assurerait que l&apos; algorithme se termine après un nombre polynomial d&apos; étapes. où \ nu est le plus petit nombre d&apos; arêtes reliées à un même sommet du polytope parcouru par le simplexe et n est le nombre de sommets . on remarquera que \ nu est minoré par la dimension de l&apos; espace dans lequel vit le polytope . néanmoins , l&apos; algorithme du simplexe est très efficace en pratique et il est implémenté dans tous les solveurs d&apos; optimisation linéaire . une analyse un peu différente , l&apos; analyse lisse permet d&apos; expliquer l&apos; efficacité du simplexe en pratique , en calculant des performances sur des entrées légèrement perturbées ( spielman et teng 2004 ) . on trouve d&apos; autres algorithmes de résolution de problèmes d&apos; optimisation linéaire : l&apos; algorithme en croix ( en ) catégorie : article contenant un appel à traduction en anglais , la méthode du gradient projeté , la méthode du lagrangien augmenté , la méthode de l&apos; ellipsoïde , les méthodes affines , les méthodes de points intérieurs , etc. l&apos; algorithme du simplexe est le plus souvent attribué à george dantzig qui l&apos; a découvert en 1947 . des techniques similaires avaient été découvertes par d&apos; autres mathématiciens précédemment , mais sans parvenir à attirer l&apos; attentiontemplate : article . . ( en ) simplex algorithm . illustration détaillée de l&apos; exécution de l&apos; algorithme ( version « tableau » ) . &#91; pdf &#93; exemple de l&apos; algorithme du simplexe . l ’ algorithme du simplexe appliqué de manière très didactique à un exemple ( version « tableau » ) . phpsimplex : outil en ligne pour résoudre les problèmes d&apos; optimisation linéaire développé par daniel izquierdo et juan josé ruiz , université de málaga ( uma , espagne ) . j. ch . gilbert , éléments d&apos; optimisation différentiable — théorie et algorithmes , syllabus de cours à l&apos; ensta paristech , paris . ( en ) g.b. dantzig ( 1990 ) . origins of the simplex method . in g. nash , éditeur , a history of scientific computing , acm press hist . ser . , pages 141 – 151 . acm press , reading , ma , états-unis . ( en ) k.g. murty ( 1983 ) . linear programming . john wiley &amp; sons inc . , new york . isbn 0-471-09725-x . mr 720547 . ( en ) m. padberg ( 1999 ) . linear optimization and extensions , deuxième édition , springer-verlag .
