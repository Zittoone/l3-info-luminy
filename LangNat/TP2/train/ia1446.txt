ces trois questions reflètent les intérêts divergents des chercheurs en ia , des scientifiques cognitifs et des philosophes , respectivement . les réponses scientifiques à ces questions sont en cours de discussion . elles dépendent des définitions de « l&apos; intelligence » et de la « conscience » , et de quelles « machines » il s&apos; agit . test de turing : « si une machine se comporte aussi intelligemment qu&apos; un être humain , alors elle est aussi intelligente qu&apos; un être humain . » this is a paraphrase of the essential point of the turing test . la proposition dartmouth : « chaque aspect de l&apos; apprentissage ou de toute autre caractéristique de l&apos; intelligence peut être si précisément détaillé qu&apos; une machine pourrait être créé pour simuler ceux-ci . » template : référence harvard sans parenthèses . l&apos; hypothèse de l&apos; ia forte de searle : « l&apos; ordinateur programmé de manière appropriée avec les bonnes entrées et sorties aurait ainsi un esprit exactement pareil que celui des êtres humains . » this version is from searle ( 1999 ) , and is also quoted in template : référence harvard sans parenthèses . est-il possible de créer une machine qui peut résoudre tous les problèmes que les humains résolvent en utilisant leur intelligence ? cette question définit la portée de ce que les machines seront en mesure de faire à l&apos; avenir et oriente ainsi la direction de la recherche en ia . elle ne concerne que le comportement des machines et ignore les questions d&apos; intérêt pour les psychologues , les chercheurs en sciences cognitives et les philosophes ; pour répondre à cette question , le fait qu&apos; une machine peut vraiment penser ( comme une personne pense ) ou pas , n&apos; a pas d&apos; importancesee template : référence harvard sans parenthèses , where they make the distinction between acting rationally and being rational , and define ai as the study of the former . . les arguments contre ce principe de base doivent montrer que la construction d&apos; un système d&apos; ia fonctionnel est impossible , parce qu&apos; il y a une limite pratique aux capacités des ordinateurs ou qu&apos; il y a une certaine qualité particulière de l&apos; esprit humain qui est nécessaire pour penser et qui ne peut pas être dupliqué par une machine ( ou par les méthodes de recherche actuel en ia ) . les arguments en faveur de ce principe de base doivent montrer qu&apos; un tel système est possible . la première étape pour répondre à la question est de définir clairement l &apos; « intelligence » . une critique du test de turing est qu&apos; il est explicitement anthropomorphique . si notre but est de créer des machines qui sont plus intelligentes que les gens , pourquoi devrions-nous insister pour que nos machines doivent ressembler étroitement aux gens ? russell et norvig écrivent que « les textes d&apos; ingénierie aéronautique ne définissent pas le but de leur domaine comme faisant des machines qui volent tellement exactement comme les pigeons qu&apos; elles peuvent tromper les autres pigeons » template : référence harvard sans parenthèses . une récente recherche en ia définit l&apos; intelligence en termes d&apos; agents intelligents . un « agent » est quelque chose qui perçoit et agit dans un environnement . une « mesure de performance » définit ce qui compte comme réussite pour l&apos; agenttemplate : référence harvard sans parenthèses . « si un agent agit de manière à maximiser la valeur attendue d&apos; une mesure de performance basée sur l&apos; expérience passée et sur la connaissance , alors il est intelligent . » russell and norvig would prefer the word &quot; rational &quot; to &quot; intelligent &quot; . les définitions comme celle-ci tentent de percevoir l&apos; essence de l&apos; intelligence , mais ont l&apos; inconvénient de ne pas parvenir à faire la distinction entre le bon sens « des choses qui pensent » et « des choses qui ne sont pas » . par cette définition , même un thermostat a une intelligence rudimentaire et une consciencerussell &amp; # x26 ; norvig ( 2003 , template : p. ) consider a thermostat a simple form of intelligent agent , known as a reflex agent . . hubert dreyfus décrit cet argument en faisant valoir que « si le système nerveux obéit aux lois de la physique et de la chimie , et que nous avons toutes les raisons de supposer qu&apos; il le fait , alors .... nous ... devrions être en mesure de reproduire le comportement dusystème nerveux avec un certain dispositif physique . » template : référence harvard sans parenthèses cet argument , introduit dès 1943template : référence harvard sans parenthèses et vivement décrit par hans moravec en 1988template : référence harvard sans parenthèses , est maintenant associé au futurologue ray kurzweil , qui estime que la puissance de l&apos; ordinateur sera suffisant pour une simulation d&apos; un cerveau complet d&apos; ici l&apos; an 2029template : référence harvard sans parenthèses . . une simulation en temps-non-réel d&apos; un modèle thalamocorticale qui a la taille du cerveau humain ( 1011 neurones ) a été réalisée en 2005template : lien web , et il a fallu 50 jours pour simuler 1 seconde de la dynamique du cerveau par un cluster de 27 processeurs ( voir aussi http : / / vesicle.nsi.edu / users / izhikevich / publications / large-scale _ model _ of _ human _ brain.pdf ) . searle souligne que , en principe , tout peut être simulé par un ordinateur ; amenant ainsi la définition à son point de rupture , conduit à la conclusion que tout processus peut techniquement être considéré comme un « calcul » template : référence harvard sans parenthèses . ainsi , simplement en imitant le fonctionnement d&apos; un cerveau serait en soi un aveu d&apos; ignorance en ce qui concerne l&apos; intelligence et la nature de l&apos; esprit . un système de symbole physique dispose des moyens nécessaires et suffisantes pour l&apos; action intelligente générale . une distinction est généralement faite entre le type de symboles de haut niveau qui correspondent à des objets dans le monde , tels que &lt; chien &gt; &lt; chien &gt; et &lt; queue &gt; &lt; queue &gt; et les « symboles » plus complexes qui sont présents dans une machine , comme un réseau neuronal . les premières recherches dans ia , par john haugeland , étaient axées sur ce genre de symboles de haut niveau &lt; / queue &gt; &lt; / chien &gt; template : référence harvard sans parenthèses . ces arguments montrent que la pensée humaine ne consiste pas ( uniquement ) à une manipulation de symboles de haut niveau . ils ne montrent pas que l&apos; intelligence artificielle est impossible , seulement qu&apos; il nécessite plus le traitement de symboles . en 1931 , kurt gödel a prouvé avec son théorème d&apos; incomplétude qu&apos; il est toujours possible de construire une « déclaration de gödel » qu&apos; un système formel logique donné ( comme un programme de manipulation de symboles de haut niveau ) ne pourra pas prouver . en dépit d&apos; être une vraie déclaration , la déclaration de gödel est indémontrable dans le système donné . plus spéculativement , gödel a conjecturé que l&apos; esprit humain peut éventuellement correctement déterminer la vérité ou la fausseté de tout énoncé mathématique bien fondée ( y compris toute déclaration de gödel ) , et le pouvoir que par conséquent l&apos; esprit humain ne se réduit pas à un mécanismegödel , kurt , 1951 , some basic theorems on the foundations of mathematics and their implications in solomon feferman , ed . , 1995 . . le philosophe john lucas ( depuis 1961 ) etroger penrose ( depuis 1989 ) ont défendu cet argument philosophique anti-mécanistetemplate : référence harvard sans parenthèses , template : référence harvard sans parenthèses , template : référence harvard sans parenthèses . hubert dreyfus a fait valoir que l&apos; intelligence et l&apos; expertise humaine dépendait principalement des instincts inconscients plutôt que de la manipulation symbolique consciente , et a fait valoir que ces compétences inconscientes ne seraient jamais pris en compte dans les règles formellestemplate : référence harvard sans parenthèses , template : référence harvard sans parenthèses , template : référence harvard sans parenthèses . . un système de symbole physique peut avoir un esprit et des états mentaux . un système de symbole physique peut agir intelligemment . searle a introduit les termes pour isoler l&apos; ia forte de l&apos; ia faible . il a fait valoir que , même si nous supposons que nous avions un programme informatique qui agi exactement comme un esprit humain , il y aurait encore une question philosophique difficile à répondre . avant de pouvoir répondre à cette question , nous devons savoir ce que nous entendons par « esprits » , « états mentaux » et « conscience » . les mots « esprit » et « conscience » sont utilisés par les différentes communautés de différentes manières . les auteurs de science-fiction utilisent le mot « conscience » pour décrire une propriété essentielle qui nous rend humains : une machine ou un extraterrestre qui est « conscient » sera présenté comme un caractère pleinement humain , avec une intelligence , des désirs , de la volonté , perspicacité , fierté etc. pour d&apos; autres , les mots « esprit » ou « conscience » sont utilisés comme une sorte de synonyme de l&apos; âme . pour les philosophes , les neuroscientifiques et les scientifiques cognitifs , les mots sont utilisés d&apos; une manière qui est à la fois plus précise et plus banale : ils se réfèrent au familier , à l&apos; expérience de tous les jours d&apos; avoir une « pensée dans votre tête » , comme une perception , un rêve , une intention ou un plan , ou dire quelque chose ou comprendre quelque chose . la théorie computationnelle de l&apos; esprit ou « computationnalisme » affirme que la relation entre l&apos; esprit et le cerveau est similaire ( sinon identique ) à la relation entre un programme en cours d&apos; exécution et un ordinateur . cette idée a des racines philosophiques de chez hobbes , leibniz , hume et même kanttemplate : référence harvard sans parenthèses , template : référence harvard sans parenthèses . la dernière version de la théorie est associée aux philosophes hilary putnam et jerry fodortemplate : référence harvard sans parenthèses . si les « émotions » sont définies uniquement en fonction de leur effet sur le comportement ou sur la façon dont elles fonctionnent à l&apos; intérieur d&apos; un organisme , alors les émotions peuvent être considérées comme un mécanisme qui utilise un agent intelligent pour maximiser l&apos; utilité de ses actionsquoted in template : référence harvard sans parenthèses . la peur est une source d&apos; urgence . l&apos; empathie est une composante nécessaire à la bonne interaction homme-machine , template : référence harvard sans parenthèses . cependant , les émotions peuvent également être définies en fonction de leur qualitésubjective , du ressenti d&apos; une émotion . la question de savoir si la machine ressent réellement une émotion , ou si elle agit simplement comme si elle ressent une émotion , est en fait la question philosophique , « une machine peut-elle être consciente ? » sous une autre formetemplate : référence harvard sans parenthèses under &quot; ( 4 ) the argument from consciousness &quot; . . la « conscience de soi » , comme indiqué ci-dessus , est parfois utilisé par les auteurs de science-fiction comme un caractère pleinement humain qui fait d&apos; un humain un humain . alan turing traite toutes les autres propriétés des êtres humains et se réduit la question suivante « une machine peut-elle faire l&apos; objet de sa propre pensée ? » peut-on penser à soi-même ? vu de cette manière , il est évident qu&apos; un programme peut rendre compte de ses propres états internes , comme un débogueur . la question de savoir si des machines hautement intelligentes et totalement autonomes serait dangereuses , a été examinée en détail par des futurologues ( tels que l&apos; institut singularity ) . vernor vinge a suggéré que dans quelques années seulement , les ordinateurs vont soudainement devenir des milliers , voire des millions , de fois plus intelligents que les humains . il appelle cela « la singularité » scientists worry machines may outsmart man by john markoff , ny times , july 26 , 2009 . . il suggère que cela peut être un peu ou très dangereux pour les humainsthe coming technological singularity : how to survive in the post-human era , by vernor vinge , department of mathematical sciences , san diego state university , ( c ) 1993 by vernor vinge . . cette question est examinée par une philosophie appelée le singularitarianisme . certains experts ont mis en doute l&apos; utilisation de robots au combat militaire , en particulier lorsque l&apos; on attribue à de tels robots un certain degré d&apos; autonomiecall for debate on killer robots , by jason palmer , science and technology reporter , bbc news , 8 / 3 / 09 . . la marine américaine a financé un rapport qui indique que les robots militaires deviennent plus complexesscience new navy-funded report warns of war robots going &quot; terminator &quot; , by jason mick ( blog ) , dailytech.com , february 17 , 2009 . , navy report warns of robot uprising , suggests a strong moral compass , by joseph l. flatley engadget.com , feb 18th 2009 . . le président de association for the advancement of artificial intelligence a commandé une étude pour examiner cette questionaaai presidential panel on long-term ai futures 2008-2009 study , association for the advancement of artificial intelligence , accessed 7 / 26 / 09 . . une solution envisageable serait alors de créer des programmes comme dispositif d&apos; acquisition de langage qui pourrait émuler l&apos; interaction humaine . certains ont suggéré la nécessité de construire une « ia gentille » , ce qui signifie que les progrès devront également inclure un effort pour rendre l&apos; ia intrinsèquement amicale et humainearticle at asimovlaws.com , july 2004 , accessed 7 / 27 / 09 . . au final , ceux qui croient en l&apos; existence d&apos; une âme peuvent soutenir que « la pensée est une fonction de l&apos; âme immortelle de l&apos; homme » . alan turing l&apos; a appelé « l&apos; objection théologique » template : référence harvard sans parenthèses under &quot; ( 1 ) the theological objection &quot; , although it should be noted that he also writes &quot; i am not very impressed with theological arguments whatever they may be used to support &quot; . le concept même d&apos; ia est incohérent ( searle ) . ( en ) cet article est partiellement ou en totalité issu de l ’ article de wikipédia en anglais intitulé « philosophy of artificial intelligence » ( voir la liste des auteurs ) . ( en ) david cole , the stanford encyclopedia of philosophy , fall 2004 ( lire en ligne ) . ( en ) hubert dreyfus , what computers still can&apos; t do , new york , mit press , &lt; time &gt; 1979 &lt; / time &gt; . ( en ) malcolm gladwell , blink : the power of thinking without thinking , boston , little , brown , &lt; time &gt; 2005 &lt; / time &gt; ( isbn 0-316-17232-4 ) . ( en ) john haugeland , artificial intelligence : the very idea , cambridge , mass . , mit press , &lt; time &gt; 1985 &lt; / time &gt; . ( en ) hobbes , léviathan , &lt; time &gt; 1651 &lt; / time &gt; . ( en ) douglas hofstadter , gödel , escher , bach : an eternal golden braid , &lt; time &gt; 1979 &lt; / time &gt; . ( en ) steven horst , the stanford encyclopedia of philosophy , edward n. zalta , &lt; time &gt; 2009 &lt; / time &gt; ( lire en ligne ) . ( en ) ray kurzweil , the singularity is near , new york , viking press , &lt; time &gt; 2005 &lt; / time &gt; ( isbn 0-670-03384-7 ) . ( en ) john lucas , minds and machines , &lt; time &gt; 1961 &lt; / time &gt; ( lire en ligne ) . ( en ) john mccarthy , marvin minsky , nathan rochester et claude shannon , a proposal for the dartmouth summer research project on artificial intelligence , &lt; time &gt; 1955 &lt; / time &gt; ( lire en ligne ) . ( en ) warren mcculloch et walter pitts , « a logical calculus of ideas immanent in nervous activity » , bulletin of mathematical biophysics 5 , ‎ &lt; time &gt; 1943 &lt; / time &gt; , p. 115-133 .
