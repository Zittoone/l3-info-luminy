en analyse numérique , la méthode de newton ou méthode de newton-raphsonjoseph louis lagrange et louis poinsot , traité de la résolution des équations numériques de tous les degrés. est , dans son application la plus simple , un algorithme efficace pour trouver numériquement une approximation précise d&apos; un zéro ( ou racine ) d&apos; une fonction réelle d&apos; une variable réelle . cette méthode doit son nom aux mathématiciens anglais isaac newton ( 1643-1727 ) et joseph raphson ( peut-être 1648-1715 ) , qui furent les premiers à la décrire pour la recherche des zéros d&apos; une équation polynomiale . on n&apos; oubliera pas thomas simpson ( 1710-1761 ) qui élargit considérablement le domaine d&apos; application de l&apos; algorithme en montrant , grâce à la notion de dérivée , comment on pouvait l&apos; utiliser pour calculer un zéro d&apos; une équation non linéaire , pouvant ne pas être un polynôme , et d&apos; un système formé de telles équations . sous sa forme moderne , l&apos; algorithme peut être présenté brièvement comme suit : à chaque itération , la fonction dont on cherche un zéro est linéarisée en l&apos; itéré ( ou point ) courant et l&apos; itéré suivant est pris égal au zéro de la fonction linéarisée . cette description sommaire indique qu&apos; au moins deux conditions sont requises pour la bonne marche de l&apos; algorithme : la fonction doit être différentiable aux points visités ( pour pouvoir y linéariser la fonction ) et les dérivées ne doivent pas s&apos; y annuler ( pour que la fonction linéarisée ait un zéro ) ; s&apos; ajoute à ces conditions la contrainte forte de devoir prendre le premier itéré assez proche d&apos; un zéro régulier de la fonction ( i.e. , en lequel la dérivée de la fonction ne s&apos; annule pas ) , pour que la convergence du processus soit assurée . l&apos; intérêt principal de l&apos; algorithme de newton est sa convergence quadratique locale . en termes imagés mais peu précis , cela signifie que le nombre de chiffres significatifs corrects des itérés double à chaque itération , asymptotiquement . comme le nombre de chiffres significatifs représentables par un ordinateur est limité ( environ 15 chiffres décimaux sur un ordinateur avec un processeur 32-bits ) , on peut simplifier grossièrement les propriétés de convergence de l&apos; algorithme de newton en disant que , soit il converge en moins de 10 itérations , soit il diverge . en effet , si l&apos; itéré initial n&apos; est pas pris suffisamment proche d&apos; un zéro , la suite des itérés générée par l&apos; algorithme a un comportement erratique , dont la convergence éventuelle ne peut être que le fruit du hasard ( un des itérés est par chance proche d&apos; un zéro ) . l&apos; importance de l&apos; algorithme a incité les numériciens à étendre son application et à proposer des remèdes à ses défauts . par exemple , l&apos; algorithme permet également de trouver un zéro d&apos; une fonction de plusieurs variables à valeurs vectorielles , voire définie entre espaces vectoriels de dimension infinie ; la méthode conduit d&apos; ailleurs à des résultats d&apos; existence de zéro ( utilisés dans certaines preuves du théorème des fonctions implicites , les théorèmes de kantorovitch ) . on peut aussi l&apos; utiliser lorsque la fonction est différentiable dans un sens plus faible ( fonction différentiable par morceaux , b-différentiable , semi-lisse , obliquement différentiable , etc ) , ainsi que pour résoudre des systèmes d&apos; inégalité non linéaire , des problèmes d&apos; inclusion fonctionnelle , d&apos; équations différentielles ou aux dérivées partielles , d ’ inéquations variationnelles , de complémentarité , etc. on a également mis au point des techniques de globalisation de l&apos; algorithme , lesquelles ont pour but de forcer la convergence des suites générées à partir d&apos; un itéré initial arbitraire ( non nécessairement proche d&apos; un zéro ) , comme la recherche linéaire et les régions de confiance agissant sur une fonction de mérite ( souvent la fonction de moindres-carrés ) . dans les versions dites inexactes ou tronquées , on ne résout le système linéaire à chaque itération que de manière approchée . enfin , la famille des algorithmes de quasi-newton propose des techniques permettant de se passer du calcul de la dérivée de la fonction . toutes ces améliorations ne permettent toutefois pas d&apos; assurer que l&apos; algorithme trouvera un zéro existant , quel que soit l&apos; itéré initial . appliqué à la dérivée d&apos; une fonction réelle , cet algorithme permet d&apos; obtenir des points critiques ( i.e. , des zéros de la fonction dérivée ) . cette observation est à l&apos; origine de son utilisation en optimisation sans ou avec contraintes . la méthode de newton fut décrite par le mathématicien anglais isaac newton dans de analysi per aequationes numero terminorum infinitas , écrit en 1669 et publié en 1711 par william jones . elle fut à nouveau décrite dans de metodis fluxionum et serierum infinitarum ( de la méthode des fluxions et des suites infinies ) , écrit en 1671 , traduit et publié sous le titre methods of fluxions en 1736 par john colson . toutefois , newton n&apos; appliqua la méthode qu&apos; aux seuls polynômes . comme la notion de dérivée et donc de linéarisation n&apos; était pas définie à cette époque , son approche diffère de celle décrite dans l&apos; introduction : newton cherchait à affiner une approximation grossière d&apos; un zéro d&apos; un polynôme par un calcul polynomial. d _ 2 ^ 3 + 6,3 \ , d _ 2 ^ 2 + 11,23 \ , d _ 2 + 0,061 = 0 . on obtiendrait la même équation en remplaçant x par 2,1 + d _ 2 dans le polynôme initial . négligeant les deux premiers termes , il reste 11,23 \ , d _ 2 + 0,061 = 0 ou d _ 2 \ simeq-0,0054 à peu près , ce qui donne comme nouvelle approximation de la racine x _ 3 = x _ 2 + d _ 2 \ simeq2,0946 . on peut poursuivre les opérations aussi longtemps qu&apos; il convient . cette méthode fut l&apos; objet de publications antérieures . en 1685 , john wallis en publia une première description dans a treatise of algebra both historical and practical . en 1690 , joseph raphson en publia une description simplifiée dans analysis aequationum universalis . raphson considérait la méthode de newton toujours comme une méthode purement algébrique et restreignait aussi son usage aux seuls polynômes . toutefois , il mit en évidence le calcul récursif des approximations successives d&apos; un zéro d&apos; un polynôme au lieu de considérer comme newton une suite de polynômes . c&apos; est thomas simpson ( 1710-1761 ) qui généralisa cette méthode au calcul itératif des solutions d&apos; une équation non linéaire , en utilisant les dérivées ( qu&apos; il appelait fluxions , comme newton ) voir simpson ( 1740 ) , pages 83-84 , selon ypma ( 1995 ) . . simpson appliqua la méthode de newton à des systèmes de deux équations non linéaires à deux inconnuesvoir simpson ( 1740 ) , page 82 , selon ypma ( 1995 ) . , en suivant l&apos; approche utilisée aujourd&apos; hui pour des systèmes ayant plus de 2 équations , et à des problèmes d&apos; optimisation sans contrainte en cherchant un zéro du gradienttemplate : en t. simpson ( 1737 ) , a new treatise of fluxions . . arthur cayley fut le premier à noter la difficulté de généraliser la méthode de newton aux variables complexes en 1879template : en arthur cayley ( 1789 ) . the newton-fourier imaginary problem . , par exemple aux polynômes de degré supérieur à 3 . on pourra consulter l&apos; article de ypma ( 1995 ) pour d&apos; autres informations sur l&apos; historique de l&apos; algorithme . cet auteur attribue l&apos; absence de reconnaissance aux autres contributeurs de l&apos; algorithme au livre influent de fourier , intitulé analyse des équations déterminées ( 1831 ) , lequel décrivait la méthode newtonienne sans faire référence à raphson ou simpson. f ( x ) \ simeq f ( x _ 0 ) + f &apos; ( x _ 0 ) ( x-x _ 0 ) . 0 = f ( x _ 0 ) + f &apos; ( x _ 0 ) ( x-x _ 0 ) . on obtient alors un point x _ 1 qui en général a de bonnes chances d&apos; être plus proche du vrai zéro de f que le point x0 précédent . par cette opération , on peut donc espérer améliorer l&apos; approximation par itérations successives ( voir illustration ) : on approche à nouveau la fonction par sa tangente en x _ 1 pour obtenir un nouveau point x _ 2 , etc. où f désigne la dérivée de la fonction f. f ( x _ k ) + f &apos; ( x _ k ) ( x-x _ k ) = 0 . il se peut que la récurrence doive se terminer , si à l&apos; étape k , xk n&apos; appartient pas au domaine de définition ou si la dérivée f &apos; ( x _ k ) est nulle ; dans ces cas , la méthode échoue . si le zéro inconnu \ alpha est isolé , alors il existe un voisinage de \ alpha tel que pour toutes les valeurs de départ x0 dans ce voisinage , la suite ( xk ) va converger vers \ alpha . de plus , si f &apos; ( \ alpha ) est non nul , alors la convergence est quadratique , ce qui signifie intuitivement que le nombre de chiffres corrects est approximativement doublé à chaque étape . bien que la méthode soit très efficace , certains aspects pratiques doivent être pris en compte . avant tout , la méthode de newton nécessite que la dérivée soit effectivement calculée . dans les cas où la dérivée est seulement estimée en prenant la pente entre deux points de la fonction , la méthode prend le nom de méthode de la sécante , moins efficace ( d&apos; ordre 1,618 qui est le nombre d&apos; or ) et inférieure à d&apos; autres algorithmes . par ailleurs , si la valeur de départ est trop éloignée du vrai zéro , la méthode de newton peut entrer en boucle infinie sans produire d&apos; approximation améliorée . à cause de cela , toute mise en œuvre de la méthode de newton doit inclure un code de contrôle du nombre d&apos; itérations . pour illustrer la méthode , recherchons le nombre positif x vérifiant \ cos ( x ) = x ^ 3 . reformulons la question pour introduire une fonction devant s&apos; annuler : on recherche le zéro positif ( la racine ) de f ( x ) = \ cos ( x ) -x ^ 3 . la dérivation donne f &apos; ( x ) = - \ sin ( x ) -3x ^ 2 . comme \ cos ( x ) \ leqslant 1 pour tout x et x3 &gt; 1 pour x &gt; 1 , nous savons que notre zéro se situe entre 0 et 1 . nous essayons une valeur de départ de x _ 0 = 0,5 . les 7 premiers chiffres de cette valeur coïncident avec les 7 premiers chiffres du vrai zéro . 0 = f ( a ) = f ( x ) + f &apos; ( x ) ( a-x ) + \ frac { f &quot; ( \ xi ) } { 2 } { ( a-x ) ^ 2 } , avec \ xi entre x et a. n _ f ( x ) -a = x- \ frac { f ( x ) } { f &apos; ( x ) } - a = \ frac { f &quot; ( \ xi ) } { 2 \ , f &apos; ( x ) } ( x-a ) ^ 2 . la tangente à la courbe peut couper l&apos; axe des abscisses hors du domaine de définition de la fonction. représentent des erreurs d&apos; approximations caractérisant la qualité de la solution numérique . dans tous les cas , il se peut que le critère d&apos; arrêt soit vérifié en des points ne correspondant pas à des solutions de l&apos; équation à résoudre. f ( x ) = x ^ 2 - a. cette méthode converge pour tout a \ geqslant 0 et tout point de départ x0 &gt; 0 . la convergence de la suite ( xk ) se démontre par récurrence : pour k donné , on peut montrer que si 0 \ leqslant \ sqrt { a } \ leqslant x _ k alors 0 \ leqslant \ sqrt { a } \ leqslant x _ { k + 1 } \ leqslant x _ { k } . de plus , si 0 &lt; x _ k \ leqslant \ sqrt { a } , alors \ sqrt { a } \ leqslant x _ { k + 1 } . la suite est donc décroissante au moins à partir du second terme . elle est également bornée , donc elle converge . reste à montrer que cette limite l est bien égale à \ sqrt { a } : on obtient ce résultat en montrant qu&apos; il est nécessaire que l = \ sqrt { a } pour que x _ { k + 1 } - l tende vers 0 lorsque k tend vers + \ infty . on peut déterminer une intersection des graphes de deux fonctions réelles dérivables f et g , c&apos; est-à-dire un point x tel que f ( x ) = g ( x ) , en appliquant la méthode de newton à la fonction f-g . la méthode peut aussi être utilisée pour trouver des zéros de fonctions holomorphes. la suite a un comportement chaotique , etc. article détaillé : fractale de newton . l&apos; ensemble des points à partir desquels peut être obtenue une suite qui converge vers un zéro fixé s&apos; appelle le bassin d&apos; attraction de ce zéro . pour beaucoup de fonctions complexes , le bassin d&apos; attraction est une fractale . l&apos; étude de la méthode de newton pour les polynômes à variables complexes trouve naturellement sa place dans l&apos; étude dynamique des fractions rationnelles et a été une des motivations récentes de l&apos; étude de la dynamique holomorphe. en l&apos; inconnue x _ { k + 1 } -x _ k. encore une fois , cette méthode ne fonctionne que pour une valeur initiale x0 suffisamment proche d&apos; un zéro de f. on obtient la méthode de la sécante . un état de l&apos; art est donné par izmailov et solodov ( 2014 ) . j. ch . gilbert , éléments d&apos; optimisation différentiable — théorie et algorithmes , syllabus de cours à l&apos; ensta paristech , paris . n. soualem ( 2006 ) . méthode de newton sur math-linux.com. ( en ) d. p. bertsekas ( 1995 ) , nonlinear programming . athena scientific . ( isbn 978-1-886529-14-4 ) . ( en ) j. f. bonnans , j. ch . gilbert , c. lemaréchal , c. sagastizábal ( 2006 ) , numerical optimization - theoretical and practical aspects &#91; détail des éditions &#93; . j.-l. chabert , é . barbin , m. guillemot , a. michel-pajus , j. borowczyk , a. djebbar , j.-c. martzloff ( 1994 ) . histoire d ’ algorithmes – du caillou à la puce . regards sur la science . belin , paris . j.-p. dedieu ( 2006 ) . points fixes , zéros et la méthode de newton . mathématiques et applications 54 . springer verlag , berlin . ( en ) p. deuflhard ( 2004 ) . newton methods for nonlinear problems . affine invariance and adaptive algorithms . springer series in computational mathematics , vol . 35 . springer , berlin , ( isbn 3-540-21099-7 ) . ( en ) a. f. izmailov , m. v. solodov ( 2014 ) . newton-type methods for optimization and variational problems . springer series in operations research and financial engineering . springer . ( en ) j. nocedal , s. j. wright ( 2006 ) , numerical optimization , springer . ( isbn 978-0-387-30303-1 ) . ( en ) j. m. ortega , w. c. rheinboldt ( 2000 ) . iterative solution of nonlinear equations in several variables . classics in applied mathematics . society for industrial and applied mathematics . ( isbn 0-89871-461-3 ) . ( en ) t. simpson ( 1740 ) . essays on several curious and useful subjects in speculative and mix&apos; d mathematicks , illustrated by a variety of examples . londres . ( en ) d. t. whiteside , éditeur ( 1967-1976 ) the mathematical papers of isaac newton , volumes i-vii , cambridge university press , cambridge . ( en ) t. j. ypma ( 1995 ) . historical development of the newton-raphson method . siam review , 37 , 531 – 551 .
