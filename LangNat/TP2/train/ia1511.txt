une base pour des système d&apos; aide à la décisionlepage , e. , fieschi , m. , traineau , r. , gouvernet , j. , &amp; chastang , c. ( 1992 ) . système d&apos; aide à la décision fondé sur un modèle de réseau bayesien application à la surveillance transfusionnelle . nouvelles méthodes de traitement de l ’ information en médecine , 5 , 76-87 . pour un domaine donné ( par exemple médical ) , on décrit les relations causales entre variables d&apos; intérêt par un graphe . dans ce graphe , les relations de cause à effet entre les variables ne sont pas déterministes , mais probabilisées . ainsi , l&apos; observation d&apos; une cause ou de plusieurs causes n&apos; entraîne pas systématiquement l&apos; effet ou les effets qui en dépendent , mais modifie seulement la probabilité de les observer . l&apos; intérêt particulier des réseaux bayésiens est de tenir compte simultanément de connaissances a priori d&apos; experts ( dans le graphe ) et de l&apos; expérience contenue dans les données . les réseaux bayésiens sont surtout utilisés pour le diagnostic ( médical et industriel ) , l&apos; analyse de risques , la détection des spams et le data mining . un opérateur travaillant sur une machine risque de se blesser s ’ il l ’ utilise mal . ce risque dépend de l ’ expérience de l ’ opérateur et de la complexité de la machine . « expérience » et « complexité » sont deux facteurs déterminants de ce risque ( fig. 1 ) . bien sûr , ces facteurs ne permettent pas de créer un modèle déterministe . quand bien même l ’ opérateur serait expérimenté et la machine simple , un accident reste possible . d ’ autres facteurs peuvent jouer : l ’ opérateur peut être fatigué , dérangé , etc. la survenance du risque est toujours aléatoire , mais la probabilité de survenance dépend des facteurs identifiés . la figure 1 ci-dessous représente la structure de causalité de ce modèle ( graphe ) . la figure 2 représente la probabilisation de la dépendance : on voit que la probabilité d&apos; accident augmente si l&apos; utilisateur est peu expérimenté ou la machine complexe . on voit ici comment intégrer des connaissances d&apos; expert ( les facteurs déterminants ) et des données ( par exemple , la table de probabilité d&apos; accident en fonction des déterminants peut venir de statistiques ) . définir les tables de probabilité de chaque variable , conditionnellement à ses causes . le graphe est aussi appelé la « structure » du modèle , et les tables de probabilités ses « paramètres » . structure et paramètres peuvent être fournis par des experts , ou calculés à partir de données , même si en général , la structure est définie par des experts et les paramètres calculés à partir de données expérimentales . l&apos; utilisation d&apos; un réseau bayésien s&apos; appelle « inférence » . le réseau bayésien est alors véritablement une « machine à calculer des probabilités conditionnelles » . en fonction des informations observées , on calcule la probabilité des données non observées . par exemple , en fonction des symptômes d&apos; un malade , on calcule les probabilités des différentes pathologies compatibles avec ces symptômes . on peut aussi calculer la probabilité de symptômes non observés , et en déduire les examens complémentaires les plus intéressants . ce résultat est parfois noté jpd , pour distribution de probabilité jointe . cette définition peut être retrouvée dans l&apos; article bayesian networks : a model of self-activated memory for evidential reasoning , où judea pearl introduit le terme « réseau bayésien » template : article. soit la chaîne contient une séquence x \ rightarrow z \ leftarrow y où z n&apos; appartient pas à s et aucun descendant de z appartient à s. l&apos; intuition est que s « bloque » l&apos; information entre x et y. dans l&apos; exemple donné plus haut ( figure 1 ) , on peut écrire que l&apos; expérience de l&apos; opérateur est indépendante de la complexité de la machine , mais qu&apos; elle est conditionnellement dépendante de la complexité de la machine étant donné le risque d&apos; accident . en conclusion , un graphe orienté acyclique g = ( v , e ) est un réseau bayésien si et seulement s&apos; il vérifie la propriété de markov globale orientée étant donné une loi de probabilité p sur l&apos; ensemble des variables v. bien que le problème d&apos; inférence dépende de la complexité du réseau ( plus la topologie du réseau est simple , plus l&apos; inférence est facile ) , il a été montré par g. f. cooper en 1987 que dans le cas général , il s&apos; agit d&apos; un problème np-difficile . par ailleurs , dagum et luby ont également montré en 1993 que trouver une approximation d&apos; un problème d&apos; inférence dans un réseau bayésien est également np-difficile . à la suite de ces résultats , deux grandes catégories d&apos; algorithmes d&apos; inférence viennent naturellement : les algorithmes d&apos; inférence exacte , qui calculent les probabilités a posteriori généralement en temps exponentiel , et les heuristiques qui fournissent plutôt une approximation des distributions a posteriori , mais avec une complexité computationnelle moindretemplate : harvsp . plus rigoureusement , les algorithmes d&apos; inférence exacte fournissent un résultat et la preuve que le résultat est exact , tandis que les heuristiques fournissent un résultat sans preuve de sa qualité ( c&apos; est-à-dire que selon les instances , une heuristique peut aussi bien trouver la solution exacte qu&apos; une approximation très grossière ) . la classification du problème d&apos; inférence comme np-difficile est donc un résultat primordial . pour établir sa preuve , cooper considère le problème général p ( x = x ) &gt; 0 : la probabilité que la variable x prenne la valeur x est-elle supérieure à zéro dans un réseau bayésien ? il s&apos; agit d&apos; un problème de décision ( la réponse est oui ou non ) . cooper montre tout d&apos; abord que si le problème p ( x = x ) &gt; 0 est np-complet , alors p ( x = x ) est np-difficile , et donc le problème de l&apos; inférence dans les réseaux bayésiens est np-difficile . pour prouver la np-complétude de p ( x = x ) &gt; 0 , il réduit polynomialement le problème 3-sat ( un problème np-complet classique ) au problème p ( x = x ) &gt; 0 : premièrement , il montre que la construction d&apos; un réseau bayésien à partir d&apos; une instance de 3-sat , notée c , peut être faite avec une complexité polynomiale ; ensuite , il montre que c est satisfaite si et seulement si p ( x = x ) &gt; 0 est vrai . il en résulte que p ( x = x ) &gt; 0 est np-complet , donc le problème d&apos; inférence d&apos; un réseau bayésien l&apos; est égalementtemplate : article ; template : article . l&apos; apprentissage automatique désigne des méthodes ayant pour but d&apos; extraire de l&apos; information contenue dans des données . il s&apos; agit de processus d&apos; intelligence artificielle , car ils permettent à un système d&apos; évoluer de façon autonome à partir de données empiriques . dans les réseaux bayésiens , l&apos; apprentissage automatique peut être utilisé de deux façons : pour estimer la structure d&apos; un réseau , ou pour estimer les tables de probabilités d&apos; un réseau , dans les deux cas à partir de données. a- les approches basées sur les contraintes . le principe en est de tester les indépendances conditionnelles , et de chercher une structure de réseau cohérente avec les dépendances et indépendances observées . article détaillé : réseau bayésien dynamique . un réseau bayésien dynamique ou temporel ( souvent noté rbn , ou dbn pour dynamic bayesian network ) est une extension d&apos; un réseau bayésien qui permet de représenter l&apos; évolution des variables aléatoires en fonction d&apos; une séquence discrète , par exemple des pas temporelstemplate : article . le terme dynamique caractérise le système modélisé , et non le réseau qui lui ne change pas . par exemple , partant du réseau donné en figure 1 , le système pourrait être rendu dynamique en exprimant que le risque futur d&apos; accident dépend du risque d&apos; accident passé et présent . l&apos; intuition est que plus le nombre d&apos; utilisateurs peu expérimentés se succèdent , plus le risque d&apos; accident augmente ; au contraire , une succession d&apos; utilisateurs expérimentés fait décroitre ce risque dans le temps . dans cet exemple , la variable « accident » est dite dynamique , temporelle ou persistante . les parents d&apos; un nœud , notés pour mémoire \ operatorname { pa } ( x _ { t } ) , peuvent ainsi être soit un parent direct dans le réseau au temps t , soit un parent direct au temps t-1 . un réseau bayésien dynamique respecte ainsi la propriété de markov , qui exprime que les distributions conditionnelles au temps t ne dépendent que de l&apos; état au temps t-1 dans un processus stochastique . les réseaux bayésiens dynamiques sont une généralisation des modèles probabilistes de séries temporelles de type modèle de markov caché , filtre de kalman ... article détaillé : classification naïve bayésienne . ces modèles sont particulièrement adaptés pour les problèmes de classification automatique , où c représente les classes possibles non observées d&apos; un domaine et f1 ... fn des variables observées caractérisant chaque classe de c. un exemple serait de trier dans une population les individus en deux classes , sains et malades , en fonction de symptômes observés , comme leur fièvre , etc.
