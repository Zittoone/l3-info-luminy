en mathématiques et en informatique , le hachage universel , en anglais universal hashing , ( dans un algorithme probabiliste ou un bloc de données ) est une méthode qui consiste à sélectionner aléatoirement une fonction de hachage dans une famille de fonctions de hachages qui ont certaines propriétés mathématiques . cela permet de minimiser la probabilité de collision de hachage . plusieurs familles de fonctions de hachages sont connues ( pour hacher des entiers , des chaînes de caractères ou des vecteurs ) , et leur calcul est souvent très efficace . le hachage universel a de nombreux usages en informatique , par exemple dans l ’ implémentation des tables de hachage , les algorithmes probabilistes et le chiffrement de données . article connexe : fonction de hachage . de plus une fonction de hachage déterministe ne se prête pas au rehachage qui peut être nécessaire si un trop grand nombre de collisions a été constaté . la solution à ces problèmes est de choisir la fonctions de hachage de manière aléatoire à partir d&apos; une famille de fonctions de hachage . une famille de fonctions h = \ { h : u \ to &#91; m &#93; \ } est appelée famille universelle si \ forall x , y \ in u , ~ x \ ne y : ~ ~ \ pr _ { h \ in h } &#91; h ( x ) = h ( y ) &#93; \ le \ frac { 1 } { m } . template : lien web . ) . si on a une borne supérieure \ epsilon &lt; 1 sur la probabilité de collision , on par de fonctions \ epsilon-presque universelles . \ forall x , y \ in u , ~ x \ ne y , si h est tiré aléatoirement parmi h , la différence h ( x ) -h ( y ) ~ \ bmod ~ m est uniformément distribuée dans &#91; m &#93; . notez que la définition de l&apos; universalité ne s ’ intéresse qu&apos; aux cas de collisions ( h ( x ) -h ( y ) = 0 ) alors que la propriété de différence uniforme est plus forte . de façon similaire , une famille universelle peut être xor-universelle si \ forall x , y \ in u , ~ x \ ne y , la valeur de h ( x ) \ oplus h ( y ) ~ \ bmod ~ m est uniformément distribué dans &#91; m &#93; avec \ oplus l&apos; opération ou exclusif bit à bit . ceci n&apos; est possible que dans le cas où m est une puissance de deux . une autre condition plus forte que l&apos; universalité est l&apos; indépendance par paires : cette propriété est obtenue si \ forall x , y \ in u , ~ x \ ne y on a la probabilité que x , y donne une paire de hashs z _ 1 , z _ 2 soit la même que si cette paire de hash était calculée d&apos; une manière parfaitement aléatoire : p ( h ( x ) = z _ 1 \ land h ( y ) = z _ 2 ) = 1 / m ^ 2 . l&apos; indépendance par paire est parfois appelée universalité forte . une autre propriété est l&apos; uniformité . on dit qu&apos; une famille est uniforme si tous les hashs possibles sont équiprobables en d&apos; autres termes p ( h ( x ) = z ) = 1 / m pour toute valeur de hash z. l&apos; universalité n&apos; implique pas l&apos; uniformité mais l&apos; universalité forte si. on peut créer une famille de fonctions de hachage fortement universelle de fonction de hachage , c&apos; est-à-dire une famille de fonction de hachage indépendantes deux à deux en ajoutant à chaque fonction de la famille mère une constante aléatoire uniformément distribuée à valeurs dans &#91; m &#93; . si m est une puissance de 2 , on peut créer dette famille indépendante par une opération xor avec une constante aléatoire uniformément distribuée . étant donné que le décalage d&apos; une constante n&apos; a pas forcément d&apos; importance dans certaines application ( par exemple les tables de hachage ) , la distinction nette entre la propriété de distance uniforme et l&apos; indépendance paire à paire n&apos; est pas toujours effectuéetemplate : ouvrage . . pour certaines applications comme les tables de hachage , il est important que les bits les moins significatifs du hash soient eux aussi universels . quand une famille est fortement universelle , cette propriété est garantie : si h est une famille fortement universelle avec m = 2 ^ l alors la famille faite avec les fonctions h \ bmod { 2 ^ { l &apos; } } pour h \ in h est également fortement universelle pour l &apos; \ leq l. cette propriété n&apos; est pas vraie en général pour les familles universelles . par exemple la famille faites avec les fonctions identité h ( x ) = x est clairement universelle mais la famille faite des fonctions h ( x ) = x \ bmod { 2 ^ { l &apos; } } ne l&apos; est pas . umac , poly1305 ( en ) catégorie : article contenant un appel à traduction en anglais-aes et quelques autres algorithmes de codes d&apos; authentification de message se basent sur le hachage universeltemplate : ouvrage . , template : ouvrage . . dans ces applications , le logiciel sélectionne une nouvelle fonction de hachage pour chaque message , basé sur un identifiant unique généré pour le hachage du message . plusieurs implémentations de tables de hachage utilisent le hachage universel . dans ces applications , typiquement , le logiciel ne prend une nouvelle fonction de hachage que s&apos; il note qu&apos; il y a trop de clés qui ont produit une collision est trop important ; sinon la même fonctions de hachage reste utilisée . certains schéma de résolution de collision , comme le hachage dynamique parfait , change de fonction de hachage à la première collision observée . les autres méthodes de résolution de collision comme la méthode du coucou et le 2-choice hashing , autorisent un certain nombre de collisions avant de changer de fonction de hachage . pour tout x de s , le nombre de clés pour le hash h ( x ) est n / m. en implémentant des tables de hachage par un chaînage , ce nombre est proportionnel au temps de calcul pour une opération basée sur une clé ( recherche , insertion ou suppression ) . le nombre de paires de clé x , y de s qui produisent des collisions ( x \ ne y et h ( x ) = h ( y ) ) est majoré par n ( n-1 ) / 2m qui est de l&apos; ordre de o ( n ^ 2 / m ) . dans le cas du hachage de n ^ 2 entrées , il y a une probabilité supérieure à 1 / 2 de n&apos; avoir aucune collision . le nombre de clés qui dans les fragments de au moins t clés est majoré par 2n / ( t-2 ( n / m ) + 1 ) template : article . . ainsi la capacité de chaque fragment est limitée à trois fois la taille moyenne ( t = 3n / m ) , le nombre total de clés dans les fragments qui dépassent la moyenne est au plus o ( m ) . cette propriété ne tient que pour une famille de fonctions de hachage où la probabilité de collision est majorée par 1 / m. si une définition plus faible est utilisée et qu&apos; on se contente d&apos; une majoration en o ( 1 / m ) , alors ce résultat n&apos; est plus valable . les garanties ci-dessus sont valables pour n&apos; importe quel ensemble s donné , elles tiennent même si le jeu de données à hacher a été sélectionné par un attaquant . cependant comme l&apos; attaquant crée son jeu de données avant que l&apos; algorithme n&apos; ait fait sa sélection de fonction de hachage aléatoire . si l&apos; attaquant peut deviner les fonctions qui seront sélectionnées par l&apos; algorithme , la sélection aléatoire n&apos; apporte rien par rapport au hachage déterministe . la deuxième et la troisième garantie sont typiquement utilisées en conjonction avec un rehachage . par exemple , un algorithme probabiliste peut être sélectionné pour un taux de collision attendu de o ( n ) . si trop de collisions sont observées , un autre algorithme h de la famille est sélectionné de manière aléatoire et le traitement est répété . l&apos; universalité garantit que le nombre de répétition est une variable aléatoire géométrique . étant donné que les informations sont représentées en machine par des mots , les hachages peuvent être réduit à trois situations : un mot ( un entier , integer en anglais ) ; un vecteur de mots de taille fixée ; et un vecteur de taille variable assimilé à une chaîne de mots informatiques / caractères ( string en anglais ) . cette section se réfère au cas du hachage d&apos; entiers qui tiennent dans un mot machine . dans ce cas les opérations addition , multiplication , et division sont exécutées directement sur le processeur et coûtent très peu de ressources . à partir de ce point on considère l&apos; univers à hacher u = \ { 0 , \ dots , m-1 \ } . a \ equiv i \ cdot m \ cdot ( x-y ) ^ { -1 } \ pmod p. \ lfloor ( p - 1 ) / m \ rfloor / ( p-1 ) \ le ( ( p-1 ) / m ) / ( p-1 ) = 1 / m. h ( x ) -h ( y ) \ equiv ( a ( x-y ) ~ \ bmod ~ p ) \ pmod { m } . étant donné que x - y est non nul et que a est uniformément distribué dans \ { 1 , \ dots , p \ } , on déduit que a ( x-y ) modulo p est aussi uniformément distribué dans \ { 1 , \ dots , p \ } . la distribution de ( h ( x ) -h ( y ) ) ~ \ bmod ~ m est ainsi presque uniforme , avec une différence de probabilité au maximum de \ pm 1 / p entre les échantillons . il en résulte que la distance statistique à une famille uniforme est o ( m / p ) , qui devient négligeable quand p \ gg m. est seulement approximativement universelle : \ pr \ { h _ a ( x ) = h _ a ( y ) \ } \ le 2 / m pour tout x \ neq y. de plus , cette analyse est assez fine ; carter et wegman ont montré que \ pr \ { h _ a ( 1 ) = h _ a ( m + 1 ) \ } \ ge 2 / ( m-1 ) pour tout ( p-1 ) ~ \ bmod ~ m = 1 . la méthode la plus populaire dans le hachage d&apos; entier est la méthode « multiplie et décale » décrit par dietzfelbinger et al. en 1997template : article . . en évitant l&apos; arithmétique modulaire , cette méthode est plus simple à implémenter et est significativement plus rapide en pratique ( usuellement plus rapide d&apos; un facteur 4 ) template : lien web . ) . ce schéma ne satisfait pas la propriété de différence uniforme et est seulement 2 / m-presque-universel ; pour tout x \ neq y , \ pr \ { h _ a ( x ) = h _ a ( y ) \ } \ le 2 / m. pour comprendre le comportement de la fonction de hachage , remarquez que si ax \ bmod 2 ^ w et ay \ bmod 2 ^ w ont les mêmes &apos; m &apos; bits de poids fort alors a ( x-y ) \ bmod 2 ^ w n&apos; a que des 1 ou que des 0 dans ses &apos; m &apos; bits de poids fort ( cela dépend du maximum entre ax \ bmod 2 ^ w et ay \ bmod 2 ^ w ) . supposons maintenant que les bits de poids faible de x-y apparaissent en position w-c . comme a est un entier impair et que les entiers impairs possèdent un inverse dans l&apos; anneau z _ { 2 ^ w } , on déduit que a ( x-y ) \ bmod 2 ^ w sera uniformément distribué parmi les entiers de w bits avec le bit de poids le plus faible situé à la position w-c . la probabilité que ces bits soient tous égaux à 0 ou à 1 est donc au plus de 2 / 2 ^ m = 2 / m. d&apos; autre part si c &lt; m , alors les m bits de poids fort de a ( x-y ) \ bmod 2 ^ w contiennent des 0 et des 1 et on est certain que h ( x ) \ ne h ( y ) . finalement , si c = m alors le bit w-m de a ( x-y ) \ bmod 2 ^ w vaut 1 et h _ a ( x ) = h _ a ( y ) si et seulement si les bits w-1 , \ ldots , w-m + 1 valent également 1 , ce qui arrive avec la probabilité de 1 / 2 ^ { m-1 } = 2 / m. cette analyse est difficile , comme on peut le constater avec les exemples x = 2 ^ { w-m-2 } et y = 3x . pour obtenir une fonction de hachage &apos; vraiment &apos; universelle , on peut utiliser la méthode multiplie et additionne. où a est un entier pair positif tiré aléatoirement , a &lt; 2 ^ w , et b un entier positif tiré aléatoirement b &lt; 2 ^ { w-m } . avec ce choix de a et b , \ pr \ { h _ { a , b } ( x ) = h _ { a , b } ( y ) \ } \ le 1 / m pour tout x \ not \ equiv y \ pmod { 2 ^ w } template : ouvrage . . ceci diffère légèrement , mais sur un point important , de l&apos; erreur de traduction de l&apos; article en anglaistemplate : chapitre . . h ( \ bar x ) = \ left ( \ sum _ { i = 0 } ^ { k-1 } h _ i ( x _ i ) \ right ) \ , \ bmod ~ m , où chaque h _ i \ in h est choisi de manière aléatoire et indépendante . si m est une puissance de deux , la somme peut être remplacée par une opération ou exclusiftemplate : chapitre , section 5.3 . . h _ { \ bar a } ( \ bar x ) = \ left ( \ big ( \ sum _ { i = 0 } ^ { k-1 } x _ i \ cdot a _ i \ big ) ~ \ bmod ~ 2 ^ { 2w } \ right ) \ , \ , \ mathrm { div } \ , \ , 2 ^ { 2w-m } . h _ { \ bar a } ( \ bar x ) = \ left ( \ big ( \ sum _ { i = 0 } ^ { \ lceil k / 2 \ rceil } ( x _ { 2i } + a _ { 2i } ) \ cdot ( x _ { 2i + 1 } + a _ { 2i + 1 } ) \ big ) \ bmod ~ 2 ^ { 2w } \ right ) \ , \ , \ mathrm { div } \ , \ , 2 ^ { 2w-m } . si les opérations en double précision ne sont pas disponibles , on peut interpréter l&apos; entrée comme un vecteur de demi-mots ( des entiers de w / 2 bits de longs ) . l&apos; algorithme va alors utiliser \ lceil k / 2 \ rceil multiplications , avec k le nombre de demi mots du vecteur . ainsi l&apos; algorithme tourne à un &quot; taux &quot; d&apos; une multiplicatio par mot d&apos; entrée . ce schéma peut également être utilisé pour hacher des entiers en considérant que leurs bits sont un vecteur d&apos; octets . dans cette variante , la technique est appelée hachage tabulaire et fournit une alternative pratique aux fonctions de hachage universelle basées sur des multiplicationstemplate : chapitre . . h _ { \ bar a } ( \ bar x ) ^ { \ mathrm { strong } } = ( a _ 0 + \ sum _ { i = 0 } ^ { k-1 } a _ { i + 1 } x _ i \ bmod ~ 2 ^ { 2w } ) \ , \ , \ mathrm { div } \ , \ , 2 ^ w . le résultat est fortement universel sur w bits . expérimentalement cette méthode consomme 0.2 cycle cpu par octet sur les dernières puces intel pour w = 32 . cette section vise le cas de vecteur de mots de taille variable . si la taille de la chaîne peut être majorée par un petit nombre , il est préférable d&apos; utiliser la méthode avec des vecteurs de taille définie en complétant la chaîne à hacher par des zéros au besoin . l&apos; espace mémoire requis pour le calcul est la longueur maximale de la chaîne , mais le temps de calcul dépend uniquement de la longueur de h ( s ) . tant qu&apos; on interdit les zéros dans la chaîne , on peut ignorer le remplissage d&apos; une chaîne par des zéros terminaux sans que la propriété d&apos; universalité en soit affectée . noter que si on autorise la présence de zéros dans la chaîne alors le problème d&apos; ajout de zéros terminaux se règle en choisissant d&apos; ajouter un caractère non nul , qui balisera la fin de la chaîne à toutes les chaînes en entrée avant le traitement . maintenant supposons qu&apos; il faille hacher \ bar x = ( x _ 0 , \ dots , x _ \ ell ) , sans qu&apos; on puisse avoir d&apos; estimation correcte de \ ell . une famille de hachage universelletemplate : chapitre. h _ a ( \ bar x ) = h _ \ mathrm { int } \ left ( \ big ( \ sum _ { i = 0 } ^ \ ell x _ i \ cdot a ^ i \ big ) \ bmod ~ p \ right ) , où a \ in &#91; p &#93; est uniformément aléatoire et h _ \ mathrm { int } est tiré aléatoirement d&apos; une famille aléatoire universelle qui indexe l&apos; ensemble des entiers &#91; p &#93; \ mapsto &#91; m &#93; . l&apos; algorithme ci-dessus est également connu en tant que fonction de hachage multiplicativetemplate : lien web . . en pratique l&apos; opérateur modulo et le paramètre p peuvent être évités tous les deux simplement en autorisant les entiers à dépasser leur taille maximale ( overflow ) car cette opération est équivalente à un modulo max _ int _ value + 1 dans beaucoup de langages de programmation . ci-dessous , un tableau de valeurs choisies pour initialiser h dans quelques implémentations populaires . soient deux chaînes \ bar x , \ bar y et \ ell la taille de la plus longue des deux ; pour les besoins de l&apos; analyse on supposera que la seconde chaîne est complétée par des zéros jusqu&apos; à atteindre la longueur \ ell . une collision avant d&apos; appliquer h _ \ mathrm { int } implique que a est une racine du polynôme dont les coefficients sont \ bar x- \ bar y. ce polynôme a au plus \ ell racines modulo p , donc la probabilité de collision est au plus de \ ell / p. la probabilité de collision à travers l&apos; aléa h _ \ mathrm { int } descend la probabilité totale de collision à \ frac1m + \ frac { \ ell } p. ainsi si le nombre premier p est suffisamment grand comparé à la longueur des chaînes à hacher , la famille est très proche d&apos; une famille universelle ( en termes de distance statistique ) . on peut choisir le nombre premier p proche d&apos; une puissance de 2 , un nombre premier de mersenne par exemple . cela permet d&apos; implémenter les opérations de modulo sans utiliser de division ( en utilisant des opérations plus rapides comme les additions et les décalages de bits ) . par exemple sur des architectures modernes on peut travailler avec p = 2 ^ { 61 } -1 , alors que les x _ i sont stockés sur 32 bits . on peut appliquer un hachage vectoriel sur des blocs de données de l&apos; entrée . par exemple , on hache l&apos; entrée par vecteurs de 16 mots et on applique le hachage de chaîne aux \ lceil k / 16 \ rceil hashs obtenus . le hachage de chaîne , très lent , étant appliqué à un ensemble de données significativement plus petit le calcul devient presque aussi rapide que le hachage vectoriel . on peut choisir une puissance de deux comme diviseur ce qui permet de réduire l&apos; opération modulo à un masquage de bits plus rapide que les divisions . la famille de fonctions nh utilise cette méthode . ( en ) cet article est partiellement ou en totalité issu de l ’ article de wikipédia en anglais intitulé « universal _ hashing » ( voir la liste des auteurs ) .
