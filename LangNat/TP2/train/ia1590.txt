superintelligence : chemins , dangers , stratégies ( en anglais : superintelligence : paths , dangers , strategies ) ( 2014 ) est un livre écrit par le philosophe suédois nick bostrom de l&apos; université d&apos; oxford . le livre pose le constat que si une superintelligence venait à être créée et qu ’ elle surpassait l&apos; intelligence générale humaine , alors elle pourrait remplacer et dominer les humainsfinancial times review , juillet 2014 . par analogie , de même que le sort des gorilles dépend maintenant plus des humains que des gorilles eux-mêmes , le sort de l&apos; humanité future dépendra des actions de la superintelligencetemplate : lien web . le résultat pourrait être une catastrophe existentielle pour l&apos; hommetemplate : article . le livre de bostrom a été traduit dans de nombreuses langues et est disponible en livre audiotemplate : lien web , template : lien web . l ’ auteur commence par énumérer les différentes possibilités qui pourraient conduire à l ’ apparition d ’ une superintelligence . elles incluent le génie génétique , la reproduction sélective , le transhumanisme , l ’ intelligence machinelle soit par rétro-ingénierie soit par le développement d ’ algorithmes d ’ apprentissage . l ’ auteur conclu cette première prospective par la haute probabilité de l ’ émergence d ’ une superintelligence . le temps nécessaire à cette apparition n ’ est pas déterminé mais selon l ’ auteur le risque existe que cette apparition soit très rapide . quel que soit le calendrier , une fois que la machine d ’ un niveau cognitif comparable aux humains sera développé , un système « superintelligent dépassant largement les performances cognitives de l&apos; homme dans pratiquement tous les domaines » devrait suivre étonnamment rapidement , peut-être même instantanément . une telle superintelligence serait difficile à contrôler ou restreindre . alors que les objectifs ultimes d ’ une superintelligence pourraient varier considérablement , une superintelligence fonctionnelle générera spontanément des sous-objectifs naturels ou instrumentaux tels que l&apos; auto-préservation , l&apos; intégrité de ses buts , l ’ amélioration cognitive et l&apos; acquisition des ressources . par exemple , un agent dont le seul but final est de résoudre l&apos; hypothèse de riemann ( une célèbre conjecture mathématique non résolue ) pourrait signifier comme sous-objectif la transformation de l&apos; ensemble de la terre en une certaine forme de computronium ( hypothétique « matière programmable » ) pour faciliter le calcul . la superintelligence agirait proactivement pour parer toutes tentatives extérieures visant à entraver la réalisation de ce sous-objectif . afin d&apos; éviter une telle catastrophe existentielle , il semble nécessaire de résoudre le « problème du contrôle de l&apos; ia » avant qu ’ une première superintelligence ne voit le jour . la solution pourrait impliquer inculquer à la superintelligence des objectifs compatibles avec la survie humaine et son bien-être . résoudre le problème du contrôle est cependant étonnamment difficile parce que la plupart des objectifs , lorsqu&apos; ils sont traduits en code implémentable dans une machine , conduisent à des conséquences imprévues et indésirables . le livre a été classé n ° 17 meilleur livre de science en août 2014 par le new york timestemplate : lien web . durant le même mois , le magnat des affaires elon musk a fait la une des titres en déclarant , en accord avec le livre , que l&apos; intelligence artificielle était potentiellement plus dangereuse que les armes nucléairestemplate : lien web , template : lien web , template : lien web . le travail de bostrom sur la superintelligence a également influencé bill gatestemplate : lien web , template : lien web . dans une interview de mars 2015 avec le pdg de baidu , robert li , m. gates a affirmé qu&apos; il « recommandait vivement » la lecture du livre de bostromtemplate : lien web . pour l&apos; éditeur du financial times , l&apos; écriture de bostrom « était parfois opaque trahissant son expérience en tant que professeur de philosophie » , mais que l ’ ouvrage était convaincant , démontrant que le risque d ’ une superintelligence était assez grand pour que la société réfléchisse dès maintenant aux moyens de doter à l&apos; avenir une intelligence machinelle de valeurs positives . une revue dans the guardian fait remarquer que « même les machines les plus sophistiquées créées aujourd ’ hui sont loin d ’ être intelligentes » et que « les premières prédictions d ’ une ia surhumaine dataient des années 1960 » , l ’ article concède malgré tout qu ’ il « serait mal avisé de rejeter complètement cette possibilité » template : article . certains collègues de bostrom suggèrent qu ’ une guerre nucléaire reste une plus grande menace pour l&apos; humanité qu ’ une superintelligence , de même que les perspectives qu ’ apportent les nanotechnologies et de la biotechnologie en matière d ’ armement destructeurguardian review , juillet 2014 . . the economist déclare que « bostrom est contraint de passer une grande partie du livre à discuter de spéculations construites sur des conjectures ... mais que le livre est néanmoins intéressant » . les implications de l&apos; introduction d&apos; une deuxième espèce intelligente sur terre sont potentiellement assez grande pour mériter qu ’ on s ’ y arrête , même si les perspectives semblent lointaines » template : article . ronald bailey écrit dans the libertarian reason que pour bostrom la résolution du problème du contrôle de l&apos; ia est la « tâche essentielle assignée à notre époque » template : article . selon tom chivers de the daily telegraph , le livre est difficile à lire , mais néanmoins enrichissanttemplate : article . ( en ) cet article est partiellement ou en totalité issu de l ’ article de wikipédia en anglais intitulé « superintelligence : paths , dangers , strategies » ( voir la liste des auteurs ) .
