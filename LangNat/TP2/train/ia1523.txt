vous pouvez partager vos connaissances en l ’ améliorant ( comment ? ) selon les recommandations des projets correspondants . la recherche des plus proches voisins , ou des k plus proches voisins , est un problème algorithmique classique . de façon informelle le problème consiste , étant donné un point à trouver dans un ensemble d&apos; autres points , quels sont les k plus proches . la recherche de voisinage est utilisée dans de nombreux domaines , tels la reconnaissance de formes , le clustering , l&apos; approximation de fonctions , la prédiction de séries temporelles et même les algorithmes de compression ( recherche d&apos; un groupe de données le plus proche possible du groupe de données à compresser pour minimiser l&apos; apport d&apos; information ) . soient un espace e de dimension d , un ensemble a de n points dans cet espace ( a ⊂ e ) et un entier k plus petit que n. la recherche des plus proches voisins consiste , étant donné un point x de e n&apos; appartenant pas nécessairement à a , à déterminer quels sont les k points de a les plus proches de x. on parle alors de trouver un voisinage de taille k autour du point x. l&apos; algorithme naïf de recherche de voisinage consiste à passer sur l&apos; ensemble des n points de a et à regarder si ce point est plus proche ou non qu&apos; un des plus proches voisins déjà sélectionné , et si oui , l&apos; insérer . on obtient alors un temps de calcul linéaire en la taille de a : o ( n ) ( tant que \ scriptstyle k \ ll n ) . cette méthode est appelée la recherche séquentielle ou recherche linéaire . la recherche linéaire souffre d&apos; un problème de lenteur . si l&apos; ensemble a est grand , il est alors extrêmement couteux de tester les n points de l&apos; espace . les optimisations de cet algorithme se basent souvent sur des cas particuliers du problème . le plus souvent , l&apos; optimisation consiste à effectuer au préalable un algorithme ( pré-traitement ) pouvant avoir une complexité supérieure à o ( n ) mais permettant d&apos; effectuer par la suite très rapidement un grand nombre de recherches . il s&apos; agit alors de trouver un juste milieu entre le temps de pré-calculs et le nombre de recherches qui auront lieu par la suite . il existe des algorithmes efficaces de recherche lorsque la dimension d est petite ( inférieure à ~ 15 ) . la structure la plus connue est l&apos; arbre k-d , introduite en 1975template : article . un problème majeur de ces méthodes est de souffrir de la malédiction de la dimension . lorsque la dimension d est trop grande , ces méthodes ont des performances comparables ou inférieures à une recherche linéairetemplate : article . on cherche à placer le point c dans l&apos; arbre , on applique donc l&apos; algorithme d&apos; insertion . une fois arrivé à une feuille , ce point est sauvegardé comme étant le « meilleur candidat pour l&apos; instant » . sinon , on élimine la branche et on continue à remonter l&apos; arbre . on s&apos; arrête à la racine . article détaillé : locality sensitive hashing . on remplace les points de l&apos; espace e par une empreinte , typiquement un nombre , calculée par une fonction de hachage . plutôt que de faire une recherche par les m coordonnées ( pour un espace e à m dimensions ) , on fait une recherche des plus proches voisins par la valeur de l&apos; empreinte . on fait des recherches sur plusieurs empreintes , en utilisant une famille de fonctions de hachage , jusqu&apos; à trouver un candidat statistiquement satisfaisant. gestion administrative d&apos; un territoire : pour déterminer de quel établissement ( bureau de poste , établissement scolaire … ) une personne dépend , on recherche le plus proche établissement voisin du domicile ; on parle d&apos; ailleurs parfois du « problème du bureau de poste » post-office problem , cf. template : knuth-taocpvol3 . ce terme est également utilisé pour décrire le problème du cercle minimum ; il s&apos; agit alors de trouver où placer un bureau de poste pour servir au mieux un ensemble de domiciles donnés . . l&apos; espace peut aussi être un espace abstrait : si un objet est représenté par un nombre m de paramètres chiffrés , on peut représenter cet objet par un point dans l&apos; espace à m dimensions , l&apos; algorithme permet alors de trouver le ou les objets ayant les propriétés les plus proches . il peut par exemple s&apos; agir de trouver le meilleur candidat de substitution à un objet donné , le meilleur candidat pour une application donnée ( plus proche voisin de l&apos; objet idéal ) , ou bien trouver l&apos; objet correspondant le mieux à une empreinte relevée ( identification , enquête ) . arbre d&apos; axes principaux .
