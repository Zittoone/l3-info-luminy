les trois lois de la robotique , formulées par l&apos; écrivain de science-fiction isaac asimov , sont des règles auxquelles tous les robots positroniques qui apparaissent dans ses romans doivent obéir. un robot doit protéger son existence tant que cette protection n&apos; entre pas en conflit avec la première ou la deuxième loi . au cours du cycle des livres sur les robots , une loi zéro , qui prendra une importance considérable , sera instituée par deux robots , r. giskard reventlov et r. daneel olivaw , dans la nouvelle les robots et l&apos; empire . cette loi zéro placera ou tentera de placer la sécurité de l&apos; humanité avant celle d&apos; un individu . cependant , cette loi n&apos; est pas codée au niveau matériel des cerveaux positroniques , à la différence des trois premières , et elle est une loi de type logiciel , puisque « déduite » par le robot r. giskard reventlov . d&apos; après l ’ oxford english dictionary , le premier passage dans la nouvelle d&apos; asimov nommée menteur ! qui mentionne la première loi est la plus ancienne mention enregistrée du mot « robotique » . asimov n&apos; en était pas conscient initialement ; il a supposé que le mot existait déjà , par analogie avec « mécanique » ( comme positronique avec « électronique » ) mais le docteur est d&apos; or ( titre original : gold ) pocket template : isbn page 235 . , et d&apos; autres termes similaires dénotant des branches de science appliquée . les trois lois forment un principe d&apos; organisation et un thème unifiant l&apos; œuvre de fiction d&apos; asimov , apparaissant dans son cycle des robots , et d&apos; autres histoires reliées à celui-ci , comme dans son cycle de lucky starr , fiction scientifiquement orientée pour jeune adulte . d&apos; autres auteurs travaillant dans l&apos; univers fictif d&apos; asimov les ont adoptées , et des références ( souvent parodiques ) apparaissent dans une bonne part de la science-fiction , et dans d&apos; autres genres . asimov considérait que ses lois devaient être universelles pour les robots . aussi , assistant à la projection de 2001 , l&apos; odyssée de l&apos; espace , il quitta avec bruit la salle lorsque l&apos; ordinateur hal 9000 viola sa première loi en s&apos; attaquant à des humains . dans la science-fiction des années 1930 , la majorité des intelligences artificielles suivent le modèle de la créature de frankenstein , ce qu&apos; asimov trouve péniblemais le docteur est d&apos; or ( titre original : gold ) pocket template : isbn page 210 : « je lisais énormément de science-fiction dans les années trente , et je commençai à en avoir assez de cette éternelle conspiration des robots » . , voire insupportable : « des robots étaient créés et détruisaient leur créateur ; des robots étaient créés et détruisaient leur créateur ; des robots … etc. » préface des robots ( titre original : i robot ) j&apos; ai lu template : isbn page 13 : « dans les années trente , je devins lecteur de science-fiction et je me lassai rapidement de cette histoire inlassablement répétée . puisque je m&apos; intéressais à la science , je me rebellais contre cette interprétation purement faustienne de la science . » asimov nomme « complexe de frankenstein » asimov , les robots , préface , traduction p. billon , traduction révisée par p.-p. durastanti , template : abrd j&apos; ai lu , template : p. cette tendance à considérer les machines comme des créatures mortellement dangereuses . le 7 mai 1939 , asimov assiste à un rassemblement de la queens science fiction society , où il rencontre binder , dont asimov a admiré l&apos; histoire . trois jours plus tard , asimov commence à écrire « &#91; sa &#93; propre histoire d&apos; un robot sympathique et noble » &#91; réf. souhaitée &#93; catégorie : article à référence souhaitée , sa quatorzième histoire . treize jours après , il propose robbie à john w. campbell , éditeur d&apos; astounding science-fiction . campbell la rejette , disant qu&apos; elle était trop ressemblante à helen o&apos; loy de del reyasimov , isaac ( 1979 ) . in memory yet green . doubleday . pages 236 – 238 template : isbn . . frederik pohl , éditeur du magazine astounding stories , la publie dans son périodique l&apos; année suivanteasimov , isaac ( 1979 ) . in memory yet green . doubleday , page 263 template : isbn . . asimov attribue les lois à john w. campbell , au cours d&apos; une conversation tenue le 23 décembre 1940 . cependant , campbell affirme qu&apos; asimov avait déjà les lois dans son esprit , et qu&apos; elles avaient simplement besoin d&apos; être formulées explicitement . plusieurs années plus tard , un ami d&apos; asimov nommé randall garrett attribue les lois à une collaboration symbiotique entre les deux hommes , une suggestion qu&apos; asimov adopte avec enthousiasmetemplate : ouvrage . d&apos; après ses écrits autobiographiques , asimov inclut l&apos; inaction à la première loi à cause d&apos; un poème d&apos; arthur hugh clough nommé le dernier décalogue , qui contient les vers satiriques : « tu ne tueras point , mais ne t&apos; acharneras point non plus , légalement , à garder en vietemplate : lang . » des détails sur cette période peuvent être trouvés dans les chapitres 21 à 26 de in memory yet green . même si asimov colle la création des lois sur une seule date , leurs interventions dans sa littérature sont présentes sur une certaine période . il écrit deux histoires de robots sans mention explicite des lois , robbie et reason . il y suppose cependant que les robots ont des garde-fous inhérents à leur nature . menteur ! , sa troisième nouvelle sur les robots , fait pour la première fois mention de la première loi , mais pas des deux autres . toutes les trois apparaissent finalement ensemble dans runaround . quand ces histoires et plusieurs autres sont compilées dans l&apos; anthologie les robots , reason et robbie sont mises à jour pour que les trois lois y apparaissent , bien que le matériel ajouté à reason ne soit pas entièrement cohérent avec les lois telles que décrites ailleurs . en particulier , l&apos; idée d&apos; un robot protégeant les vies humaines sans même croire en l&apos; existence des êtres humains est en désaccord avec le raisonnement d&apos; elijah baley , décrit ci-après . pendant les années 1950 , asimov écrit une série de nouvelles de science-fiction expressément créée pour un public de jeunes adultes . originellement , son éditeur attend des nouvelles qu&apos; elles puissent être adaptées dans une série télévisée long métrage , quelque chose comme ce qu&apos; avait été the lone ranger pour la radio . ayant peur que ses histoires soient adaptées dans le programme « généralement déplorable » qu&apos; il a vu inonder les canaux télévisés , asimov décide de publier son cycle de lucky starr sous le pseudonyme paul french . quand les plans pour la télévision furent abandonnés , il décide d&apos; abandonner ce nom ; il apporte les lois dans lucky starr et les lunes de jupiter , « ce qui était un suicide pour l&apos; identité de paul french même pour le lecteur le plus anodin » . dans sa nouvelle la preuve ( evidence ) , asimov expose , par le personnage dr susan calvin , une base morale derrière les lois . calvin précise qu&apos; il est naturel d&apos; attendre des êtres humains qu&apos; ils se restreignent de blesser d&apos; autres humains ( excepté dans des temps d&apos; extrême coercition comme la guerre , ou pour sauver un plus grand nombre d&apos; humains ) . cela équivaut à la première loi pour un robot . de même , d&apos; après calvin , la société attend des individus qu&apos; ils obéissent aux instructions des autorités reconnues : docteurs , enseignants , et ainsi de suite , ce qui est équivalent à la seconde loi de la robotique . enfin , les humains sont en général enclins à éviter de se voir blessés eux-mêmes , ce qui est la troisième loi pour un robot . l&apos; intrigue de la preuve tourne autour de la question de la définition d&apos; un être humain par rapport à un robot conçu spécialement pour sembler humain ; calvin pense que si un tel individu obéit aux lois , il serait un robot , ou « un homme très bon » . un autre personnage demande alors à calvin si , après tout , les robots sont si différents des êtres humains . elle répond : « ils sont à des mondes de nous . les robots sont , pour l&apos; essentiel , corrects » . un outil doit rester intact durant son utilisation , sauf si sa destruction est requise pour son utilisation ou sa sécurité . les histoires d&apos; asimov testent ses lois dans une large variété de circonstances , proposant et rejetant des modifications . un disciple de la science-fiction , james gunn , écrit : « les histoires de robots d&apos; asimov dans leur entier répondent de la meilleure manière à une analyse sur cette base : l&apos; ambiguïté dans les trois lois et les manières par lesquelles asimov a joué vingt et une variations sur le thème » ( le nombre est précis depuis 1980 ) . tandis que l&apos; ensemble des lois procurait de l&apos; inspiration à beaucoup d&apos; histoires , asimov introduisait de temps en temps des versions modifiées dans son œuvre . comme l&apos; exemple suivant le démontre , les lois servent une fonction conceptuelle analogue au test de turing , replaçant des questions brouillées comme « qu&apos; est-ce qui est humain ? » par des problèmes permettant une réflexion plus fructueuse . dans face aux feux du soleil , asimov établit que la première loi était incomplète : il y montre qu&apos; un robot est pleinement capable de blesser un être humain tant qu&apos; il ignore que ses actions entraîneront une telle conséquence . l&apos; exemple suivant est utilisé : un robot met du poison dans un verre de lait , car on lui a dit que le lait sera jeté plus tard ; ensuite , un second robot sert le lait à un homme , ne sachant pas qu&apos; il est empoisonné . cette modification est motivée par une difficulté pratique : des robots et des êtres humains travaillent au milieu de radiations fatales aux robots , mais supportables pour les hommes . or les robots s&apos; acharnent à aller « secourir » les humains au cœur des radiations , même en l&apos; absence de danger immédiat ; ce faisant , ils nuisent au travail et se détruisent eux-mêmes . enlever la clause d &apos; « inaction » de la première loi résout le problème , mais crée la possibilité d&apos; un problème encore plus grand : un robot peut commencer une action dangereuse en sachant qu&apos; il peut l&apos; interrompre , puis décider de ne pas aller jusqu&apos; au bout ( lâcher une lourde charge sans la rattraper est l&apos; exemple donné dans le texte ) . les solariens ont créé dans le roman les robots et l&apos; empire des robots régis par les trois lois de manière normale , mais pour lesquels le sens du mot « humain » est déformé . selon leur programmation , seules les personnes parlant avec l&apos; accent solarien sont humaines . de cette manière , ces robots n&apos; auront aucun problème à agresser des humains non solariens ( et certains sont même programmés spécifiquement pour cela ) . au temps où se déroule terre et fondation , les solariens se sont modifiés génétiquement au point de devenir une espèce distincte de l&apos; humanité , devenant hermaphrodites et capables de contrôler et de transformer diverses formes d&apos; énergie ( cinétique , chimique , thermique , lumineuse , électrique ) au point d&apos; alimenter en énergie tous les robots et machines de leurs immenses domaines . les robots de solaria continuent de respecter les trois lois en considérant les solariens comme seuls humains , plutôt que les hommes normaux du reste de la galaxie . pour que tu t&apos; y intéresses ( that thou art mindful of mind ) , qui devait être pour asimov l &apos; « ultime » sonde dans les subtilités des lois , utilise finalement les trois lois pour conjurer le scénario à la « frankenstein » que les hommes devaient résoudre . la nouvelle prend comme concept le développement grandissant des robots qui imitent les êtres vivants non humains , et sont par conséquent programmés pour agir selon les comportements de simples animaux qui ne nécessitent pas les trois lois . la présence d&apos; une large palette de vie robotique qui sert le même but que la vie organique se termine avec deux robots humanoïdes concluant que la vie organique est une condition non nécessaire pour une vraie logique et une définition cohérente par elle-même d &apos; « humanité » , que comme ils sont les êtres pensants les plus avancés sur leur planète , ils sont les seuls vrais humains en vie , et que les trois lois s&apos; appliquent seulement à eux-mêmes . l&apos; histoire se termine sur une note sinistre : les robots hibernent et attendent le moment où ils vont conquérir la terre et soumettre les humains biologiques s&apos; y trouvant , une conséquence qu&apos; ils considèrent comme le résultat inévitable des « trois lois de l&apos; humanique » . asimov arrive finalement à la conclusion qu&apos; il faut ajouter aux trois lois une « loi zéro » . le personnage robotique r. daneel olivaw est le premier à donner un nom à cette loi , dans le roman les robots et l&apos; empire ; cependant , susan calvin articule ce concept dans la nouvelle conflit évitable . dans les scènes finales du roman les robots et l&apos; empire , r. giskard reventlov est le premier robot à agir selon la loi zéro , cependant cela s&apos; avère destructeur pour son cerveau positronique , car il n&apos; est pas certain que son acte oriente l&apos; humanité vers son bien absolu ou non . giskard est télépathe , comme le robot herbie dans la nouvelle menteur ! , et il en vient à comprendre la loi zéro à travers sa compréhension d&apos; un concept plus subtil de la &quot; blessure &quot; que la plupart des robots peuvent saisir . cependant , à l&apos; inverse de herbie , giskard saisit le concept philosophique de la loi zéro , ce qui lui permet de blesser des êtres humains si cela peut en quoi que ce soit l&apos; aider dans son service du concept abstrait d&apos; humanité . la loi zéro n&apos; est jamais programmée dans le cerveau de giskard , c&apos; est en fait une règle qu&apos; il tente de rationaliser par pure réflexion métaphysique ; il échoue , et donne ses capacités télépathiques à son successeur , r. daneel olivaw . durant des milliers d&apos; années , daneel s&apos; adapte lui-même pour être capable d&apos; obéir pleinement à la loi zéro. un robot ne peut pas faire de mal à l&apos; humanité , ni , par son inaction , permettre que l&apos; humanité soit blessée. troisième loi : un robot doit protéger son existence tant que cette protection n&apos; entre pas en conflit avec la première ou la deuxième loi ou la loi zéro . le traducteur français jacques brécardasimov , isaac ( 1952 ) . the caves of steel . doubleday . , translated by jacques brécard as les cavernes d&apos; acier . j&apos; ai lu science-fiction . 1975 . template : isbn. incorpora le concept de loi zéro dans une des nouvelles d&apos; asimov avant même qu&apos; asimov lui-même ne l&apos; explicite . vers l&apos; apogée des cavernes d&apos; acier , elijah baley se fait un commentaire amer à lui-même , pensant que la première loi interdit à un robot de blesser un être humain , sauf si le robot en question est assez intelligent pour réaliser que ses actions sont faites pour le bien , à long terme , de l&apos; homme ( ce qui veut dire ici que dans les cavernes d&apos; acier les pensées de baley émergent dans une voie légèrement différente : « un robot ne doit faire aucun tort à un homme , à moins qu&apos; il trouve un moyen de prouver qu&apos; en fin de compte le tort qu&apos; il aura causé profite à l&apos; humanité en général ! » ) . les conséquences de la loi zéro sont considérables : elle donne le droit aux robots de s ’ attaquer à des hommes si ceux-ci mettent l ’ humanité en danger . c&apos; est justement le thème principal du film i , robot , où l&apos; i.a. viki ( mémoire centrale de la firme u.s. robots ) arrive à la conclusion logique que la plus grande menace pour l&apos; homme est l&apos; homme lui-même et décide d&apos; enfreindre la première loi pour protéger l&apos; humanité . cependant , dans les romans , même programmés avec la loi zéro , les robots ne tueront aucun humain , essayant toujours de trouver le moyen de l&apos; appliquer en intervenant le plus légèrement possible . les romans d&apos; asimov les cavernes d&apos; acier , face aux feux du soleil , les robots de l&apos; aube et les robots et l&apos; empire montrent que des robots trop basiques et surtout sans loi zéro finissent par avoir des effets néfastes sur l&apos; humanité ( et plus précisément sur les spaciens ) en empêchant toute forme de souffrance , la poussant ainsi à l&apos; inaction et étouffant toute pensée artistique . ainsi , la conclusion du roman les robots et l&apos; empire en particulier est que seuls des robots très intelligents pour pouvoir correctement appliquer la loi zéro ( en l&apos; occurrence r. daneel olivaw et r. giskard reventlov ) seront bénéfiques pour l&apos; humanité , car ils ont connaissance de toutes les subtilités de l&apos; esprit humain et du fait que tout n&apos; y est pas bon ou mauvais . ces robots peuvent comprendre des notions telles que le sacrifice ( dont le but est censé être positif ) ou la punition ( idem ) . cependant , le niveau de subtilité dans l&apos; interprétation de ces robots est sans doute tel qu&apos; ils ne pourront jamais être créés dans la réalité . dans ce cas , il faudra trouver un autre moyen de contourner les effets néfastes à long terme des trois lois . par trois fois dans sa carrière d&apos; écrivain de fiction , asimov a fait le portrait de robots qui négligeaient complètement le système de valeur des trois lois , à l&apos; inverse des robots daneel et giskard , qui avaient pour but de l&apos; augmenter . le premier cas , une histoire courte nommée première loi , est souvent considéré comme insignifiant , invraisemblable ou même apocryphe . d&apos; un autre côté , l&apos; histoire courte nommée cal ( intégrée dans gold ) , racontée à la première personne par un narrateur robotique , met en scène un robot qui néglige les lois parce qu&apos; il a trouvé quelque chose de bien plus important : il veut être écrivain . humoristique , en partie autobiographique , et dans un style expérimental inhabituel , cal a été vu comme une des histoires les plus fortes de gold . la troisième est une histoire courte dont le titre est sally , dans laquelle des voitures équipées de cerveaux positroniques sont apparemment capables de blesser et de tuer des humains , désobéissant à la première loi . cependant , mis à part le concept de cerveau positronique , cette histoire ne se réfère pas aux autres histoires de robots , et ne peut donc pas vraiment être incluse dans la même continuité . la nouvelle le robot qui rêvait , reprise dans le recueil de même titre , dépeint un robot , lvx-1 ou « elvex » , qui entre dans un état d&apos; inconscience et de rêve , dû à la structure fractale inhabituelle de son cerveau positronique . dans son rêve , les deux premières lois sont absentes , et la troisième loi dit : « un robot doit protéger sa propre existence » . la position d&apos; asimov sur la profondeur de l&apos; empreinte des lois évolua dans la chronologie de ses histoires : bien que dans ses premiers écrits elles n&apos; aient été que des garde-fous précautionneusement conçus , dans les histoires plus récentes asimov indiqua qu&apos; elles étaient une partie inaliénable de la fondation mathématique soutenant le cerveau positronique : sans la théorie de base des trois lois , les scientifiques fictifs de l&apos; univers d&apos; asimov seraient incapables de créer une unité cervicale &#91; informations douteuses &#93; &#91; ? &#93; viable . &#91; réf. souhaitée &#93; catégorie : article à référence souhaitée dans le petit robot perdu , susan calvin considère que modifier les lois est une idée terrible , mais faisable , tandis que , des siècles plus tard , le dr gerrigel , dans les cavernes d&apos; acier , croit que c&apos; est impossible . comme les personnages dans les histoires le font souvent remarquer , les lois telles qu&apos; elles existent dans l&apos; esprit d&apos; un robot ne correspondent pas à la version écrite , verbale , habituellement citée par les humains , mais sont des concepts mathématiques abstraits sur lesquels l&apos; entière conscience développante d&apos; un robot est basée . &#91; réf. souhaitée &#93; catégorie : article à référence souhaitée ainsi , les lois sont comparables aux instincts basiques de l&apos; homme sur la famille ou l&apos; accouplement , et sont conséquemment plus proches de former la base d&apos; une conscience propre d&apos; un robot — un sens dont le but est basé sur le service à l&apos; humanité , l&apos; obéissance aux ordres des hommes et l&apos; existence continue dans ce mode &#91; quoi ? &#93; — plus que des limitations arbitraires de l&apos; entourage d&apos; un esprit indépendant sans cela . &#91; réf. souhaitée &#93; catégorie : article à référence souhaitée ce concept est largement brouillé et peu clair dans les histoires les plus anciennes qui décrivent des robots très rudimentaires qui sont seulement programmés pour accomplir des tâches physiques sommaires , avec les lois implantées comme des protections , mais dans l&apos; ère des cavernes d&apos; acier , où l&apos; on voit des robots avec une intelligence de niveau humain , les trois lois sont devenues une vue éthique du monde sous-tendant les actions de tous les robots . les mouvances technophile et transhumaniste voient parfois les trois lois comme un idéal à venir . des avancées significatives en matière d&apos; intelligence artificielle seraient nécessaires pour que les robots obtiennent une intelligence . toutefois , la complexité des robots a augmenté et l&apos; avancée de la technologie suit une courbe exponentielle selon la singularité technologique . l&apos; humanité a donc intérêt à élaborer des directives et des garanties pour leur fonctionnementmoravec , hans . the age of robots , extro 1 , proceedings of the first extropy institute conference on transhumanist thought ( 1994 ) template : p. . june 1993 version . , template : article . roger clarke a écrit des analyses sur les complications dans l&apos; application de ces lois , dans l&apos; hypothèse que les systèmes soient un jour capables de les employer . il a fait valoir que les lois de la robotique d&apos; asimov ont été un procédé littéraire très réussi . peut-être ironiquement , ou peut-être parce que c&apos; était approprié dans le domaine artistique , la somme des récits d&apos; asimov réfutent eux-mêmes l&apos; affirmation avec laquelle il commence ces récits , c&apos; est pourquoi clarke conclut : « il n&apos; est pas possible de limiter de manière fiable le comportement des robots en concevant et en appliquant un ensemble de règles » clarke , roger . asimov&apos; s laws of robotics : implications for information technology , lois de la robotique d&apos; asimov : implications pour la technologie de l&apos; information . part 1 : ieee computer , décembre 1993 , &#91; &#91; : template : p. &#93; . &#93; part 2 : ieee computer , janvier 1994 , &#91; &#91; : template : p. &#93; . &#93; les deux pièces sont disponibles librement à l ’ template : lien brisé . enhancements to codes of ethics , améliorations des codes d ’ éthique . . en 2004 , l&apos; institut singularity a lancé une campagne internet appelée 3 lois dangereuses : 3 laws unsafe ( les 3 lois d&apos; asimov ) pour sensibiliser aux questions de la problématique de l&apos; intelligence artificielle et l&apos; insuffisance des lois d&apos; asimov en particuliersingularity institute for artificial intelligence ( 2004 ) , singularity institute for artificial intelligence , 3 laws unsafe sur template : lien brisé , récupéré le 2007-08-07 , sauvé sur web.archive.org. il convient de noter que l&apos; essai de sawyer néglige les questions de dommage involontaire ou inconscient , sujet traité dans des livres comme face aux feux du soleil . à noter que les trois lois ne sont pas applicables pour les robots militaires qui peuvent avoir pour objectif de tuer des personnes humaines . dans un tel cas , il est proposé que les robots puissent prendre des décisions éthiquesautonomous military robotics : risk , ethics and design . lin , bekey , abney , 2008 . . en mars 2007 , le gouvernement sud-coréen a annoncé que plus tard dans l&apos; année il émettrait une charte sur l&apos; éthique des robots , afin de fixer des normes pour les utilisateurs et les fabricants . selon park hye-young , du ministère de l&apos; information et de la communication , la charte reflète les trois lois d&apos; asimov : la tentative de définition des règles de base pour le développement futur de la robotiquetemplate : lien web . ( en ) frequently asked questions about isaac asimov , sur le site asimovonline.com ( consulté le 1er mars 2016 ) .
