le perceptron multicouche ( multilayer perceptron mlp ) est un classifieur linéaire de type réseau neuronal formel organisé en plusieurs couches au sein desquelles une information circule de la couche d&apos; entrée vers la couche de sortie uniquement ; il s&apos; agit donc d&apos; un réseau de type feedforward ( en ) catégorie : article contenant un appel à traduction en anglais . chaque couche est constituée d&apos; un nombre variable de neurones , les neurones de la couche de sortie correspondant toujours aux sorties du système . le perceptron a été inventé en 1957 par frank rosenblatt au cornell aeronautical laboratory , inspiré par la théorie cognitive de friedrich hayek et celle de donald hebb . dans cette première version le perceptron était alors mono-couche et n&apos; avait qu&apos; une seule sortie à laquelle toutes les entrées sont connectées . les premiers réseaux de neurones n&apos; étaient pas capable de résoudre des problèmes non linéaires ; cette limitation fut supprimée au travers de la rétropropagationrumelhart , d. e. , hinton , mcclelland , and williams , r. j. ( 1986 ) , ― learning internal representations by error propagation ‖ parallel distributed processing : explorations in the microstructure of cognition du gradient de l&apos; erreur dans les systèmes multicouches , proposé par paul werbos ( en ) catégorie : article contenant un appel à traduction en anglais en 1984 et mis au point deux années plus tard , en 1986 par david rumelhart ( en ) catégorie : article contenant un appel à traduction en anglais . dans le perceptron multicouche à rétropropagation , les neurones d&apos; une couche sont reliés à la totalité des neurones des couches adjacentes . ces liaisons sont soumises à un coefficient altérant l&apos; effet de l&apos; information sur le neurone de destination . ainsi , le poids de chacune de ces liaisons est l&apos; élément clef du fonctionnement du réseau : la mise en place d&apos; un perceptron multicouche pour résoudre un problème passe donc par la détermination des meilleurs poids applicables à chacune des connexions inter-neuronales . ici , cette détermination s&apos; effectue au travers d&apos; un algorithme de rétropropagation . présentation d&apos; un motif d&apos; entraînement au réseau . comparaison de la sortie du réseau avec la sortie ciblée . calcul de l&apos; erreur en sortie de chacun des neurones du réseau . calcul , pour chacun des neurones , de la valeur de sortie qui aurait été correcte . définition de l&apos; augmentation ou de la diminution nécessaire pour obtenir cette valeur ( erreur locale ) . ajustement du poids de chaque connexion vers l&apos; erreur locale la plus faible . attribution d&apos; un blâme à tous les neurones précédents . recommencer à partir de l&apos; étape 4 , sur les neurones précédents en utilisant le blâme comme erreur . marc parizeau , réseaux de neurones ( le perceptron multicouche et son algorithme de retropropagation des erreurs ) , université laval , laval , 2004 , 272 p.
