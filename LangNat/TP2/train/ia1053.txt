l&apos; algorithme espérance-maximisation ( en anglais expectation-maximization algorithm , souvent abrégé em ) , proposé par dempster et al. ( 1977 ) template : article , est un algorithme itératif qui permet de trouver les paramètres de vraisemblance maximum d&apos; un modèle probabiliste lorsque ce dernier dépend de variables latentes non observables . de nombreuses variantes ont par la suite été proposées , formant une classe entière d&apos; algorithmes . on utilise souvent l&apos; algorithme em pour la classification de données , l&apos; apprentissage automatique , ou la vision artificielle . on peut également citer son utilisation en imagerie médicale dans le cadre de la reconstruction tomographique. une étape de maximisation ( m ) , où l&apos; on estime le maximum de vraisemblance des paramètres en maximisant la vraisemblance trouvée à l&apos; étape e. on utilise ensuite les paramètres trouvés en m comme point de départ d&apos; une nouvelle phase d&apos; évaluation de l&apos; espérance , et l&apos; on itère ainsi . pour résoudre le problème d&apos; apprentissage des modèles de markov cachés ( hmm ) , c ’ est-à-dire la détermination des paramètres du modèle markovien , on utilise l&apos; algorithme de baum-welch . l ( \ mathbf { x } ; \ boldsymbol { \ theta } ) = \ sum _ { i = 1 } ^ n \ log f ( \ boldsymbol { x } _ i , \ boldsymbol { \ theta } ) . cet algorithme est particulièrement utile lorsque la maximisation de l est très complexe mais que , sous réserve de connaître certaines données judicieusement choisies , on peut très simplement déterminer \ boldsymbol { \ theta } . fait tendre l \ left ( \ mathbf { x } ; \ boldsymbol { \ theta } ^ { ( c + 1 ) } \ right ) vers un maximum local . en pratique , pour s&apos; affranchir du caractère local du maximum atteint , on fait tourner l&apos; algorithme em un grand nombre de fois à partir de valeurs initiales différentes de manière à avoir de plus grandes chances d&apos; atteindre le maximum global de vraisemblance . l ( x , \ phi ) = \ sum _ { i = 1 } ^ n \ log \ left ( \ sum _ { k = 1 } ^ g \ pi _ kf ( x _ i , \ theta _ k ) \ right ) . parallèlement , si on connaissait les groupes auxquels appartient chacun des individus , alors le problème serait un problème d&apos; estimation tout à fait simple et très classique . l ( x , z , \ phi ) = \ sum _ { i = 1 } ^ n \ sum _ { k = 1 } ^ gz _ { ik } \ log \ left ( \ pi _ kf ( x _ i , \ theta _ k ) \ right ) . avec m la matrice transposée de m et en supposant que les \ mu _ k sont des vecteurs colonnes . l&apos; algorithme em allie , dans la plupart des cas , simplicité de mise en œuvre et efficacité . néanmoins quelques cas problématiques ont donné lieu à des développements complémentaires . parmi les variantes existantes de cet algorithme nous évoquerons l&apos; algorithme gem ( generalized em ) qui permet de simplifier le problème de l&apos; étape maximisation ; l&apos; algorithme cem ( classification em ) permettant de prendre en compte l&apos; aspect classification lors de l&apos; estimation , ainsi que l&apos; algorithme sem ( stochastic em ) dont l&apos; objectif est de réduire le risque de tomber dans un optimum local de vraisemblance. de maximiser q à chaque étape mais qu&apos; une simple amélioration de q est suffisante . l&apos; algorithme em se positionne dans une optique estimation , c&apos; est-à-dire qu&apos; on cherche à maximiser la vraisemblance du paramètre \ theta \ , , sans considération de la classification faite a posteriori en utilisant la règle de bayes . lorsque les composantes du mélange appartiennent à la même famille exponentielle , en utilisant la bijection entre les divergences de bregman et les familles exponentielles , on obtient l&apos; algorithme k-mletemplate : article . afin de réduire le risque de tomber dans un maximum local de vraisemblance , celeux et diebolt ( 1985 ) template : article proposent d ’ intercaler une étape stochastique de classification entre les étapes e et m. après le calcul des probabilités t _ { ik } ^ { ( c ) } , l ’ appartenance z _ { ik } ^ { ( c ) } des individus aux classes est tirée aléatoirement selon une loi multinomiale de paramètres \ mathcal { m } \ left ( 1 , t _ { i1 } ^ { ( q ) } , \ dots , t _ { ig } ^ { ( q ) } \ right ) . contrairement à ce qui se produit dans l ’ algorithme cem , on ne peut considérer que l ’ algorithme a convergé lorsque les individus ne changent plus de classes . en effet , celles-ci étant tirées aléatoirement , la suite \ left ( z ^ { ( q ) } , \ theta ^ { ( q ) } \ right ) ne converge pas au sens strict . en pratique , celeux et diebolt ( 1985 ) proposent de lancer l ’ algorithme sem un nombre de fois donné puis d ’ utiliser l ’ algorithme cem pour obtenir une partition et une estimation du paramètre \ theta \ , .
