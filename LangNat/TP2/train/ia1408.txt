les moindres carrés non linéaires est une forme des moindres carrés spécialisée dans l&apos; estimation d&apos; un modèle non linéaire en n paramètres à partir de m observations ( m &gt; n ) . une façon d&apos; estimer ce genre de problème est de considérer des itérations successives se basant sur une version linéarisée du modèle initial. pour i = 1 , 2 , \ dots , m. \ frac { \ partial s } { \ partial \ beta _ j } = 2 \ sum _ i r _ i \ frac { \ partial r _ i } { \ partial \ beta _ j } = 0 \ ( j = 1 , \ ldots , n ) . \ boldsymbol { \ beta } ^ { k + 1 } = \ boldsymbol { \ beta } ^ k + \ delta \ boldsymbol { \ beta } . qui fournit des approximations successives \ boldsymbol { \ beta } ^ k de plus en plus proches de la vraie valeur ( inconnue ) des paramètres , \ boldsymbol { \ beta } _ 0. f ( x _ i , \ boldsymbol \ beta _ 0 ) \ approx f ( x _ i , \ boldsymbol \ beta ^ k ) + \ sum _ j \ frac { \ partial f ( x _ i , \ boldsymbol \ beta ^ k ) } { \ partial \ beta _ { 0 , j } } \ left ( \ beta _ { 0 , j } - \ beta ^ { k } _ j \ right ) \ approx f ( x _ i , \ boldsymbol \ beta ^ k ) + \ sum _ j j _ { ij } \ delta \ beta _ j. r _ i = \ delta y _ i- \ sum _ { j = 1 } ^ { n } j _ { ij } \ delta \ beta _ j ; \ \ delta y _ i = y _ i- f ( x _ i , \ boldsymbol \ beta ^ k ) . \ mathbf { \ left ( j ^ tj \ right ) \ delta \ boldsymbol \ beta = j ^ t \ delta } y. \ boldsymbol { \ beta } ^ { k + 1 } = \ boldsymbol { \ beta } ^ k + \ left ( \ mathbf { j ^ tj } \ right ) ^ { -1 } \ mathbf { j ^ t \ delta } y. il faut remarquer que l&apos; ensemble du terme de droite dépend seulement de l&apos; itération en cours , à savoir \ boldsymbol { \ beta } ^ k , et permet donc de trouver la prochaine itération \ boldsymbol { \ beta } ^ { k + 1 } . s = \ sum _ { i = 1 } ^ { m } w _ { ii } r _ i ^ 2 . dans ce cas , la matrice idéale de pondération devrait être égale à l&apos; inverse de la matrice de variance-covariance des observations. ce qui procure la base de l&apos; algorithme d&apos; optimisation de gauss-newton . pour les mcl , la solution est unique mais pas pour les mcn : plusieurs minima ( locaux ) peuvent exister . lorsqu&apos; il y a un seul paramètre à estimer β , la fonction s est une parabole en β . pour deux paramètres ou plus , le contour de s est constitué d&apos; ellipses concentriques , à condition que la matrice \ mathbf { x ^ twx } soit définie positive . le minimum , atteint pour la valeur optimale des paramètres , est le centre de ces ellipses concentriques . dans le cas non linéaire , le contour en ellipses concentriques n&apos; est vrai qu&apos; au voisinage du minimum , puisque dans ce cas l&apos; approximation linéaire de taylor s&apos; avère être une bonne approximation de la fonction objectif . plus les paramètres s&apos; éloignent de leur valeur optimale , plus le contour dévie de sa forme ellipsoïdale . ceci signifie qu&apos; il est essentiel de choisir l&apos; approximation initiale \ boldsymbol { \ beta } ^ 0 du procédé itératif proche des valeurs optimales , qui sont par définition inconnues . \ boldsymbol { \ beta } ^ { k + 1 } = \ boldsymbol { \ beta } ^ k + \ delta \ boldsymbol { \ beta } . si la direction de l&apos; incrément est trop éloigné de sa direction « optimale » et que la méthode précédente échoue , il faudra peut-être changer légèrement la direction du vecteur d&apos; incrément \ delta \ boldsymbol { \ beta } . pour cela , les équations normales sont transformées en \ mathbf { \ left ( j ^ twj + \ lambda i \ right ) \ delta \ boldsymbol \ beta = \ left ( j ^ tw \ right ) \ delta y } , où \ lambda est le paramètre de marquardtcette technique a été proposée indépendamment par levenberg ( 1944 ) , girard ( 1958 ) , wynne ( 1959 ) , morrison ( 1960 ) et marquardt ( 1963 ) . c&apos; est le nom de ce dernier que la littérature scientifique a généralement conservé. et i la matrice identité . on consultera avec profit la page consacrée à la méthode de levenberg-marquardt. où q est une matrice orthogonale m \ times m et où r est une matrice m \ times n , partitionnée en un bloc \ mathbf \ r _ n , de dimension n \ times n , et en un bloc nul , de dimension m-n \ times n zero block . de plus , \ mathbf \ r _ n est triangulaire supérieure . le vecteur de résidu est pré-multiplié par \ mathbf q ^ t. la résolution est facile d&apos; accès car la matrice r a été prise triangulaire supérieure . la relative simplicité de cette expression est très utile dans l&apos; analyse théorique des moindres carrés . cette méthode est largement détaillée dans lawson et hansonc.l. lawson and r.j. hanson , solving least squares problems , prentice-hall , 1974 . un paramètre intervient dans une fonction périodique , comme dans \ sin \ beta \ , . dans ce cas , \ hat \ beta + 2n \ pi donne la même valeur critère. il y a un minimum local en \ beta \ , = 1 et un minimum global en \ hat \ beta \ , = -3p . gans , data fitting in the chemical sciences , wiley , 1992 , template : p. . . pour être certain d&apos; avoir obtenu un minimum global , il est souhaitable de recommencer la procédure de minimisation en changeant le point de départ . quand on obtient le même résultat quel que soit le point de départ , on peut alors penser obtenir un minimum global . on utilise typiquement des points de départ aléatoires , par exemple déterminés par l&apos; algorithme de metropolis-hastings ; c&apos; est la méthode du recuit simulé . l&apos; existence de minimums multiples a une conséquence importante : la fonction objectif admet une valeur maximum quelque part entre les deux minimums . les équations normales en ce maximum fait intervenir des matrices non définies positives . une telle situation est à proscrire , en particulier comme initialisation du procédé itératif . par exemple , pour le cas de l&apos; ajustement du modèle de lorentz , le cas β = 0 est à éviter. on peut obtenir un modèle linéaire par transformation logarithmique . toutefois , si on n&apos; a aucun renseignement sur la structure des aléas , cette transformation peut être problématique : de toute évidence , les erreurs expérimentales sur y ne sont pas les mêmes que sur log y. estimer le modèle initial et celui linéarisé donnera des estimations différentes et des variances estimées . en pratique , le modèle exponentiel s&apos; estime dans une procédure à part . l&apos; inclusion des dérivées secondes dans le développement de taylor . on obtient la méthode classique de newton . la bibliothèque logicielle en c + + ceres solver a été spécifiquement conçue pour résoudre le problème des moindres carrés non linéairessameer agarwal , keir mierle et al. , ceres solver . . elle est utilisée dans divers produits google comme street viewtemplate : lien web . . mathieu rouaud , calcul d&apos; incertitudes régression polynomiale et non-linéaire avec ou sans barres d&apos; erreur .
