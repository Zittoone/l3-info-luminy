la mise en forme du texte ne suit pas les recommandations de wikipédia : il faut le « wikifier » . découvrez comment faire . la typographie , les liens internes ou externes , les conventions de style , la présentation des sources , etc. sont autant de points qui peuvent ne pas convenir voire être absents . si seules certaines sections de l&apos; article sont à wikifier , pensez à les indiquer en utilisant { { section à wikifier } } . ne doit pas être confondu avec pédagogie active . l ’ apprentissage actiftemplate : ouvrage , template : lien web est un modèle d ’ apprentissage semi-supervisé où un oracle intervient au cours du processus . plus précisément contrairement au cadre classique où les données sont connues et imposées , en apprentissage actif , c&apos; est l&apos; algorithme d&apos; apprentissage qui demande des informations pour des données précises . cette technique repose sur l&apos; hypothèse que l ’ acquisition de données non étiquetées est beaucoup moins coûteuse que celle de données étiquetées . elle repose également sur l ’ hypothèse que l ’ apprentissage est plus efficace lorsque l ’ on est “ curieux ” , en cherchant les données les plus intéressantes à étiqueter . l ’ apprentissage actif permet d&apos; effectuer diverses tâches classiques dans le domaine de l&apos; apprentissage automatique telles que la classification ou la régression . le principe de la technique est de trouver la requête la plus pertinente , pendant le processus d ’ apprentissage afin de maximiser le gain d ’ informations sur le problème . c ’ est pour cela que ce type d ’ apprentissage nécessite des interactions avec un oracle , humain ou non . contrairement à l ’ apprentissage passif , c ’ est l&apos; apprenant ( learner ) qui choisit les données à étiqueter par l ’ oracle . à cette fin , il existe plusieurs types de processus de construction ou de sélection de ces requêtes , qui sont détaillés dans les sections suivantes . en exemple , disons que l&apos; on peut disposer d&apos; un expert , un cancérologue de grande renommée ( l&apos; oracle ) , et donc très cher lorsque l&apos; on souhaite identifier si sur une radiographie il y a ou non présence de tumeur cancéreuse ( classification binaire , il y a une tumeur , ou non ) . dans cet exemple , la création d&apos; une base de données non étiquetées , un ensemble de radiographies , est beaucoup moins coûteuse que d ’ acquérir un ensemble de données étiquetés , via le diagnostic d&apos; un expert sur chaque donnée . l&apos; apprenant va donc réfléchir aux questions les plus intéressantes à poser , c&apos; est-à-dire sur les cas les plus ambiguës , afin de maximiser notre savoir sur ces radiographies tout en minimisant le coût ( le salaire du médecin ) . par rapport à l ’ apprentissage supervisé passif , l ’ apprentissage actif permet d ’ obtenir de bons résultats avec un ensemble de données étiquetées réduits . cependant , le cadre et le problème en lui-même influent sur les performances . il existe trois grands processus d&apos; apprentissage qui doivent être couplés à des stratégies de sélection de données à étiqueter . nous détaillerons d&apos; abord ces 3 processus , puis les stratégies communes de sélection . dans une dernière partie sera détaillé les limitations rencontrées dans l&apos; usage de telles méthodes . on définira ici un formalise utilisé le long de l&apos; article . les trois processus d ’ apprentissage principaux sont la synthèse de requête , la sélection sur un flux de données entrant et l ’ échantillonnage sur une base de données . cependant , celui-ci dépend du problème , des données et du contexte dans lequel il évolue . dans la suite de la section qui détaillera ces trois types de processus , on considérera qu ’ une requête est une demande d&apos; étiquetage par l ’ oracle d ’ une donnée non étiquetée . les premiers travaux en apprentissage actif se sont fait via la synthèse de requêtes : l ’ apprenant crée lui-même les requêtes sur les espaces les plus ambigus de l ’ espace des données . un exemple d&apos; un scénario simple peut être un problème de classification binaire avec des données mono-dimensionnelles réel , tel que le jeu du &quot; plus ou moins &quot; . cela revient à chercher la limite séparant les deux classes , qui correspond à un réel r \ in \ mathbb { r } . l&apos; apprenant va alors successivement créer des requêtes sur la limite actuel prédite afin d ’ affiner cette prédiction en suivant la réponse de l&apos; oracle . cependant , la génération de nouvelles données par l ’ apprenant donne parfois des résultats impossibles pour l ’ oracle à étiqueter , car dans l&apos; espace des données synthétisables , toutes les données ne sont pas forcément valide . par exemple , lang et baum template : article ont utilisé la synthèse de requête pour reconnaître des chiffres écrits à la main . mais le problème est que l ’ algorithme créait des symboles qui n ’ existait pas , car mélangeait plusieurs chiffres différents , et que l ’ on ne peut donc pas classifier . la seconde manière de procéder est d ’ utiliser des techniques issues de l&apos; apprentissage en ligne : il se fait sur des données qui arrivent de manière successive . dans le cas de l ’ apprentissage actif , l ’ apprenant décide , à chaque nouvelle donnée reçue si cette dernière nécessite d&apos; être étiquetée ou non . il existe plusieurs méthodes pour définir si une donnée mérite d ’ être étiquetée ou non en fonction de la connaissance que cela apporterai à l ’ apprenant ( détaillées plus tard ) . cette méthode permet de réduire l ’ espace mémoire consommé par l ’ apprentissage ( par exemple dans une application mobile ou embarquée , où l ’ espace mémoire est limité ) . par exemple , fujii et altemplate : article ont utilisé la sélection d ’ échantillon sur un flux ( en réalité sur une base , mais ils prennent les données une par une , ce qui revient à les prendre en flux ) afin de construire une base de données pour connaître le sens d ’ un verbe polysémique dans un contexte donné . en effet , annoter à la main un corpus entier de phrase est long et fastidieux pour un être humain . l&apos; apprentissage actif est donc utilisé pour sélectionner les “ meilleurs ” échantillons de ce corpus et en faire la base d ’ un autre algorithme qui donne le bon sens à un verbe dans son contexte en fonction de cette base . dans beaucoup de contextes d ’ apprentissage , on peut obtenir une base de données non étiquetées facilement . la tâche de l ’ apprenant est donc de déterminer quelle est la donnée à étiqueter qui rapporterait le plus d ’ informations afin d ’ améliorer la classification . comme dit dans la section précédente , il est simple de passer d&apos; une base de donnée à un flux . cependant , ceci dépend du problème étudié et de ce que l&apos; on veut faire . l&apos; avantage principale des méthodes hors ligne est la connaissance de l&apos; ensemble des données dès le début de l&apos; apprentissage et donc en théorie , améliore la décision de sélection des requêtes à étiqueteré . ceci peut avoir pour conséquence de converger vers une solution acceptable avec moins de requête . cette stratégie , introduite par lewis et galetemplate : article consiste à choisir simplement les données dont l ’ apprenant est le moins sûr ou a le plus de doute à quelle étiquette l ’ associer . dans un processus de flux , un seuil de confiance peut être utilisé afin de savoir si oui ou non la requête doit être effectuée . dans le cas d&apos; un problème de classification binaire , l ’ apprenant cherche les données pour lesquelles la probabilité a posteriori d&apos; appartenance aux deux classes est proche de 0.5 . cela signifie qu&apos; il a un fort doute sur quelle étiquette à attribuer à la donnée car les deux étiquettes ont des probabilités d&apos; appartenance semblable aux deux classes . il espère alors obtenir de nouvelles informations qui lui permettront de bien classifier ce type de données . ce système se base sur la classification automatique via une règle bayesienne . avec \ hat { y } l&apos; étiquette qui a le plus de probabilité d ’ être attribuer à la donnée x et \ theta le modèle courant . pour y remédier scheffer et al propose le ‘ “ margin sampling ” template : article qui au lieu de ne considérer que pour chaque donnée la classe la plus probable , utilise la marge entre cette dernière et la seconde classe la plus probable . de cette manière , l&apos; apprenant peut connaitre la taille de la marge de doute entre classifier la donnée dans la première classe ou dans la seconde . l&apos; apprenant est alors plus sûr pour les données avec de grandes marges , car il y a une grande différence de probabilité , et a plus de doutes sur les petites marges . cependant , comme pour la méthode précédente , l&apos; ensemble de la distribution des probabilités d&apos; appartenance aux classes n&apos; est pas prise en compte . prendre en considération l&apos; entropie permet d&apos; étendre la zone de doute . körner et altemplate : article dans l&apos; apprentissage actif pensent que l ’ échantillonnage avec marge devrait être la stratégie standard . cependant , les techniques doivent toujours être adaptées au problème étudié ( la tâche d&apos; apprentissage ) et au processus d&apos; apprentissage adopté . cette stratégie ( introduite pour la première fois par seug et altemplate : article ) consiste à mettre en place , entraîner et maintenir plusieurs modèles d&apos; apprenant . chaque modèle va voter sur une étiquette à attribuer à la donnée . les données les plus informatives sont donc celle pour qui le comité est le plus en désaccord . généralement , chacun des modèles est basé sur un échantillonnage incertain . deux points sont cruciaux dans cette méthode : la gestion des différents modèles du comité et la mesure du désaccord . initialiser les paramètres de manière aléatoire sur une distribution postérieure . partitionner les différentes dimensions de l&apos; espace des données . utiliser le principe du bagging ( bootstrap aggregating ( en ) catégorie : article contenant un appel à traduction en anglais ) , c&apos; est-à-dire échantillonner pour différents modèles d&apos; apprentissage les données d&apos; entrées , et d&apos; utiliser la moyenne de l&apos; hypothèse finale . utiliser le principe du boosting : prendre pour modèle des apprenants faibles . les deux dernières méthodes ont été proposées par naoki abe et al template : article . ces derniers affirment avoir pris les performances des requêtes grâce à ces techniques . elles leurs permettent également d&apos; utiliser des modèles déterministes . de plus , ces méthodes sont facilement utilisables puisqu&apos; elles utilisent plusieurs modèle en parallèle , donc le vote est naturellement utilisable . cependant il ne semble pas avoir de méthode idéale , ni un nombre optimal de membres à utiliser , car les résultats dépendent fortement de l&apos; application . avec c , la taille du comité et v \ left ( y _ i \ right ) le nombre de votes attribués à l&apos; étiquette y _ i. pour un problème de régression , on peut voir le désaccord comme une mesure de variance . une autre mesure de sélection est de choisir la donnée qui va le plus changer le modèle courant template : article . une mesure de changement peut être la norme du gradient pour les algorithmes utilisant un tel procédé . cependant , cette méthode a le désavantage d ’ être assez coûteuse à calculer , et d ’ être peu efficace si une des dimensions a une magnitude largement supérieure aux autres car le gradient aurait tendance à être surestimé pour des légères variations de cette dimension . une autre mesure peut être de réduire l&apos; erreur de généralisation template : article . pour cela , il faut prévoir l ’ erreur sur les données non étiquetées restantes . pour cela , il faut ré-entraîner le modèle , pour chaque étiquette possible , en faisant l ’ hypothèse que chaque donnée x lui appartienne . tout comme pour l ’ échantillonnage incertain , on peut prendre différentes fonctions de perte . avec u l&apos; ensemble des données restantes non étiquetées . mais cette méthode est très coûteuse car il est nécessaire de recalculer tous les modèles pour chaque couple possible de données non-étiquettes et étiquettes possibles . avec \ hat { \ sigma } la variance prédit . avec tr la trace d&apos; une matrice et \ mathcal { u } l&apos; ensemble des données non étiqueté restante . cette méthode part du principe où , parfois , il est plus intéressant de connaitre l&apos; étiquette d&apos; une donnée très représentative de la distribution sous-jacente . en effet , dans certain cas , apprendre l ’ étiquette de la donnée où l&apos; étiquetage est le moins sur , comme pour la stratégie de l&apos; échantillonnage incertain , n&apos; est pas forcément très instructif . typiquement , une donnée très marginale ne nous apprendra que très peu sur une région plus riche en données mais éloignée de celle-ci . le second terme pondère la quantité d&apos; information par sa similarité moyenne avec les autres données . il existe cependant d&apos; autres stratégies utilisant la densité pondérée . par exemple , mccallum et nigamtemplate : article ont développé une approche utilisant des requêtes par vote pour de la classification de textes . aussi , nguyen et smeulderstemplate : article ont proposé une approche basée sur la densité qui groupe d&apos; abord les instances et essaie d&apos; évider d&apos; interroger des données marginales en propageant les étiquettes aux instances d&apos; un même groupe . de plus , settles et craven ont montré que si la densité peut être pré-calculée efficacement et stockée , le temps de sélectionner la prochaine requête à effectuer est du même ordre que le temps de mesurer la quantité d&apos; information . cela devient alors avantageux pour réaliser de l&apos; apprentissage actif interactif avec des oracles en temps réel . l&apos; utilisation de l&apos; apprentissage actif peut se justifier par la motivation de vouloir apprendre à moindre coût . plusieurs problèmes pratiques peuvent alors se poser lorsque l&apos; on veut employer l&apos; apprentissage actif . il peut être intéressant d&apos; émettre plusieurs requêtes en même temps , soit parce qu&apos; il est préférable d ’ étiqueter des groupes de données en une seule fois , soit parce que plusieurs oracles sont disponibles . la problématique de sélection change donc : au lieu de choisir la donnée optimale x ^ * , il faut trouver l&apos; ensemble optimale \ mathcal { q } = \ left \ lbrace x _ 1 , x _ 2 , .... , x _ k \ right \ rbrace de données à étiqueter . choisir les k meilleurs x ^ * indépendamment ne marche pas forcément , car l&apos; information cumulée apportée n&apos; est pas optimale ( si les x ^ * meilleurs données sont situées dans la même région de l&apos; espace des données par exemple ) . plusieurs approches ont été tentées pour résoudre ce problème . des machine à vecteurs de support avec de la diversité ont été utilisées par brinker template : article . hoi et al. template : article ont étendu la réduction de la variance prévur , via l&apos; information de fisher , à un ensemble de requêtes . malgré l&apos; expertise des oracles employées , il se peut qu&apos; elles se trompent . surtout lorsque les étiquettes se basent sur des résultats empiriques ( expérimentation biologique , réaction chimie ... ) . pour reprendre l&apos; exemple de l&apos; introduction , notre cancérologue peut se tromper ( bruit sur l&apos; étiquette fournit ) lorsqu&apos; il diagnostique un cancer . une raison peut-être la qualité de la radio sur laquelle il se base par exemple . pour surmonter ce problème , sheng et al template : article ont montré que dans le cas d&apos; un étiquetage bruité , peu coûteux et avec plusieurs oracles , on peut augmenter la qualité des étiquetages et donc du modèle appris en demandant à étiquetée plusieurs fois la même données . cependant , notons que leurs résultats nécessitent des conditions d&apos; utilisation spécifique et ne peut s&apos; appliquer à tous les cas . le but de l&apos; apprentissage actif est de réduire le coût d&apos; apprentissage . parfois il ne suffit pas de réduire le nombre d&apos; étiquetage , car les différents étiquetages peuvent avoir un coût différent . les approches d&apos; apprentissage actif qui ne prennent pas compte les variations de coût d&apos; étiquetage lorsqu&apos; il y en a seraient aussi mauvais qu&apos; un apprentissage aléatoire . on peut approcher le coût de manière stochastique afin de prédire le coût d&apos; étiquetage et de choisir de demander l&apos; étiquetage de cette donnée ou non . la variation peut-être dû aux données et à ( aux ) oracle ( s ) . il faut préciser que ces résultats ont été trouvés sur des instances spécifiques .
