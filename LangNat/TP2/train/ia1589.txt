une superintelligence est un agent hypothétique qui posséderait une intelligence de loin supérieure à celle des humains les plus brillants et les plus doués . un système résolvant des problèmes ( comme un traducteur automatique ou un assistant à la conception ) est parfois aussi décrit comme « superintelligent » s&apos; il dépasse de loin les performances humaines correspondantes , même si cela ne concerne qu&apos; un domaine plus limité . s&apos; il existe des scénarios de création de superintelligence biologique , ou de superintelligence collective , la plupart des analyses se concentrent sur la possibilité qu&apos; une intelligence artificielle devienne capable de s&apos; améliorer elle-même , donnant naissance à la singularité technologique ; celle-ci est le sujet d&apos; espoirs ( le transhumanisme ) , mais aussi de craintes de catastrophe . de manière générale , on parle de superintelligence dès qu&apos; un agent dépasse de loin les performances humaines dans une activité intellectuelle . le philosophe nick bostrom définit une « superintelligence » comme « un intellect beaucoup plus compétent que les meilleurs cerveaux humains dans pratiquement tous les domaines , y compris la créativité scientifique , la sagesse et les talents sociaux . » template : article . pour cet auteur , des programmes de jeux de réflexion , tels que fritz ou alphago , bien que largement supérieurs aux humains , ne méritent ainsi pas d&apos; être considérés comme superintelligents , car ils ne sont compétents que pour une seule tâchetemplate : référence harvard sans parenthèses . . comme marcus hutter ( en ) catégorie : article contenant un appel à traduction en anglais avant lui , bostrom définit la superintelligence comme une supériorité générale dans les comportements ayant un objectif , laissant ouverte la question de capacités telles que l&apos; intentionnalitévoir l&apos; argument de la chambre chinoise. ou la perception des qualiavoir la question du problème difficile de la conscience . . les chercheurs sont en désaccord sur les chemins pouvant mener à une superintelligence . le scénario le plus souvent proposé envisage des progrès en intelligence artificielle ( ia ) , cependant d&apos; autres pensent que les humains évolueront ou modifieront leur biologie pour augmenter radicalement leurs possibilités intellectuelles . certaines analyses de futurologistes combinent des éléments de ces deux possibilités , suggérant que les humains pourraient se connecter directement à des ordinateurs , ou même y transférer leur esprit , de façon à permettre une amplification de leurs possibilités . certains chercheurs , comme david chalmerstemplate : référence harvard sans parenthèses . , pensent que la superintelligence apparaîtra rapidement après la création d&apos; une intelligence artificielle forte . les premières machines véritablement intelligentes auront immédiatement une énorme supériorité au moins sur certaines capacités intellectuelles , par exemple une mémoire absolue , une base de connaissance énorme , ou la capacité de mener plusieurs tâches simultanémenttemplate : ouvrage . plusieurs scientifiques considèrent l&apos; étude de ces possibilités comme prioritaire , en raison de leur impact social potentieltemplate : référence harvard sans parenthèses . . un logiciel suffisamment intelligent serait capable de se reprogrammer et de s&apos; améliorer , ce qui le rendrait encore plus capable de s&apos; améliorer , scénario connu sous le nom d&apos; explosion d&apos; intelligence ( en ) catégorie : article contenant un appel à traduction en anglais ; c&apos; est cette situation , proche du concept de singularité technologique , que de nombreux experts considèrent comme le chemin le plus plausible vers une superintelligence . une autre possibilité envisagée est la simulation du cerveau humain par des circuits électroniques , dont les performances sont typiquement de sept ordres de grandeur supérieures à celle des neuronestemplate : référence harvard sans parenthèses . . un système raisonnant comme un humain , mais des millions de fois plus rapidement , aurait évidemment un énorme avantage dans la plupart des tâches intellectuelles , en particulier celles demandant des décisions rapides , ou nécessitant de longues chaines de déductions couvrant de nombreux cas possibles . un autre avantage des circuits électroniques est leur modularité , permettant d&apos; accroitre presque sans limite leur taille et leur complexité . nick bostrom considère également que cela pourrait donner naissance à une « superintelligence collective » , si l&apos; on peut faire communiquer un nombre assez grand d&apos; agents déjà intelligents par eux-mêmes . on peut enfin espérer des améliorations qualitatives des raisonnements et des prises de décision humainstemplate : lien web . , template : référence harvard sans parenthèses . . carl sagan a suggéré que la généralisation des césariennes et de la fécondation in vitro pourrait permettre aux humains de développer de plus grands cerveaux , que la sélection naturelle pourrait ensuite conduire à une intelligence amélioréetemplate : ouvrage . . d&apos; un autre côté , gerald crabtree ( en ) catégorie : article contenant un appel à traduction en anglais craint au contraire que la diminution des pressions de sélection amène à un déclin de l&apos; intelligence humaine . il n&apos; y a pas de consensus à ce sujet , et dans tous les cas ces changements seraient lents , comparés à la vitesse des changements culturels . des méthodes eugéniques , et plus encore le génie génétique , pourraient améliorer l&apos; intelligence humaine plus rapidement . bostrom pense que si nous parvenons à comprendre les mécanismes génétiques de l&apos; intelligence , nous pourrons sélectionner des embryons ayant un haut potentiel intellectuel ; itérant ce processus sur de nombreuses générations , les gains pourraient être très importants . bostrom suggère de plus que le processus pourrait être énormément accéléré en travaillant directement sur les cellules souches embryonniarestemplate : référence harvard sans parenthèses . ; une organisation sociale convenable d&apos; humains ayant une intelligence exceptionnelle pourrait potentiellement développer une superintelligence collectivetemplate : référence harvard sans parenthèses . . les avantages mentionnés plus haut d&apos; une superintelligence artificielle sont cependant moins importants pour une superintelligence biologique , les contraintes physiologiques limitant la vitesse et la taille des cerveaux ; c&apos; est pourquoi les études ont plutôt porté sur des scénarios d&apos; intelligence artificielletemplate : référence harvard sans parenthèses . . un compromis intéressant pourrait être la création de cyborgs , associations symbiotiques de l&apos; homme et de la machine . cependant , bostrom exprime des doutes sur la faisabilité d&apos; une interface superintelligente , estimant qu&apos; il s&apos; agit d&apos; un problème aussi difficile que de créer une superintelligence artificielle puretemplate : référence harvard sans parenthèses . . la majorité des chercheurs en intelligence artificielle s&apos; attendent à ce que les machines soient un jour capable de rivaliser avec les humains sur le plan de l&apos; intelligence , bien qu&apos; il y ait peu de consensus sur la date à laquelle cela se produira . ainsi , à la conférence de 2006 de l&apos; ai @ 50 ( en ) catégorie : article contenant un appel à traduction en anglais , 18 % des participants s&apos; attendaient à ce que les machines « soient capable de simuler l&apos; apprentissage et les autres capacités intellectuelles humaines » d&apos; ici 2056 ; 41 % pensaient que cela se produirait , mais après 2056 , et 41 % pensaient que les machines n&apos; y arriveraient jamaistemplate : lien web . . en mai 2013 , une enquête auprès des cent auteurs les plus cités dans le domaine de l&apos; ia , 2070 était l&apos; année médiane pour laquelle était estimée , avec une confiance de 90 % , que des machines pourraient « exercer la plupart des professions humaines aussi bien qu&apos; un humain typique » ; avec une probabilité de 50 % , ils estimaient de même qu&apos; il faudrait ensuite 30 ans pour que se développe une superintelligencetemplate : référence harvard sans parenthèses . . valeurs extrapolées cohérentes ( vec ) : les valeurs sont celles sur lesquelles tous les humains s&apos; accordent . justesse morale ( jm ) : la valeur principale est la justice . permissivité morale ( pm ) : tout ce qui est moral est permis , en respectant les valeurs vec . ( en ) nick bostrom , « existential risks » , journal of evolution and technology , vol. 9 , ‎ &lt; time &gt; 2002 &lt; / time &gt; ( lire en ligne ) . ( en ) david chalmers , « the singularity : a philosophical analysis » , consc.net , vol. 17 , ‎ &lt; time &gt; 2010 &lt; / time &gt; , p. 7-65 ( lire en ligne ) . ( en ) bill hibbard , super-intelligent machines , kluwer academic / plenum publishers , &lt; time &gt; 2002 &lt; / time &gt; . ( en ) shane legg , « machine super intelligence » , department of informatics , university of lugano , ‎ &lt; time &gt; 2008 &lt; / time &gt; ( consulté le 19 septembre 2014 ) . ( en ) vincent c. müller et nick bostrom , fundamental issues of artificial intelligence , springer , &lt; time &gt; 2016 &lt; / time &gt; , 553-571 p. ( lire en ligne ) , chap. future progress in artificial intelligence : a survey of expert opinion . ( en ) christopher santos-lang , « our responsibility to manage evaluative diversity » , acm sigcas computers &amp; society , vol. 44 , no 2 , ‎ &lt; time &gt; 2014 &lt; / time &gt; , p. 16 – 19 ( doi 10.1145 / 2656870.2656874 , lire en ligne ) . ( en ) cet article est partiellement ou en totalité issu de l ’ article de wikipédia en anglais intitulé « superintelligence » ( voir la liste des auteurs ) .
