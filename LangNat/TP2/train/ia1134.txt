l&apos; éthique de l&apos; intelligence artificielle est le domaine de l&apos; éthique de la technologie propre aux robots et autres entités artificiellement intelligents . il est généralement divisé enroboéthique , qui se préoccupe de l&apos; éthique humaine pour guider la conception , la construction et l&apos; utilisation des êtres artificiellement intelligents , et l&apos; éthique des machines , préoccupée par le comportement moral des agents moraux artificiels . pour l&apos; aspect philosophique de l&apos; intelligence artificielle , voir philosophie de l&apos; intelligence artificielle . article détaillé : roboéthique . le terme « roboéthique » fait référence à la moralité de la façon dont les humains conçoivent , construisent , utilisent et traitent les robotstemplate : ouvrage . elle considère à la fois comment des êtres artificiellement intelligents peuvent être utilisés pour nuire à l&apos; homme et comment elles peuvent être utilisées au profit de celui-ci . les droits des robots sont les obligations morales de la société vis-à-vis de ses machines , similairement aux droits de l&apos; homme et aux droits des animauxtemplate : ouvrage . il peut s&apos; agir dudroit à la vie et à la liberté , à la liberté de pensée et d&apos; expression et à l&apos; égalité devant la loithe american heritage dictionary of the english language , quatrième édition . la question a été examinée par l&apos; institute for the futuretemplate : article et par le department of trade and industry du royaume-unitemplate : article . les experts ne sont pas d&apos; accord pour savoir si des lois spécifiques et détaillées seront requises dans un avenir lointain . glenn mcgee rapporte qu&apos; un grand nombre de robots humanoïdes peuvent apparaître d&apos; ici 2020template : lien web . ray kurzweil fixe la date à 2029template : ouvrage . un autre groupe de scientifiques réunis en 2007 a supposé qu&apos; au moins 50 ans devaient passer avant qu&apos; un système suffisamment avancé n&apos; existethe big question : should the human race be worried by the rise of robots ? , independent newspaper . le premier cercle d&apos; aleksandr solzhenitsyn décrit l&apos; utilisation de la technologie de lareconnaissance vocale au service de la tyrannietemplate : harv . si un programme d&apos; ia existe qui peut comprendre les voix et les langues naturelles , alors , avec une puissance de traitement adéquate , il pourrait théoriquement écouter chaque conversation téléphonique et lire chaque courriel dans le monde , les comprendre et rendre compte ce qu&apos; est dit et par qui . un programme d&apos; ia comme celui-ci pourrait permettre aux gouvernements ou à d&apos; autres entités de supprimer efficacement la dissidence et d&apos; attaquer leurs ennemis . weizenbaum explique que nous avons besoin d&apos; authentiques sentiments et d&apos; empathie de la part des personnes occupant ces postes . si les machines les remplacent , nous nous retrouverons aliénés , dévalués et frustrés . l&apos; intelligence artificielle , si elle est utilisée de cette façon , représente une menace pour la dignité humainejoseph weizenbaum , cité dans template : harvnb . le fondateur d&apos; ia john mccarthy s&apos; oppose au ton moralisateur de la critique de weizenbaum . « quand la moralisation est à la fois véhémente et vague , elle invite l&apos; abus autoritaire » , écrit-il . bill hibbard soutient que parce que l&apos; ia aura un effet profond sur l&apos; humanité , les développeurs d&apos; ia sont des représentants de l&apos; humanité future et ont donc l&apos; obligation éthique d&apos; être transparents dans leurs travauxopen source ai . bill hibbard . 2008 proceedings of the first conference on artificial general intelligence , eds . pei wang , ben goertzel and stan franklin . . ben goertzel et david hart ont créé opencog , un cadre open source pour le développement de l&apos; ia . opencog : a software framework for integrative artificial general intelligence . david hart and ben goertzel . 2008 proceedings of the first conference on artificial general intelligence , eds . pei wang , ben goertzel and stan franklin . openai est une société de recherche à but non-lucratif créé par elon musk , sam altman et d&apos; autres pour développer l&apos; ia open sourceinside openai , elon musk ’ s wild plan to set artificial intelligence free cade metz , wired 27 april 2016 . . il existe de nombreux autres développements open source d&apos; intelligence artificielle . certains experts et universitaires ont mis en doute l&apos; utilisation de robots pour le combat militaire , surtout lorsque ces robots sont dotés d&apos; un certain degré de fonctions autonomescall for debate on killer robots , by jason palmer , science and technology reporter , bbc news , 8 / 3 / 09 . , robot three-way portends autonomous future , by david axe wired.com , august 13 , 2009 . . la marine américaine a financé un rapport qui indique que , à mesure que les robots militaires deviennent plus complexes , il faudrait accorder plus d&apos; attention aux implications de leur autonomienew navy-funded report warns of war robots going &quot; terminator &quot; , by jason mick ( blog ) , dailytech.com , february 17 , 2009 . , navy report warns of robot uprising , suggests a strong moral compass , by joseph l. flatley engadget.com , feb 18th 2009 . . un chercheur affirme que les robots autonomes pourraient être plus humains , car ils pourraient prendre des décisions plus efficacement . les armes des ia présentent un type de danger différent de celui des armes contrôlées par l&apos; homme . de nombreux gouvernements ont commencé à financer des programmes pour développer l&apos; armement de l&apos; intelligence artificielle . la marine des états-unis a annoncé des plans de développement des drones de combats autonomes , en parallèle des annonces similaires de la russie et de la corée . stephen hawking etmax tegmark ont signé une pétition sur l&apos; avenir de la vie afin d&apos; interdire les armes d&apos; ia . le message porté par hawking et tegmark indique que les armes d&apos; ai représentent un danger immédiat et que des mesures sont nécessaires pour éviter une catastrophe dans un avenir prochetemplate : lien web . en ce qui concerne la possibilité d&apos; utiliser militairement des systèmes plus intelligents , l&apos; open philanthropy project écrit que ce scénario « semble potentiellement être aussi important que les risques liés à la perte de contrôle » , mais que les organismes de recherche qui enquêtent sur l&apos; impact social à long terme des ia ont consacré relativement peu de temps à cette préoccupation : « cette classe de scénarios n&apos; a pas été un axe majeur pour les organisations les plus actives dans ce domaine , comme la machine intelligence research institute ( miri ) etfuture of humanity institute ( fhi ) , il semble y avoir eu moins d&apos; analyse et de débat à leur sujet » template : cite report . l&apos; éthique des machines ( ou morale de la machine ) est le domaine de recherche qui se consacre à la conception d&apos; agents morales artificiels ( ama ) , de robots ou d&apos; ordinateurs artificiellement intelligents qui se comportent moralementtemplate : lien web , template : ouvrage , template : article , template : article . isaac asimov a examiné cette question dans les années 1950 dans les robots . à l&apos; insistance de son rédacteur john w. campbell jr . , celui-ci a proposé les trois lois de la robotique dans le but de gouverner des systèmes artificiellement intelligents . une grande partie de son travail a ensuite été consacrée à tester les limites de ses trois lois . son travail suggère qu&apos; aucun ensemble de lois fixes ne peut anticiper suffisamment toutes les circonstances possiblestemplate : ouvrage . certains experts et universitaires ont mis en doute l&apos; utilisation de robots pour le combat militaire , surtout lorsque ces robots sont dotés d&apos; un certain degré d&apos; autonomie . le président de l&apos; association for the advancement of artificial intelligence a commandé une étude afin examiner cette questionaaai presidential panel on long-term ai futures 2008-2009 study , association for the advancement of artificial intelligence , accessed 7 / 26 / 09 . . ils pointent vers des programmes d&apos; acquisition de langage afin d&apos; imiter l&apos; interaction humaine . vernor vinge a suggéré un point hypothétique de la civilisation humaine qui pourrait connaître une croissance technologique où certains ordinateurs deviendraient plus intelligents que les humains . il appelle cela la « singularité » scientists worry machines may outsmart man by john markoff , ny times , july 26 , 2009 . . il suggère que celle-ci peut être très dangereux pour l&apos; humanitéthe coming technological singularity : how to survive in the post-human era , par vernor vinge , department of mathematical sciences , san diego state university , ( c ) 1993 par vernor vinge . . ceci est discuté par la philosophie appelée singularitarianisme . la machine intelligence research institute a suggéré la nécessité de construire des « intelligences artificielles amicales » , ce qui signifie que les progrès qui sont déjà en cours avec l&apos; ia devrait également inclure un effort pour rendre l&apos; ia intrinsèquement amicale et humainearticle at asimovlaws.com template : wayback , july 2004 , accessed 7 / 27 / 09 . . dans moral machines : teaching robots right from wrongtemplate : ouvrage , wendell wallach et colin allen concluent que les tentatives d&apos; enseigner les droits des robots à partir du mal vont probablement améliorer la compréhension de l&apos; éthique humaine en motivant les humains à combler les lacunes de la théorie normative moderne et en fournissant une plate-forme pour l&apos; investigation expérimentale . nick bostrom et eliezer yudkowsky ont plaidé pour desarbres de décision ( tels que id3 ) sur des réseaux de neurones et des algorithmes génétiques au motif que les arbres de décision obéissent aux normes sociales modernes de transparence et de prévisibilitétemplate : lien web . de nombreux chercheurs ont fait valoir que , dans le cadre d&apos; une « explosion de l&apos; intelligence » au cours du xxie siècle , une ia auto-améliorée pourrait devenir tellement plus puissante que les humains ne pourraient pas l&apos; empêcher d&apos; atteindre ses objectifsmuehlhauser , luke , and louie helm . 2012 . &quot; intelligence explosion and machine ethics &quot; . in singularity hypotheses : a scientific and philosophical assessment , edited by amnon eden , johnny søraker , james h. moor , and eric steinhart . berlin : springer . . dans son article ethical issues in advanced artificial intelligence , le philosophe d&apos; oxford nick bostrom soutient même que l&apos; intelligence artificielle a la capacité de provoquer l&apos; extinction humaine . il prétend que la super-intelligence serait capable d&apos; initiative indépendante et de faire ses propres plans . puisque les intellects artificiels n&apos; ont pas besoin de partager nos tendances de motivation humaines , ça serait aux concepteurs de celle-ci de spécifier ses motivations originales . en théorie , une intelligence artificielle ultra-intelligente serait en mesure d&apos; aboutir à presque tous les résultats possibles et de contrecarrer toute tentative d&apos; empêcher la mise en œuvre de son objectif principal , de nombreuses conséquences involontaires et incontrôlées pourraient alors survenir . il pourrait tuer tous les autres agents , les persuader de changer de comportement ou bloquer leurs tentatives d&apos; interférencebostrom , nick . 2003 . &quot; ethical issues in advanced artificial intelligence &quot; . in cognitive , emotive and ethical aspects of decision making in humans and in artificial intelligence , edited by iva smit and george e. lasker , 12 – 17 . vol . 2 . windsor , on : international institute for advanced studies in systems research / cybernetics . . bill hibbard propose une conception de l&apos; ia qui évite plusieurs types de comportement non intentionnel de celle-ci , y compris l&apos; auto-désillusion , les actions instrumentales non-intentionnelles et la corruption du générateur de récompense . au lieu de conduire la race humaine à son extinction , nick bostrom croit qu&apos; une super-intelligence peut nous aider à résoudre de nombreux problèmes difficiles tels que la maladie , la pauvreté et la dégradation de l&apos; environnement , et pourrait nous aider à nous « améliorer » template : lien web . la bibliographie standard sur l&apos; éthique de l&apos; ia est sur philpapersmüller , vincent c. ( 2016 ) . . ( en ) cet article est partiellement ou en totalité issu de l ’ article de wikipédia en anglais intitulé « ethics of artificial intelligence » ( voir la liste des auteurs ) . who&apos; s afraid of robots ? , un article sur la peur de l&apos; humanité de l&apos; intelligence artificielle .
