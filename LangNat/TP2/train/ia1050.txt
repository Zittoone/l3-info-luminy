l&apos; algorithme du gradient désigne un algorithme d&apos; optimisation différentiable . il est par conséquent destiné à minimiser une fonction réelle différentiable définie sur un espace euclidien ( par exemple , \ r ^ n , l&apos; espace des n-uplets de nombres réels , muni d&apos; un produit scalaire ) ou , plus généralement , sur un espace hilbertien ( de dimension infinie ) . l&apos; algorithme est itératif et procède donc par améliorations successives . au point courant , un déplacement est effectué dans la direction opposée au gradient , de manière à faire décroître la fonction . le déplacement le long de cette direction est déterminé par la technique numérique connue sous le nom de recherche linéaire . cette description montre que l&apos; algorithme fait partie de la famille des algorithmes à directions de descente . les algorithmes d&apos; optimisation sont généralement écrits pour minimiser une fonction . si l&apos; on désire maximiser une fonction x \ mapsto f ( x ) , il suffira de minimiser son opposée x \ mapsto -f ( x ) . il est important de garder à l&apos; esprit le fait que le gradient , et donc la direction de déplacement , dépend du produit scalaire qui équipe l&apos; espace hilbertien ; l&apos; efficacité de l&apos; algorithme dépend donc de ce produit scalaire . l&apos; algorithme du gradient est également connu sous le nom d&apos; algorithme de la plus forte pente ou de la plus profonde descente ( steepest descent , en anglais ) parce que le gradient est la pente de la fonction linéarisée au point courant et est donc , localement , sa plus forte pente ( notion qui dépend du produit scalaire ) . dans sa version la plus simple , l&apos; algorithme ne permet de trouver ou d&apos; approcher qu&apos; un point stationnaire ( i.e. , un point en lequel le gradient de la fonction à minimiser est nul ) d&apos; un problème d&apos; optimisation sans contrainte . de tels points sont des minima globaux , si la fonction est convexe . des extensions sont connues pour les problèmes avec contraintes simples , par exemple des contraintes de borne . malgré des résultats de convergence théoriques satisfaisants , cet algorithme est généralement lent si le produit scalaire définissant le gradient ne varie pas avec le point courant de manière convenable , c&apos; est-à-dire si l&apos; espace vectoriel n&apos; est pas muni d&apos; une structure riemannienne appropriée , d&apos; ailleurs difficilement spécifiable a priori . il est donc franchement à déconseiller , même pour minimiser une fonction quadratique strictement convexe de deux variables . toutefois , ses qualités théoriques font que l&apos; algorithme sert de modèle à la famille des algorithmes à directions de descente ou de sauvegarde dans les algorithmes à régions de confiance . le principe de cet algorithme remonte au moins à cauchy ( 1847 ) template : article . algorithme du gradient — on se donne un point / itéré initial x _ 0 \ in \ mathbb { e } et un seuil de tolérance \ varepsilon \ geqslant 0 . l&apos; algorithme du gradient définit une suite d&apos; itérés x _ 1 , x _ 2 , \ ldots \ in \ mathbb { e } , jusqu&apos; à ce qu&apos; un test d&apos; arrêt soit satisfait . il passe de x _ k à x _ { k + 1 } par les étapes suivantes . en pratique , il faudra prendre \ varepsilon &gt; 0 ; la valeur nulle de cette tolérance a été admise uniquement pour simplifier l&apos; expression des résultats de convergence ci-dessous . grâce à la recherche linéaire , tant que f &apos; ( x _ k ) \ ne0 , l&apos; algorithme fait décroître la fonction strictement à chaque itération : f ( x _ { k + 1 } ) &lt; f ( x _ k ) . l&apos; algorithme du gradient peut s&apos; utiliser lorsque l&apos; espace vectoriel sur lequel est définie la fonction à minimiser est de dimension infiniek . ito , k. kunisch ( 2008 ) , lagrange multiplier approach to variational problems and applications , advances in design and control , siam publication , philadelphia . . dans ce cas , l&apos; algorithme n&apos; est pas implémentable , mais son étude peut avoir un intérêt pour connaître son comportement en grande dimension ou pour en utiliser les propriétés de convergence à des fins théoriques . l&apos; algorithme du gradient peut s&apos; interpréter comme la méthode d&apos; euler explicite de résolution de l&apos; équation différentielle ordinaire x &apos; ( \ alpha ) = - \ nabla f ( x ( \ alpha ) ) ( flot du gradient ) , avec un pas \ alpha _ k de discrétisation adapté à l&apos; itération k courante par la recherche linéaire . l&apos; évolution des itérés x _ k au cours de l&apos; algorithme est illustrée sur la figure de droite : f est une fonction convexe de deux variables ( définie sur le plan \ r ^ 2 ) et son graphe représente une forme de bol . chaque courbe bleue représente une courbe de niveau de f , un lieu de points en lesquels f vaut une constante donnée . chaque vecteur rouge représente un déplacement x _ { k + 1 } -x _ k , qui est orienté suivant l&apos; opposé de la direction du gradient en xk . ici , le gradient en xk est celui associé au produit scalaire euclidien , si bien qu&apos; il est orthogonal ( pour le produit scalaire euclidien ) à la tangente en xk à la courbe de niveau auquel xk appartient . la figure illustre la progression des itérés vers le fond du bol , c&apos; est-à-dire vers le point où la valeur de f est minimale . l&apos; algorithme du gradient peut rencontrer un certain nombre de problèmes , en particulier celui de la convergence lorsque le minimum de la fonction se trouve au fond d&apos; une vallée étroite ( plus précisément lorsque le conditionnement de la matrice hessienne est élevée ) . dans un tel cas , la suite des { xk } oscille de part et d&apos; autre de la vallée et progresse laborieusement , même lorsque les \ alpha _ k sont choisis de sorte à minimiser f ( b ) . la figure ci-dessous illustre ce type de comportement pour une fonction de rosenbrock à 2 dimensions . l&apos; algorithme peut nécessiter de nombreuses itérations pour converger vers un minimum local , notamment si la courbure est très différente dans des directions différentes . la recherche du pas \ alpha optimal , généralement effectuée par une recherche linéaire , peut se révéler très longue . inversement , utiliser un pas \ alpha fixe peut conduire à de mauvais résultats . des méthodes comme la méthode de newton et l&apos; inversion de la matrice hessienne en complément des techniques de gradient conjugué offrent souvent de meilleurs résultats . un algorithme plus efficace est la méthode bfgs , qui consiste à calculer en chaque étape une matrice , qui multipliée au gradient permet d&apos; obtenir une meilleure direction . de plus , cette méthode peut être combinée avec une méthode plus efficace de recherche linéaire afin d&apos; obtenir la meilleure valeur de \ alpha . l&apos; algorithme du gradient est mal défini pour minimiser des fonctions non lisses , même si elles sont convexes . lorsque le critère est localement lipschitzien , et spécialement s&apos; il est convexe , l&apos; algorithme des faisceaux ( en ) catégorie : article contenant un appel à traduction en anglais apporte un remède à l&apos; absence de convergencek . c. kiwiel ( 2001 ) . convergence and efficiency of subgradient methods for quasiconvex minimization . mathematical programming ( series a ) , 90 , 1-25 . ( en ) cet article est partiellement ou en totalité issu de l ’ article de wikipédia en anglais intitulé « gradient descent » ( voir la liste des auteurs ) . j. ch . gilbert , éléments d&apos; optimisation différentiable — théorie et algorithmes , syllabus de cours à l&apos; ensta paristech , paris . ( en ) mordecai avriel ( 2003 ) . nonlinear programming : analysis and methods . dover publishing . ( isbn 0-486-43227-0 ) .
