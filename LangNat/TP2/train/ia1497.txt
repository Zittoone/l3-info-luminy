en probabilité , un processus stochastique vérifie la propriété de markov si et seulement si la distribution conditionnelle de probabilité des états futurs , étant donnés les états passés et l&apos; état présent , ne dépend en fait que de l&apos; état présent et non pas des états passés ( absence de « mémoire » ) . un processus qui possède cette propriété est appelé processus de markov . pour de tels processus , la meilleure prévision qu&apos; on puisse faire du futur , connaissant le passé et le présent , est identique à la meilleure prévision qu&apos; on puisse faire du futur , connaissant uniquement le présent : si on connait le présent , la connaissance du passé n&apos; apporte pas d&apos; information supplémentaire utile pour la prédiction du futur . pour tout \ scriptstyle \ n \ ge 0 , \ pour toute suite d&apos; états \ scriptstyle \ ( i _ 0 , \ ldots , i _ { n-1 } , i , j ) \ in e ^ { n + 2 } , \ \ begin { align } \ mathbb { p } \ big ( x _ { n + 1 } = j &amp; \ mid \ , x _ 0 = i _ 0 , x _ 1 = i _ 1 , \ ldots , x _ { n-1 } = i _ { n-1 } , x _ n = i \ big ) &amp; = \ mathbb { p } \ left ( x _ { n + 1 } = j \ mid x _ n = i \ right ) . \ mathbb { p } \ big ( x _ { n + 1 } = j \ mid \ , x _ 0 = i _ 0 , x _ 1 = i _ 1 , \ ldots , x _ { n-1 } = i _ { n-1 } , x _ n = i \ big ) = \ mathbb { p } \ left ( x _ { 1 } = j \ mid x _ 0 = i \ right ) . \ forall n \ ge 0 , \ forall ( i , j ) \ in e ^ { 2 } , \ qquad \ mathbb { p } \ left ( x _ { n + 1 } = j \ mid x _ n = i \ right ) = \ mathbb { p } \ left ( x _ { 1 } = j \ mid x _ 0 = i \ right ) . dans la suite de l&apos; article on ne considèrera que des chaînes de markov homogènes . pour une application intéressante des chaînes de markov non homogènes à l&apos; optimisation combinatoire , voir l&apos; article recuit simulé . notons que les évènements passés \ scriptstyle \ \ { ( x _ 0 , \ dots , x _ { n } ) \ in a \ } \ et futurs \ scriptstyle \ \ { ( x _ { n } , x _ { n + 1 } , \ dots ) \ in b \ } \ prennent ici la forme la plus générale possible , alors que l&apos; évènement présent \ scriptstyle \ \ { x _ n = i \ } \ reste sous une forme particulière , et pas par hasard : si on remplace \ scriptstyle \ \ { x _ n = i \ } \ par \ scriptstyle \ \ { x _ n \ in c \ } \ dans l&apos; énoncé ci-dessus , alors l&apos; énoncé devient faux en général , car l&apos; information sur le passé devient utile pour prévoir le présent ( où \ scriptstyle \ x _ n \ peut-il bien se trouver , plus précisément , à l&apos; intérieur de la partie \ scriptstyle \ c \ ? ) , et , partant de là , pour prévoir le futur . ainsi , du fait d&apos; une connaissance imprécise ( \ scriptstyle \ \ { x _ n \ in \ { 0,1 \ } \ } \ ) du présent , certaines informations concernant le passé permettent d&apos; améliorer le pronostic : sachant que xn-1 = 0 , on en déduit que xn n&apos; est pas nul , donc que xn est égal à 1 , puis on conclut que xn + 1 ne peut être égal à 1 . par contre , sans l&apos; information xn-1 = 0 , on ne peut exclure que xn + 1 soit égal à 1 . pourtant , la marche aléatoire sur \ scriptstyle \ \ mathbb { z } \ est une chaîne de markov , et possède bien la propriété de markov . il n&apos; y a pas de contradiction , ici : la propriété de markov stipule que , lorsque l&apos; on a une connaissance précise ( xn = i ) du présent , aucune information concernant le passé ne permet d&apos; améliorer le pronostic . il existe une propriété de markov forte , liée à la notion de temps d&apos; arrêt : cette propriété de markov forte est cruciale pour la démonstration de résultats importants ( divers critères de récurrence , loi forte des grands nombres pour les chaînes de markov ) . et supposons que la suite \ scriptstyle \ y \ est indépendante de \ scriptstyle \ x _ 0 . \ alors \ scriptstyle \ x \ est une chaîne de markov homogène. où les variables aléatoires \ scriptstyle \ y _ { n } \ sont des variables aléatoires indépendantes et uniformes sur \ scriptstyle \ &#91; \ ! &#91; 1,11 &#93; \ ! &#93; \ : ce sont les numéros successifs des vignettes tirées des tablettes de chocolat . le temps moyen nécessaire pour compléter la collection ( ici le nombre de tablettes que petit pierre doit acheter en moyenne pour compléter sa collec &apos; ) est , pour une collection de \ scriptstyle \ n \ vignettes au total , de \ scriptstyle \ n \ , h _ n , \ où \ scriptstyle \ h _ n \ est le \ scriptstyle \ n \ -ème nombre harmonique . par exemple , \ scriptstyle \ 11 \ , h _ { 11 } = 33,2 \ dots \ quad tablettes de chocolat . \ forall n \ in \ mathbb n , \ quad \ { t \ le n \ } \ in \ mathcal { f } _ n. \ { t = n \ } \ quad \ leftrightarrow \ quad \ left \ { ( x _ 0 , x _ 1 , \ dots , x _ n ) \ in b _ n \ right \ } . cela interdit au joueur de prendre sa décision en fonction des résultats des parties futures : cela revient à faire l&apos; hypothèse que tricherie et don de double vue sont exclus . article détaillé : temps d&apos; arrêt . \ right . \ right. ou encore l&apos; instant de \ scriptstyle \ k-ème entrée dans \ scriptstyle \ c , \ sont des t.a .. contrexemple : pour \ scriptstyle \ i \ et \ scriptstyle \ j \ dans \ scriptstyle \ e , \ on pose \ scriptstyle \ t = \ inf \ left \ { n \ ge 0 \ , \ vert \ , x _ n = i \ text { et } x _ { n + 1 } = j \ right \ } . \ on peut montrer que \ scriptstyle \ t \ n&apos; est pas un temps d&apos; arrêt , mais que , par contre , \ scriptstyle \ t + 1 \ est un temps d&apos; arrêt . \ forall n \ in \ mathbb n , \ qquad \ a \ cap ( t = n ) \ in \ mathcal { f } _ n. l&apos; ensemble des évènements antérieurs à \ scriptstyle \ t \ , forme une sous-tribu de \ scriptstyle \ \ mathcal { a } appelée tribu antérieure à \ scriptstyle \ t \ , et notée \ scriptstyle \ \ mathcal { f } _ t. \ { t = n \ } \ quad \ leftrightarrow \ quad \ left \ { ( x _ 0 , x _ 1 , \ dots , x _ n ) \ in b _ n \ right \ } . \ left \ { a \ cap \ { t = n \ } \ right \ } \ quad \ leftrightarrow \ quad \ left \ { ( x _ 0 , x _ 1 , \ dots , x _ n ) \ in d _ n \ right \ } . \ infty \ text { et } x _ t = i \ right ) . \ infty \ text { et } x _ t = i \ right ) . { \ mathbb p } _ { \ mu } \ big ( x _ t = i \ big ) = 1 . ainsi les conditions apparaissant dans la propriété de markov forte sont presque certaines . &amp; = { \ mathbb p } _ i \ left ( \ left ( x _ { n } \ right ) _ { n \ ge 0 } \ in b \ right ) { \ mathbb p } _ { \ mu } \ left ( a \ right ) . pour tout k , il y a donc indépendance ( inconditionnelle ) entre les évènements qui précèdent le k-ème passage en \ scriptstyle \ i \ et les évènements qui suivent le k-ème passage en \ scriptstyle \ i. \ qui plus est , la trajectoire de la chaîne de markov après le k-ème passage en \ scriptstyle \ i , \ ( x _ { t + n } ) _ { n \ ge 0 } , \ a même loi que la trajectoire d&apos; une chaîne de markov partant de \ scriptstyle \ i \ à l&apos; instant 0 : elle redémarre comme neuve , indépendamment de ce qui a pu se passer auparavant . on dit alors que les temps de retour successifs sont des instants de renouvellement ou bien des instants de régénération . les morceaux de trajectoires entre deux régénérations consécutives forment alors une suite de variables aléatoires i.i.d. ( sauf le premier morceau , indépendant , mais éventuellement de loi différente , si la chaîne de markov ne part pas de \ scriptstyle \ i \ à l&apos; instant 0 ) . cela conduit à une démonstration de la loi forte des grands nombres pour les chaînes de markov déduite de la loi forte des grands nombres pour les v.a.r. i.i.d. . cela donne également une méthode pour construire des intervalles de confiance pour les paramètres intéressants de la chaîne de markov . y ( t ) = \ big \ { x ( s ) : s \ in &#91; a ( t ) , b ( t ) &#93; \ , \ big \ } . si y est markovien , alors c&apos; est la représentation markovienne de x et x qui est alors appelée processus de markov du second ordre . les processus d&apos; ordre supérieur sont définis de la même manière . elle se transforme en une équation aux dérivées partielles , plus facile à manipuler , qui prend le nom d&apos; équation de fokker-planck . norris , j. : markov chains .
