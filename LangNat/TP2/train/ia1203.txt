fonction et données bruitées. spread = 5spread = 1spread = 0.1une fonction ( rouge ) est estimée à l&apos; aide de fonctions de base radiales ( rbf ) ( en bleu ) . plusieurs essais sont présentés dans chaque graphique . pour chaque essai , quelques points de données bruitées sont fournis comme ensemble d&apos; apprentissage ( en haut ) . pour une forte valeur du paramètre d&apos; envergure ( spread ) ( image 2 ) , le biais est élevé : les rbfs ne peuvent pleinement approximer la fonction ( en particulier le creux central ) , mais la variance entre les différents essais est faible . lorsque le paramètre d&apos; envergure diminue ( image 3 et 4 ) , le biais diminue : les courbes bleues se rapprochent davantage de la courbe rouge . cependant , en fonction du bruit dans les différents essais , la variance entre les essais augmente . dans l&apos; image du bas , les approximations pour x = 0 varient énormément selon l&apos; endroit où se trouvaient les points de données . le biais est l&apos; erreur provenant d ’ hypothèses erronées dans l&apos; algorithme apprentissage . un biais élevé peut être lié à un algorithme qui manque de relations pertinentes entre les données en entrée et les sorties prévues ( sous-apprentissage ) . la variance est l&apos; erreur dû à la sensibilité aux petites fluctuations de l ’ échantillon d&apos; apprentissage . une variance élevée peut entraîner un sur-apprentissage , c&apos; est-à-dire modéliser le bruit aléatoire des données d&apos; apprentissage plutôt que les sorties prévues . la décomposition biais-variance est une façon d&apos; analyser l&apos; espérance de l&apos; erreur de prédiction d&apos; un algorithme d&apos; apprentissage d&apos; un problème particulier comme une somme de trois termes : le biais , la variance et une quantité , appelée erreur irréductible , résultant du bruit dans le problème lui-même . ce compromis s&apos; applique à toutes les formes d&apos; apprentissage supervisé : classification , régression ( fonction de montage ) geman , stuart ; e. bienenstock ; r. doursat ( 1992 ) . , bias – variance decomposition , in encyclopedia of machine learning . , et le structured ( output ) learning ( en ) catégorie : article contenant un appel à traduction en anglais . il a également été invoqué pour expliquer l&apos; efficacité des heuristiques dans l&apos; apprentissage humain . le compromis biais-variance est un problème central en apprentissage supervisé . idéalement , on veut choisir un modèle qui reflète avec précision les régularités dans les données d&apos; apprentissage , mais qui se généralise aussi aux données tests ( données n&apos; ayant pas servi à apprendre le modèle ) . malheureusement , il est généralement impossible de faire les deux en même temps . les méthodes d&apos; apprentissage avec une variance élevée peuvent assez bien représenter l ’ échantillon d ’ apprentissage , mais il existe un risque de sur-apprentissage sur des données tests ou bruitées . en revanche , les algorithmes avec un biais élevé produisent généralement des modèles plus simples qui n&apos; ont pas tendance au sur-apprentissage , mais peuvent être en sous-apprentissage sur le jeu de données d&apos; apprentissage . les modèles avec un faible biais sont généralement plus complexes ( par exemple la régression polynomiale à plusieurs degrés ) , mais permettent de représenter les données d ’ apprentissage avec plus de précision . cependant , ils peuvent également représenter une partie du bruit aléatoire du jeu d&apos; apprentissage , leurs prédictions sont donc moins précises malgré la complexité supplémentaire . en revanche , les modèles avec un biais plus élevé ont tendance à être relativement simple ( régression polynomiale à moindre degré ou même linéaire ) , mais peuvent produire des prédictions de variance plus faible lorsqu&apos; ils sont appliqués au-delà de l&apos; ensemble d&apos; apprentissage . supposons que nous avons un ensemble d&apos; apprentissage constitué d&apos; un ensemble de points x _ 1 , \ dots , x _ n et de valeurs réelles y _ i associée à chaque point x _ i. nous supposons qu&apos; il existe une relation fonctionnelle bruitée y _ i = f ( x _ i ) + \ epsilon , où le bruit , \ epsilon , a une moyenne nulle et une variance \ sigma ^ 2 . cependant , la complexité va rendre le modèle &quot; mobile &quot; pour s&apos; adapter aux données , et donc sa variance sera plus grande . la démonstration de la décomposition biais-variance pour erreur quadratique se déroule comme suitvijayakumar , sethu ( 2007 ) . , shakhnarovich , greg ( 2011 ) . . y = f + \ epsilon et \ mathrm { e } &#91; \ epsilon &#93; = 0 , implique \ mathrm { e } &#91; y &#93; = \ mathrm { e } &#91; f + \ epsilon &#93; = \ mathrm { e } &#91; f &#93; = f. domingos , pedro ( 2000 ) . , valentini , giorgio ; dietterich , thomas g. ( 2004 ) . . sinon , si le problème de la classification peut être formulé comme classification probabiliste , alors l&apos; erreur quadratique attendue des probabilités prédites par rapport aux véritables probabilités peut être décomposée comme précédemmentmanning , christopher d. ; raghavan , prabhakar ; schütze , hinrich ( 2008 ) . . de même , un plus grand ensemble d&apos; apprentissage tend à diminuer la variance . l&apos; ajout de variables explicatives ( features ) tend à diminuer le biais , au détriment de l&apos; introduction de variance supplémentaire . les modèles linéaires généralisés peuvent être régularisés afin d&apos; en diminuer la variance mais au prix de l&apos; augmentation du biaisbelsley , david ( 1991 ) . . avec les réseaux de neurones , la variance augmente et le biais diminue avec le nombre de couches cachées . comme dans le modèle linéaire généralisé , une régularisation est généralement appliquée . avec la méthode des k plus proches voisins , une valeur élevée de k conduit à un biais élevé et une variance faible ( voir ci-dessous ) . avec la méthode d&apos; instance-based learning ( en ) catégorie : article contenant un appel à traduction en anglais , la régularisation peut être obtenue en variant le mélange de prototypes et modèlesgagliardi , f ( 2011 ) . . une façon de résoudre le compromis consiste à utiliser des modèles mixte et de l&apos; ensemble learning ( en ) catégorie : article contenant un appel à traduction en anglaisjo-anne ting , sethu vijaykumar , stefan schaal , locally weighted regression for control . , scott fortmann-roe . . par exemple , le boosting combine plusieurs &quot; mauvais &quot; modèles ( biais élevé ) dans un ensemble qui a un biais plus faible que les modèles individuels , tandis que le bagging combine les &quot; meilleurs &quot; classifieurs d&apos; une manière qui réduit leur variance. où n _ 1 ( x ) , \ dots , n _ k ( x ) sont les k plus proches voisins de x dans l ’ échantillon d&apos; apprentissage . le biais ( premier terme de l ’ équation ) est une fonction monotone croissante de k , alors que la variance ( second terme ) diminue lorsque k augmente . en effet , avec des &quot; hypothèses raisonnables &quot; , le biais de l&apos; estimateur du plus proche voisin ( 1-nn ) disparaît entièrement lorsque la taille de l ’ échantillon d&apos; apprentissage tend vers l&apos; infini . bien que largement discuté dans le contexte de l&apos; apprentissage automatique , le dilemme biais-variance a été examiné dans le contexte des sciences cognitives , et plus particulièrement par gerd gigerenzer et ses co-auteurs dans le contexte de l&apos; apprentissage heuristique . ils soutiennent que le cerveau humain résout ce dilemme dans le cas des généralement parcimonieux sur des ensembles mal caractérisés fournies par une expérience en adoptant une heuristique biais élevé / faible variance . cela reflète le fait qu&apos; une approche non biaisée se généralise mal à de nouvelles situations , et suppose aussi déraisonnablement une connaissance précise de la réalité . les heuristiques en résultant sont relativement simples , mais produisent de meilleures inférences dans une plus grande variété de situationsgigerenzer , gerd ; brighton , henry ( 2009 ) . . gelman et al. soutiennent que le dilemme biais-variance implique que les capacités telles que la reconnaissance d&apos; objet générique ne peuvent être apprises à partir de zéro , mais nécessitent un certain degré d&apos; inné qui est ensuite réglée par l&apos; expérience . ceci car les approches sans modèle d&apos; inférence nécessitent des ensembles d&apos; apprentissage démesurément grands si l&apos; on veut éviter une forte variance . ( en ) cet article est partiellement ou en totalité issu de l ’ article de wikipédia en anglais intitulé « bias – variance tradeoff » ( voir la liste des auteurs ) . ( en ) cet article est partiellement ou en totalité issu de l ’ article de wikipédia en anglais intitulé « bias – variance _ tradeoff » ( voir la liste des auteurs ) .
