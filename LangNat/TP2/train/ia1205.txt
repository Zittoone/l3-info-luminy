vous pouvez partager vos connaissances en l ’ améliorant ( comment ? ) selon les recommandations des projets correspondants . améliorez-le , ou discuter des points à vérifier . si vous venez d&apos; apposer le bandeau , merci d&apos; indiquer ici les points à vérifier . dans la théorie de l&apos; apprentissage automatique , la dimension vc ( pour dimension de vapnik-chervonenkis ) est une mesure de la capacité d&apos; un algorithme de classification statistique . elle est définie comme le cardinal du plus grand ensemble de points que l&apos; algorithme peut pulvériser . c&apos; est un concept central dans la théorie de vapnik-chervonenkis . il a été défini par vladimir vapnik et alexey chervonenkis . de manière informelle , la capacité d&apos; un modèle de classification correspond à sa complexité . par exemple , considérons comme modèle de classification la fonction de heaviside d&apos; un polynôme de degré élevé : si en un point donné la valeur du polynôme est positive , ce point est étiqueté positif ; sinon , il est étiqueté négatif . un polynôme de degré assez grand peut être très sinueux et bien correspondre à un échantillon de points d&apos; apprentissage . mais du fait de cette sinuosité élevée , on peut penser que ce modèle de classification donnera des évaluations fausses pour d&apos; autres points . un tel polynôme aura une capacité élevée . si maintenant , nous remplaçons dans ce modèle ce polynôme de degré élevé par une fonction linéaire , le modèle obtenu peut ne pas bien correspondre à l&apos; échantillon d&apos; apprentissage , car sa capacité est faible . nous décrivons cette notion de capacité de manière plus rigoureuse ci-dessous . la dimension vc de h est alors le cardinal de l&apos; ensemble c le plus grand qui peut être pulvérisé par h. on dit qu&apos; un modèle de classification f , prenant comme paramètre un vecteur θ , pulvérise un ensemble de données ( x _ 1 , x _ 2 , \ ldots , x _ n ) si , pour tout étiquetage de cet ensemble de données , il existe un θ tel que le modèle f ne fasse aucune erreur dans l&apos; évaluation de cet ensemble de données . on appellera alors dimension vc d&apos; un modèle f le cardinal du plus grand ensemble pulvérisé par f. par exemple , prenons comme modèle de classification une droite . on étudie si la ligne peut séparer les données positives ( + ) des données négatives ( - ) . si on prend 3 points non alignés , la ligne peut les pulvériser . cependant , la ligne ne peut pas pulvériser 4 points . ainsi , la dimension vc de la droite est de 3 . il est important de se rappeler qu&apos; on peut choisir les positions des points qu&apos; on va pulvériser avec la droite , mais qu&apos; on ne peut pas ensuite modifier ces positions lorsqu&apos; on permute leur étiquetage . ci-dessous , pour la pulvérisation de 3 points , on montre seulement 3 des 8 étiquetages possibles ( 1 seule possibilité de les étiqueter tous les 3 positifs , 3 possibilités d&apos; en étiqueter 2 sur 3 positifs , 3 possibilités d&apos; en étiqueter 1 sur 3 positif , 1 possibilité de n&apos; en étiqueter aucun positif ) . la dimension vc est utilisée en théorie de l&apos; apprentissage automatique pour calculer la valeur de la marge d&apos; erreur probable maximum d&apos; un test de modèle de classification. avec la probabilité de 1- \ eta , où h est la dimension vc du modèle de classification , et n la taille de l&apos; échantillon d&apos; apprentissage . cette formule n&apos; est valide que lorsque h &lt; n. ( en ) cet article est partiellement ou en totalité issu de l ’ article de wikipédia en anglais intitulé « vc dimension » ( voir la liste des auteurs ) . ( en ) v. vapnik et a. chervonenkis . on the uniform convergence of relative frequencies of events to their probabilities . ( de la convergence uniforme des fréquences relatives des événements vers leur probabilité ) theory of probability and its applications ( théorie de la probabilité et ses applications ) , 16 ( 2 ) : 264--280 , 1971 . ( en ) a. blumer , a. ehrenfeucht , d. haussler , et m. k. warmuth . learnability and the vapnik-chervonenkis dimension . ( capacité d&apos; apprentissage et dimension de vapnik-chervonenkis ) journal of the acm , 36 ( 4 ) : 929--865 , 1989 .
