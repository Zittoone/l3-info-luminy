vous pouvez partager vos connaissances en l ’ améliorant ( comment ? ) selon les recommandations des projets correspondants . en informatique théorique , un algorithme de fouille de flots de données ( ou algorithme de streaming de streaming algorithm en anglais ) est un algorithme prenant en entrée un flot continu d&apos; items . ces algorithmes ont en général peu de mémoire à leur disposition ( beaucoup moins que la taille du volume en entrée ) et peu de temps à accorder à chaque item . ces contraintes peuvent impliquer qu&apos; un tel algorithme fournit une réponse approchée fondée sur l&apos; exploitation d&apos; un résuméenst , projet midas ( « summaries » ) du flot de données en mémoire . le modèle partage certains aspects avec les algorithmes onlines , mais les deux modèles sont différents . dans un algorithmes de streaming la réponse peut être donnée de façon différée , et la difficulté est le peu d&apos; espace disponible , il peut même y avoir plusieurs passes sur la donnée . au contraire pour les algorithme online , les décisions doivent être prises au fur et à mesure de la réception des informations , et les ressources en espace et en temps de calcul ne sont pas limitées . pour la recherche d&apos; items fréquentsnishad manerikar , themis palpanas , frequent items in streaming data : an experimental evaluation of the state-of-the-art dans un flot de données , il y a deux types d&apos; algorithmes : les algorithmes basés sur les comptages et les algorithmes axés sur les résumés ( « sketch » ) . sticky sampling et lossy-countinggurmeet singh manku , rajeev motwani , approximate frequency counts over data streams sont deux algorithmes importants dans ce domaine ne serait-ce que parce qu&apos; ils sont des références . ce sont tous les deux des algorithmes orientés faux-positifs ( « false-positive » ) à savoir , ils s&apos; autorisent à présenter en résultat des items ou des itemsets fréquents alors qu&apos; ils ne le sont pas , mais aucun faux-négatifs sont oubliés . lossy-countinghervé bronnimann , echantillonnage et problèmes géométriques en ligne est un des premiers algorithmes d&apos; exploration des flots de données utilisant le modèle des fenêtres à drapeau ( « landmark windows model » ) . c&apos; est un algorithme paramétrique qui accepte deux paramètres de l&apos; utilisateur : \ epsilon \ in &#91; 0,1 &#93; et s \ in &#91; 0,1 &#93; ~ \ text { avec } ~ \ epsilon \ ll s où \ epsilon est le taux d&apos; erreur et s le seuil de support souhaités par l&apos; analyste . si n est le nombre d&apos; items ( itemsets ) venant d&apos; arriver , l&apos; algorithme utilise des fenêtres de longueur 1 / \ epsilon . la conception de l&apos; algorithme garantit que tous les items ( itemsets ) dont la fréquence réelle est supérieure à sn ( le support s _ i de i dans un ensemble de cardinalité n est égal à \ frac { f _ i } { n } ) sont dans la liste de sortie , aucun item ( itemset ) dont la fréquence réelle est inférieure à sn - \ epsilon n sont dans la liste de sortie , et les fréquences estimées ne sont éloignées des fréquences réelles que d&apos; un facteur au plus égal à \ epsilon n. sticky sampling utilise des fenêtres de longueur fixe , et un taux d ’ échantillonnage r , ie il choisit un élément avec une probabilité égale à \ frac { 1 } { r } . il utilise trois paramètres \ epsilon - le taux d&apos; erreur - s le seuil de support , et \ delta la probabilité d ’ échec souhaités par l&apos; analyste . si t = \ frac { 1 } { \ epsilon } \ log ( \ epsilon ^ { -1 } \ delta ^ { -1 } ) , les t premiers arrivants sont choisis avec un taux r égal à 1 , les 2t suivants avec un taux égal à 2 , .... si l&apos; analyste demande la sortie des items ( itemsets ) au-dessus du seuil s , l&apos; algorithme sort les éléments dont la fréquence f \ ge ( s- \ epsilon ) n. data stream mining for frequent itemsethua-fu li , suh-yin lee et man-kwan , shanan efficient algorithm for mining frequent itemsets over the entire history of data streams est un algorithme créé par hua-fu li , suh-yin lee et man-kwan shan pour explorer les itemsets fréquents dans un flot de données . « very fast decision trees learner » pedro domingos , geoff hulten , mining high-speed data streams réduit le temps d&apos; apprentissage pour les grands ensembles incrémentaux de données en sous-échantillonnant le flux de données . vfdt utilise un arbre de hoeffding . « concept-adapting very fast decision trees learner » pedro domingos , laurie spencer , geoff hulten , mining time-changing data streams est une amélioration de l&apos; algorithme précédent en ce qu&apos; il tient compte de la dérive conceptuelle ( « concept drift » ) . un arbre de hoeffdingpedro domingos , geoff hulten , mining high-speed data streams , albert bifet , geoff holmes , bernhard pfahringer , richard kirkby , ricard gavaldà , new ensemble methods for evolving data streams , page 4 , geoff holmes , bernhard pfahringer , richard kirkby , tie breaking in hoeffding trees , page 2est un algorithme d&apos; arbre de décision incrémental et perpétuel , capable d&apos; apprentissage à partir d&apos; un flots de données massif , avec l&apos; hypothèse que la distribution des échantillons ne varie pas en fonction du temps - pas de dérive conceptuelle ( « concept drift » ) . cet algorithme construit un arbre d&apos; une manière incrémentale , en rassemblant dans les feuilles suffisamment d&apos; informations pour pouvoir choisir à un moment donné quel est le meilleur attribut pour transformer ces feuilles en nœuds . la division de la feuille - qui transforme la feuille en nœud - en deux sous-feuilles s&apos; effectue en utilisant l&apos; inégalité de hoeffding ( « hoeffding bound » ) , mesure statistique qui permet de savoir à partir de combien d&apos; échantillons un estimateur est proche de la vraie valeur de la variable estimée avec une probabilité 1 - \ delta , si on se donne \ delta à priori . birchtian zhang , raghu ramakrishnan , miron livny , birch : an efﬁcient data clustering method for very large databases , chun wei , clustering data streams ( « balanced iterative reducing and clustering using hierarchies » ) est un algorithme d&apos; exploration de données non-supervisé utilisé pour produire une segmentation hiérarchisée sur des volumes de données particulièrement importants . cet algorithme utilise des vecteurs de caractérisation de segment ( « clustering feature » ) composés de ( \ nu , \ sum _ { k = 1 } ^ \ nu \ chi _ i ^ 2 , \ sum _ { k = 1 } ^ \ nu \ chi _ i ) où chaque \ chi _ i est un vecteur , pour résumer les micro-segments ( « micro-cluster » ) afin de bâtir un arbre équilibré composé de ces micros-segments . les informations contenues dans un vecteur cf sont suffisantes pour calculer les estimateurs de moyenne , variance , les centroids , et certaines distances . l&apos; arbre cf possède trois paramètres : b le facteur de branche , t le seuil , l le nombre de feuilles maximum sous les derniers nœuds . les feuilles sont reliées entre elles par des pointeurs prec et suiv. l&apos; algorithme se déroule en trois phases : la première consiste à lire les données et à construire l&apos; arbre cf dans la limite de la mémoire disponible . la deuxième phase sert à éliminer les aberrations ( « outlier » ) et un algorithme de segmentation est utilisé dans la phase trois pour segmenter les feuilles . des bornes inférieures peuvent être calculer pour les algorithmes de streaming , notamment en utilisant les résultats de la complexité de communication . ( en ) cet article est partiellement ou en totalité issu de l ’ article de wikipédia en anglais intitulé « streaming algorithm » ( voir la liste des auteurs ) . r. agrawal , s. p. ghosh , t. imielinski , b. r. iyer , and a. n. swami . an interval classifier for database mining applications . in vldb &apos; 92 , pages 560-573 , 1992 . r. agrawal , t. imielinski , and a. swami . database mining : a performance perspective . ieee trans. on knowl. and data eng . , 5 ( 6 ) : 914-925 , 1993 .
