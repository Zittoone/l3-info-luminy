l&apos; optimisation aléatoire ( oa ) est une famille de méthodes d&apos; optimisation numérique qui ne nécessite pas de connaître le gradient du problème pour être utilisée , comme dans le cas de fonctions non continues ou non différentiables . ces méthodes sont aussi connues sous le nom de recherche directe , méthodes sans dérivation ou méthodes boîte noire . le nom d&apos; optimisation aléatoire ( random optimization ) est attribué à matyas , qui présenta une analyse mathématique de base des méthodes . l&apos; optimisation aléatoire consiste en des déplacements itératifs vers de meilleures positions dans l&apos; espace de recherche , positions déterminées selon une distribution normale autour de la position courante. fin de l&apos; algorithme , x est la solution recherchée . matyas a montré que la forme basique de l&apos; oa converge vers l&apos; optimum d&apos; une fonction unimodale simple en utilisant une preuve par limite : la convergence vers l&apos; optimum est garantie après un nombre virtuellement infini d&apos; itérations . cependant , cette preuve n&apos; est pas utile en pratique , où seul un nombre fini d&apos; itérations peut être exécuté . en fait , une telle preuve par limite montre aussi qu&apos; un échantillonnage aléatoire de l&apos; espace de recherche mène inévitablement à un choix d&apos; échantillon arbitrairement proche de l&apos; optimum . des analyses mathématiques conduites par baba ainsi que solis et wets ont établi que la convergence vers une région approchant l&apos; optimum est inévitable sous certaines conditions faibles , pour des variantes de l&apos; oa utilisant d&apos; autres lois de probabilité pour l&apos; échantillonnage . une estimation du nombre d&apos; itérations nécessaire pour approcher l&apos; optimum est donnée par dorea . ces analyses ont été critiquées par sarma via des tests empiriques , en utilisant les variantes de baba et dorea sur deux problèmes pratiques : l&apos; optimum est atteint très lentement , et les méthodes se sont révélées incapables de trouver une solution convenable à moins de démarrer le processus d&apos; un point déjà proche de l&apos; optimum . ( en ) cet article est partiellement ou en totalité issu de l ’ article de wikipédia en anglais intitulé « random optimization » ( voir la liste des auteurs ) .
