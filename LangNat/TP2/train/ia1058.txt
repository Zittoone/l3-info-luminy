en analyse numérique et plus précisément en optimisation mathématique , l&apos; algorithme proximal ( ou algorithme du point proximal ) est un algorithme itératif de calcul d&apos; un minimum d&apos; une fonction convexe semi-continue inférieurement propre . si la fonction n&apos; est pas quadratique , chaque itération requiert la minimisation d&apos; une fonction non linéaire fortement convexe . l&apos; algorithme peut être vu comme une méthode de gradient implicite . certains algorithmes peuvent être interprétés comme des algorithmes proximaux . il en est ainsi de la méthode des multiplicateurs ( ou algorithme du lagrangien augmenté ) . cette lecture permet alors d&apos; en établir des propriétés de convergence , déduites de celles de l&apos; algorithme proximal. f ( x ) \ leqslant f ( x &apos; ) . où \ partial f ( x ) est le sous-différentiel de f en x , parce que cette inclusion est une condition nécessaire et suffisante d&apos; optimalité du problème de minimisation . on montre que , sous les propriétés énoncées de f , x \ multimap \ partial f ( x ) est un opérateur monotone maximalla monotonie maximale du sous-différentiel d&apos; une fonction convexe fermée propre est due à minty ( 1964 ) et moreau ( 1965 ) . , ce qui permet de voir le problème comme un cas particulier de recherche de zéro d&apos; opérateur monotone maximal et de voir l&apos; algorithme proximal en optimisation comme un cas particulier de l&apos; algorithme proximal pour la recherche de zéro de tels opérateurs. f _ k : = f _ { x _ k , r _ k } . où r _ k &gt; 0 est un nombre réel pouvant être modifié à chaque itération. x _ { k + 1 } = x _ k - r _ kg _ { k + 1 } , \ quad \ mbox { avec } \ quad g _ { k + 1 } \ in \ partial f ( x _ { k + 1 } ) . l&apos; algorithme peut donc être vu comme une méthode de sous-gradient implicite ( implicite car le sous-gradient est évalué au nouveau point x _ { k + 1 } – inconnu – et non pas en l&apos; itéré courant x _ k ) avec pas r _ k. on voit aussi que chaque itération requiert la résolution d&apos; un problème d&apos; optimisation non linéaire ( à moins que f ne soit quadratique ) . voilà un algorithme bien étrange , puisque pour minimiser f , il faut qu&apos; à chaque itération , l&apos; algorithme proximal minimise la fonction f _ k qui semble bien être aussi compliquée que f. ce point de vue doit être relativisé au vu des remarques suivantes . le calcul de l&apos; itéré suivant par x _ { k + 1 } = \ operatorname { arg \ , min } _ { x \ in \ mathbb { h } } \ , f _ k ( x ) est souvent coûteux en temps de calcul . dès lors , l&apos; on se contente souvent d&apos; un calcul approché conservant toutefois les propriétés de convergence de lalgorithme idéal . on peut aussi arguer que ce calcul ne peut être réalisé exactement en arithmétique flottante . différents critères ont donc été proposés pour déterminer ce qu&apos; est une résolution approchée acceptable . \ sum _ { k \ geqslant0 } \ varepsilon _ k &lt; \ infty . \ sum _ { k \ geqslant 0 } \ varepsilon _ k &lt; \ infty . \ end { array } \ right. où \ theta _ k : = ( \ mu _ k + \ varepsilon _ k ) / ( 1- \ varepsilon _ k ) \ leqslant \ bar { \ theta } &lt; 1 avec \ mu _ k : = l / ( l ^ 2 + r _ k ^ 2 ) ^ { 1 / 2 } \ leqslant \ bar { \ mu } &lt; 1 . on note que si r _ k \ uparrow \ infty , alors \ mu _ k \ to0 et \ theta _ k \ to0 , ce qui implique qu&apos; alors la suite \ { x _ k \ } converge superlinéairement vers \ bar { x } . j. ch . gilbert , éléments d&apos; optimisation différentiable — théorie et algorithmes , syllabus de cours à l&apos; ensta paristech , paris . ( en ) g.j. minty ( 1964 ) . on the monotonicity of the gradient of a convex function . pacific journal of mathematics , 14 , 243 – 247 . j.j. moreau ( 1965 ) . proximité et dualité dans un espace hilbertien . bulletin de la société mathématique de france , 93 , 273 – 299 . ( en ) r.t. rockafellar ( 1976a ) . monotone operators and the proximal point algorithm . siam journal on control and optimization , 14 , 877 – 898 . ( en ) r.t. rockafellar ( 1976b ) . augmented lagrangians and applications of the proximal point algorithm in convex programming . mathematics of operations research , 1 , 97-116 .
