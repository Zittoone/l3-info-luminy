un algorithme par séparation et évaluation , ou branch and bound en anglais , est une méthode générique de résolution de problèmes d&apos; optimisation combinatoire . l&apos; optimisation combinatoire consiste à trouver un point minimisant une fonction , appelée coût , dans un ensemble dénombrable . une méthode naïve pour résoudre ce problème est d&apos; énumérer toutes les solutions du problème , de calculer le coût pour chacune , puis de donner le minimum . parfois , il est possible d&apos; éviter d&apos; énumérer des solutions dont on sait , par l&apos; analyse des propriétés du problème , que ce sont de mauvaises solutions , c&apos; est-à-dire des solutions qui ne peuvent pas être le minimum . la méthode séparation et évaluation est une méthode générale pour cela . cette méthode est très utilisée pour résoudre des problèmes np-complets , c&apos; est-à-dire des problèmes considérés comme difficiles à résoudre efficacement . le branch and bound est parfois comparé à une autre technique de recherche de solution , l&apos; algorithme a * , très souvent utilisé en intelligence artificielle , alors que le branch and bound est plutôt destiné aux problèmes de recherche opérationnelle . soit s un ensemble fini mais de « grande » cardinalité qu&apos; on appelle ensemble ( ou espace ) des solutions réalisables . on dispose d&apos; une fonction f qui , pour toute solution réalisable x de s , renvoie à un coût f ( x ) . le but du problème est de trouver la solution réalisable x de coût minimal . d&apos; un point de vue purement existentiel , le problème est trivial : une telle solution x existe bien car l&apos; ensemble s est fini . en revanche , l&apos; approche effective du problème se confronte à deux difficultés . la première est qu&apos; il n&apos; existe pas forcément un algorithme simple pour énumérer les éléments de s. la seconde est que le nombre de solutions réalisables est très grand , ce qui signifie que le temps d&apos; énumération de toutes les solutions est prohibitif ( la complexité en temps est en général exponentielle ) template : lien web . . dans les méthodes par séparation et évaluation , la séparation permet d&apos; obtenir une méthode générique pour énumérer toutes les solutions tandis que l&apos; évaluation évite l&apos; énumération systématique de toutes les solutions . la phase de séparation consiste à diviser le problème en un certain nombre de sous-problèmes qui ont chacun leur ensemble de solutions réalisables , de telle sorte que tous ces ensembles forment un recouvrement ( idéalement une partition ) de l&apos; ensemble s. ainsi , en résolvant tous les sous-problèmes et en prenant la meilleure solution trouvée , on est assuré d&apos; avoir résolu le problème initial . ce principe de séparation peut être appliqué de manière récursive à chacun des sous-ensembles de solutions obtenus , et ceci tant qu&apos; il y a des ensembles contenant plusieurs solutions . les ensembles de solutions ( et leurs sous-problèmes associés ) ainsi construits ont une hiérarchie naturelle en arbre , souvent appelée arbre de recherche ou arbre de décision . l&apos; évaluation d&apos; un nœud de l&apos; arbre de recherche a pour but de déterminer l&apos; optimum de l&apos; ensemble des solutions réalisables associé au nœud en question ou , au contraire , de prouver mathématiquement que cet ensemble ne contient pas de solution intéressante pour la résolution du problème ( typiquement , qu&apos; il n&apos; y a pas de solution optimale ) . lorsqu&apos; un tel nœud est identifié dans l&apos; arbre de recherche , il est donc inutile d&apos; effectuer la séparation de son espace de solutions . à un nœud donné , l&apos; optimum du sous-problème peut être déterminé lorsque le sous-problème devient « suffisamment simple » . par exemple , lorsque l&apos; ensemble des solutions réalisables devient un singleton , le problème est effectivement simple : l&apos; optimum est l&apos; unique élément de l&apos; ensemble . dans d&apos; autres cas , il arrive que par le jeu des séparations , on arrive à un sous-problème dans lequel les décisions « difficiles » ont été prises et qui peut ainsi être résolu en temps polynomial . pour déterminer qu&apos; un ensemble de solutions réalisables ne contient pas de solution optimale , la méthode la plus générale consiste à déterminer un minorant du coût des solutions contenues dans l&apos; ensemble ( s&apos; il s&apos; agit d&apos; un problème de minimisation ) . si on arrive à trouver un minorant qui est supérieur au coût de la meilleure solution trouvée jusqu&apos; à présent , on a alors l&apos; assurance que le sous-ensemble ne contient pas l&apos; optimum . les techniques les plus classiques pour le calcul de minorants sont fondées sur l&apos; idée de relaxation de certaines contraintes : relaxation continue , relaxation lagrangienne , etc. la qualité de l&apos; exploration repose grandement sur le choix d&apos; une heuristique dont on suppose qu&apos; elle aura plus de chance de faire venir le meilleur résultat dans les premiers . de cette manière , on augmente la probabilité de trouver de bonnes solutions réalisables dès le début de la recherche . le programme mémorise aussi la croissance ou décroissance de la fonction objectif au fil du temps , afin de suggérer éventuellement des temps d&apos; exploration plus longs si des gains importants ont été obtenus vers la fin de la période de recherche . on peut , bien que ce ne soit pas obligatoire , mémoriser aussi les meilleures solutions trouvées au fur et à mesure qu&apos; on les trouve . la suite des réorganisations conduisant à de meilleurs résultats peut en effet à son tour aiguiller vers de nouvelles heuristiques . il est également possible de munir le programme d&apos; un test de clé pupitre , dinteraction utilisateur par le moyen du clavier ou de chronométrage assurant qu&apos; il s&apos; arrêtera au bout d&apos; un temps compatible avec le budget , et en imprimant alors le meilleur résultat trouvé à ce moment-là ( les résultats sont souvent imprimés ou affichés au fur et à mesure , ce qui permet de savoir quand s&apos; arrêter ) . une bonne fonction d&apos; évaluation est essentielle pour que la méthode soit efficace . le but d&apos; une fonction d&apos; évaluation est de donner une estimation la plus proche possible de la valeur exacte , c&apos; est-à-dire du plus petit coût dans le sous-problème . il y a cependant un compromis à faire entre la qualité et le temps de calcul . deux techniques classiques sont l&apos; utilisation de relaxations et la modification de la fonction de coût . pour pallier l&apos; imperfection des heuristiques , le programme est souvent muni de métaheuristiques permettant d&apos; abandonner momentanément une exploration quand elle ne donne pas le rendement souhaité . lorsque l&apos; exploration d&apos; arbre se fait contre un joueur adverse , on utilise un autre court-circuit , d&apos; esprit voisin , qui est l&apos; élagage alpha-bêta ( parfois nommée coupure p-q ) . cette technique est très couramment utilisée dans le domaine de la recherche opérationnelle pour résoudre les problèmes np-completstemplate : lien web . . elles sont en particulier au cœur des solveurs d&apos; optimisation linéaire en nombres entiers et de programmation par contraintes .
