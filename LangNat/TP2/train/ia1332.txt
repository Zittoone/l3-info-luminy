le partitionnement en k-moyennes ( ou k-means en anglais ) est une méthode de partitionnement de données et un problème d&apos; optimisation combinatoire . étant donnés des points et un entier k , le problème est de diviser les points en k groupes , souvent appelés clusters , de façon à minimiser une certaine fonction . on considère la distance d&apos; un point à la moyenne des points de son cluster ; la fonction à minimiser est la somme des carrés de ces distances . il existe une heuristique classique pour ce problème , souvent appelée méthodes des k-moyennes , utilisée pour la plupart des applications . le problème est aussi étudié comme un problème d&apos; optimisation classique , avec par exemple des algorithmes d&apos; approximation . les k-moyennes sont notamment utilisées en apprentissage non supervisé où l&apos; on divise des observations en k partitions . les nuées dynamiques sont une généralisation de ce principe , pour laquelle chaque partition est représentée par un noyau pouvant être plus complexe qu&apos; une moyenne . un algorithme classique de k-means est le même que l&apos; algorithme de quantification de lloyd-max. où μi est la moyenne des points dans si . template : article . . en 1965 , e. w. forgy publia une méthode essentiellement similaire , raison pour laquelle elle est parfois appelée « méthode de lloyd-forgy » template : article . . une version plus efficace , codée en fortran , a été publiée par hartigan et wong en 1975 / 1979template : ouvrage . , template : article . . il existe un algorithme classique pour le problème , parfois appelé méthode des k-moyennes , très utilisé en pratique et considéré comme efficace bien que ne garantissant ni l&apos; optimalité , ni un temps de calcul polynomialtemplate : article . . il y a un nombre fini de partitions possibles à k classesvoir nombre de stirling pour plus de détails . . de plus , chaque étape de l&apos; algorithme fait strictement diminuer la fonction de coût , positive , et fait découvrir une meilleure partition . cela permet d&apos; affirmer que l&apos; algorithme converge toujours en temps fini , c&apos; est-à-dire termine . la solution finale n&apos; est pas toujours optimale . de plus le temps de calcul peut-être exponentiel en le nombre de points , même dans le plantemplate : article . dans la pratique , il est possible d&apos; imposer une limite sur le nombre d ’ itérations ou un critère sur l&apos; amélioration entre itérations . à k fixé , la complexité lisse est polynomiale pour certaines configurations , dont des points dans un espace euclidien et le cas de la divergence de kullback-leiblertemplate : article . . si k fait partie de l&apos; entrée , la complexité lisse est encore polynomiale pour le cas euclidientemplate : article . ces résultats expliquent en partie l&apos; efficacité de l&apos; algorithme en pratique . le problème des k-moyennes est np-difficile dans le cas généralthe hardness of kmeans clustering sanjoy dasgupta , technical report cs2008-06 , department of computer science and engineering , university of california , san diego . dans le cas euclidien , il existe un algorithme d&apos; approximation polynomial , de ratio 9 , par recherche localetemplate : article . un inconvénient possible des k-moyennes pour le partitionnement est que les clusters dépendent de l&apos; initialisation et de la distance choisie &#91; réf. souhaitée &#93; catégorie : article à référence souhaitée . le fait de devoir choisir a priori le paramètre k peut être perçu comme un inconvénient ou un avantage . dans le cas du calcul des sac de mots par exemple , cela permet de fixer exactement la taille du dictionnaire désiré . au contraire , dans certains partitionnements de données , on préférera s&apos; affranchir d&apos; une telle contrainte . article détaillé : quantification vectorielle .
