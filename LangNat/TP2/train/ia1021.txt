un algorithme à directions de descente est un algorithme d&apos; optimisation différentiable ( l&apos; optimisation dont il est question ici est une branche des mathématiques ) , destiné à minimiser une fonction réelle différentiable définie sur un espace euclidien ( par exemple , \ mathbb { r } ^ n , l&apos; espace des n-uplets de nombres réels , muni d&apos; un produit scalaire ) ou , plus généralement , sur un espace hilbertien . l&apos; algorithme est itératif et procède donc par améliorations successives . au point courant , un déplacement est effectué le long d&apos; une direction de descente , de manière à faire décroître la fonction . le déplacement le long de cette direction est déterminé par la technique numérique connue sous le nom de recherche linéaire . cette approche algorithmique peut être vue comme une technique de globalisation , c&apos; est-à-dire une méthode permettant d&apos; obtenir la convergence des itérés ( sous certaines conditions ) quel que soit l&apos; itéré initial choisi . elle s&apos; apparente ainsi aux algorithmes à régions de confiance ; ces dernières améliorent légèrement ( mais parfois de manière décisive ) leurs résultats de convergence mais sont plus compliquées à mettre en œuvre , ce qui limite parfois leur application . les algorithmes à directions de descente s&apos; étendent aux problèmes avec contraintes simples ( pourvu que la projection sur l&apos; ensemble admissible soit aisée , peu coûteuse en temps de calcul ) ou pour des problèmes avec contraintes fonctionnelles non linéaires , par l&apos; intermédiaire de fonctions de mérite . elles sont aussi utilisées en optimisation non lisse . \ forall \ , d \ in \ mathbb { e } : \ qquad f &apos; ( x ) \ cdot d = \ langle \ nabla f ( x ) , d \ rangle. détermination d&apos; un pas \ alpha _ k , qui est un nombre réel strictement positif , le long de la direction de descente de telle sorte que le nouvel itéré donne au critère une valeur inférieure à celle qu&apos; il a en l&apos; itéré courant ; le nouvel itéré est de la forme suivantex _ { k + 1 } : = x _ k + \ alpha _ k d _ k ; cette opération de détermination du pas s&apos; appelle la recherche linéaire . ces deux opérations seront décrites ci-dessous , mais on peut dès à présent résumer l&apos; algorithme . il s&apos; agit d&apos; un schéma algorithmique , car beaucoup d&apos; aspects de celui-ci ne sont pas spécifiés avec précision . algorithme à directions de descente ( schéma ) — on se donne un point / itéré initial x _ 1 \ in \ mathbb { e } et un seuil de tolérance \ varepsilon \ geqslant 0 . un algorithme à directions de descente définit une suite d&apos; itérés x _ 1 , x _ 2 , \ ldots \ in \ mathbb { e } , jusqu&apos; à ce qu&apos; un test d&apos; arrêt soit satisfait . il passe de x _ k à x _ { k + 1 } par les étapes suivantes . cet algorithme est extrêmement simple ; ça ne l&apos; empêche pas d&apos; avoir des propriétés de convergence intéressantes , bien au contraire . cette simplicité permet d&apos; étendre l&apos; algorithme à des contextes variés , aux problèmes d&apos; optimisation avec contraintes en particulier . en pratique , il faudra prendre \ varepsilon &gt; 0 dans le test d&apos; arrêt de l&apos; étape 2 ; la valeur nulle de cette tolérance a été admise uniquement pour simplifier l&apos; expression des résultats de convergence ci-dessous . dans les problèmes sans contrainte , il est normal que le test d&apos; arrêt porte sur la petitesse du gradient ( \ varepsilon est généralement pris petit ) . c&apos; est en effet ce que suggère la condition nécessaire d&apos; optimalité du premier ordre \ nabla f ( x _ * ) = 0 . comme x _ k n&apos; est jamais exactement égal à x _ * , ce test ne pourra fonctionner que si \ nabla f ( x ) est faible en norme pour x voisin de x _ * , ce qui revient pratiquement à supposer que f est de classe c ^ 1 . par ailleurs , un tel test d&apos; arrêt suggère qu&apos; un algorithme à directions de descente ne peut pas trouver mieux qu&apos; un point stationnaire de f. c&apos; est en effet souvent le cas , mais ce point faible est rarement rédhibitoire en pratique . on peut noter qu&apos; il existe une version élaborée des méthodes à régions de confiance qui permet de trouver un minimum local , évitant ainsi les points stationnaires qui n&apos; ont pas cette propriété de minimalité locale . on est parfois tenté d&apos; arrêter l&apos; algorithme si le critère f ne décroît presque plus . ceci n&apos; est pas sans risque et il vaut mieux ne pas utiliser un tel test d&apos; arrêt , car une faible variation du critère peut se produire loin d&apos; une solution . en effet , au premier ordre , f ( x _ { k + 1 } ) \ simeq f ( x _ k ) revient à \ alpha _ k \ langle \ nabla f ( x _ k ) , d _ k \ rangle \ simeq0 , ce qui peut arriver si le pas \ alpha _ k est petit ( c&apos; est en général très suspect ) ou si la direction de descente fait avec l&apos; opposé du gradient un angle proche de 90 degrés , une situation qui se rencontre fréquemment ( si l&apos; algorithme est bien conçu , cela traduit un mauvais conditionnement du problème ) . \ qquad \ mbox { avec } ~ ~ a \ succ0. l&apos; algorithme de gauss-newton est utilisé pour résoudre les problèmes de moindres-carrés et utilise la direction de gauss-newton . ces directions sont décrites dans l&apos; article « direction de descente » . q ( \ alpha ) = f ( x _ k + \ alpha d _ k ) . en choisissant α trop petit , l&apos; algorithme aura une convergence lente. q ( \ alpha ) \ leqslant q ( 0 ) + m \ alpha q &apos; ( 0 ) . le risque de cette méthode est de favoriser les valeurs trop petites , aussi , elle est rarement utilisée seule. q ( \ alpha ) &amp; \ geqslant q ( 0 ) + m _ 2 \ alpha q &apos; ( 0 ) . q &apos; ( \ alpha ) &amp; \ geqslant m _ 2 q &apos; ( 0 ) . deux valeurs usuelles des paramètres sont m _ 1 = 0,1 et m _ 2 = 0,7 . j. ch . gilbert , éléments d&apos; optimisation différentiable — théorie et algorithmes , syllabus de cours à l&apos; ensta paristech , paris . ( en ) d. p. bertsekas ( 1995 ) , nonlinear programming . athena scientific . ( isbn 978-1-886529-14-4 ) . ( en ) j. f. bonnans , j. ch . gilbert , c. lemaréchal , c. sagastizábal ( 2006 ) , numerical optimization - theoretical and numerical aspects &#91; détail des éditions &#93; . ( en ) j. nocedal , s. j. wright ( 2006 ) , numerical optimization , springer . ( isbn 978-0-387-30303-1 ) .
