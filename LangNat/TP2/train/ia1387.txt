en analyse numérique , la méthode du gradient conjugué est un algorithme pour résoudre des systèmes d&apos; équations linéaires dont la matrice est symétrique définie positive . cette méthode , imaginée en 1950 simultanément par cornelius lanczos et magnus hestenestemplate : article , est une méthode itérative qui converge en un nombre fini d&apos; itérations ( au plus égal à la dimension du système linéaire ) . toutefois , son grand intérêt pratique du point de vue du temps de calcul vient de ce qu ’ une initialisation astucieuse ( dite « préconditionnement » ) permet d&apos; aboutir en seulement quelques passages à une estimation très proche de la solution exacte , c&apos; est pourquoi en pratique on se borne à un nombre d&apos; itérations bien inférieur au nombre d&apos; inconnues . la méthode du gradient biconjugué fournit une généralisation pour les matrices non symétriques . l&apos; objectif est de minimiser la fonction f : x \ mapsto \ frac { 1 } { 2 } ( \ mathbf { a } x , x ) - ( b , x ) où a est une matrice carrée symétrique définie positive de taille n. le calcul montre qu&apos; une solution du problème est la solution du système \ mathbf { a } x = b : en effet , on a \ nabla f \ left ( x \ right ) = \ mathbf { a } x-b . intuitivement , la fonction f peut dont être vue comme une primitive du résidu \ mathbf a x - b. en annulant le gradient de f , on obtient le vecteur x qui minimise l&apos; erreur. u ^ \ mathrm { t } \ mathbf { a } v = 0 . \ langle u , v \ rangle _ \ mathbf { a } : = \ langle \ mathbf { a } { u } , { v } \ rangle = \ langle { u } , \ mathbf { a } ^ \ mathrm { t } { v } \ rangle = \ langle { u } , \ mathbf { a } { v } \ rangle = { u } ^ \ mathrm { t } \ mathbf { a } { v } . deux vecteurs sont conjugués s&apos; ils sont donc orthogonaux pour ce produit scalaire . la conjugaison est une relation symétrique : si u est conjugué à v pour a , alors v est conjugué à u. { b } = \ mathbf { a } { x } _ * = \ sum ^ { n } _ { i = 1 } \ alpha _ i \ mathbf { a } { p } _ i. on a ainsi l&apos; idée directrice de la méthode pour résoudre le système ax = b : trouver une suite de n directions conjuguées , et calculer les coefficients αk . en choisissant correctement les directions conjuguées pk , il n&apos; est pas nécessaire de toutes les déterminer pour obtenir une bonne approximation de la solution x * . il est ainsi possible de considérer la méthode du gradient conjugué comme une méthode itérative . ce choix permet ainsi de considérer la résolution de systèmes de très grande taille , où le calcul de l&apos; ensemble des directions aurait été très long. f ( \ mathbf { x } ) = \ frac12 x ^ \ mathrm { t } \ mathbf { a } x - x ^ \ mathrm { t } b , \ quad x \ in \ r ^ n. ainsi , si f ( x ) diminue après une itération , alors on s&apos; approche de x * . ceci suggère donc de prendre la première direction p1 comme l&apos; opposé du gradient de f à x = x0 . le gradient vaut ax0-b = -b , d&apos; après notre première hypothèse . les vecteurs suivants de la base seront ainsi conjugués au gradient , d&apos; où le nom « méthode du gradient conjugué » . notons que rk est l&apos; opposé du gradient de f en x = xk , ainsi , l&apos; algorithme du gradient indique d&apos; évoluer dans la direction rk . on rappelle que les directions pk sont conjuguées deux à deux . on veut aussi que la direction suivante soit construite à partir du résidu courant et des directions précédemment construites , ce qui est une hypothèse raisonnable en pratique . la contrainte de conjugaison est une contrainte d&apos; orthonormalité , aussi le problème partage des similitudes avec le procédé de gram-schmidt . l&apos; algorithme ci-dessous résout ax = b , où a est une matrice réelle , symétrique , et définie positive . le vecteur d&apos; entrée x0 peut être une approximation de la solution initiale ou 0 . la méthode du gradient conjugué a donc une convergence superlinéaire , qui peut être mise à mal par un mauvais conditionnement de la matrice . elle reste toutefois meilleure que les algorithmes à direction de plus forte pente . ( en ) m1cg1 - a solver of symmetric linear systems by conjugate gradient iterations , using / building a bfgs / ℓ-bfgs preconditioner . écrit en fortran-77 . le solveur a l&apos; intérêt d&apos; offrir la possibilité de construire un préconditionneur bfgs ou ℓ-bfgs ( en ) catégorie : article contenant un appel à traduction en anglais , qui pourra être utile pour la résolution d&apos; un système linéaire avec une matrice proche et un second membre différent . ( en ) cet article est partiellement ou en totalité issu de l ’ article de wikipédia en anglais intitulé « conjugate gradient method » ( voir la liste des auteurs ) .
