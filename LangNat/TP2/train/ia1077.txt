l&apos; apprentissage automatique ou apprentissage statistique ( machine learning en anglais ) , champ d&apos; étude de l&apos; intelligence artificielle , concerne la conception , l&apos; analyse , le développement et l&apos; implémentation de méthodes permettant à une machine ( au sens large ) d&apos; évoluer par un processus systématique , et ainsi de remplir des tâches difficiles ou problématiques à remplir par des moyens algorithmiques plus classiques . un exemple possible d&apos; apprentissage automatique est celui de la classification : étiqueter chaque donnée en l&apos; associant à une classe . différents systèmes d&apos; apprentissage existentprésentation sur youtube de classifications automatiques diverses issue du paquet mldemos disponible dans les dépôts linux ou sur ce site , listés ci-dessous . les algorithmes utilisés permettent , dans une certaine mesure , à un système piloté par ordinateur ( un robot éventuellement ) , ou assisté par ordinateur , d&apos; adapter ses analyses et ses comportements en réponse , en se fondant sur l&apos; analyse de données empiriques provenant d&apos; une base de données ou de capteurs . la difficulté réside dans le fait que l&apos; ensemble de tous les comportements possibles compte tenu de toutes les entrées possibles devient rapidement trop complexe à décrire ( on parle d&apos; explosion combinatoire ) . on confie donc à des programmes le soin d&apos; ajuster un modèle pour simplifier cette complexité et de l&apos; utiliser de manière opérationnelle . idéalement , l&apos; apprentissage visera à être non supervisé , c&apos; est à dire que la nature des données d&apos; entrainement n&apos; est pas connueyann le cun sur l&apos; apprentissage prédictif &#93; , 2016 . la reconnaissance de caractères manuscrits est une tâche complexe car deux caractères similaires ne sont jamais exactement égaux . on peut concevoir un système d&apos; apprentissage automatique qui apprend à reconnaître des caractères en observant des « exemples » , c&apos; est-à-dire des caractères connus . si les classes sont prédéterminées et les exemples connus , le système apprend à classer selon un modèle de classement ; on parle alors d&apos; apprentissage supervisé ( ou d&apos; analyse discriminante ) . un expert ( ou oracle ) doit préalablement étiqueter des exemples . le processus se passe en deux phases . lors de la première phase ( hors ligne , dite dapprentissage ) , il s&apos; agit de déterminer un modèle des données étiquetées . la seconde phase ( en ligne , dite de test ) consiste à prédire l&apos; étiquette d&apos; une nouvelle donnée , connaissant le modèle préalablement appris . parfois il est préférable d&apos; associer une donnée non pas à une classe unique , mais une probabilité d&apos; appartenance à chacune des classes prédéterminées ( on parle alors d&apos; apprentissage supervisé probabiliste ) . ex. : l&apos; analyse discriminante linéaire ou les svm en sont des exemples typiques . autre exemple : en fonction de points communs détectés avec les symptômes d&apos; autres patients connus ( les exemples ) , le système peut catégoriser de nouveaux patients au vu de leurs analyses médicales en risque estimé ( probabilité ) de développer telle ou telle maladie . quand le système ou l&apos; opérateur ne disposent que d&apos; exemples , mais non d&apos; étiquettes , et que le nombre de classes et leur nature n&apos; ont pas été prédéterminés , on parle d&apos; apprentissage non supervisé ou clustering . aucun expert n&apos; est requis . l&apos; algorithme doit découvrir par lui-même la structure plus ou moins cachée des données . le partitionnement de données , data clustering en anglais , est un algorithme d&apos; apprentissage non supervisé . le système doit ici — dans l&apos; espace de description ( la somme des données ) — cibler les données selon leurs attributs disponibles , pour les classer en groupe homogènes d&apos; exemples . la similarité est généralement calculée selon une fonction de distance entre paires d&apos; exemples . c&apos; est ensuite à l&apos; opérateur d&apos; associer ou déduire du sens pour chaque groupe et pour les motifs ( patterns en anglais ) dapparition de groupes , ou de groupes de groupes , dans leur « espace » . divers outils mathématiques et logiciels peuvent l&apos; aider . on parle aussi d&apos; analyse des données en régression ( ajustement d&apos; un modèle par une procédure de type moindres carrés ou autre optimisation d&apos; une fonction de coût ) . si l&apos; approche est probabiliste ( c&apos; est-à-dire que chaque exemple , au lieu d&apos; être classé dans une seule classe , est caractérisé par un jeu de probabilités d&apos; appartenance à chacune des classes ) , on parle alors de « soft clustering » ( par opposition au « hard clustering » ) . cette méthode est souvent source de sérendipité. ex. : pour un épidémiologiste qui voudrait dans un ensemble assez large de victimes de cancer du foie tenter de faire émerger des hypothèses explicatives , l&apos; ordinateur pourrait différencier différents groupes , que l&apos; épidémiologiste chercherait ensuite à associer à divers facteurs explicatifs , origines géographique , génétique , habitudes ou pratiques de consommation , expositions à divers agents potentiellement ou effectivement toxiques ( métaux lourds , toxines telle que l&apos; aflatoxine , etc. ) . effectué de manière probabiliste ou non , il vise à faire apparaître la distribution sous-jacente des exemples dans leur espace de description . il est mis en œuvre quand des données ( ou « étiquettes » ) manquent … le modèle doit utiliser des exemples non étiquetés pouvant néanmoins renseigner. ex. : en médecine , il peut constituer une aide au diagnostic ou au choix des moyens les moins onéreux de tests de diagnostic. probabiliste ou non , quand l&apos; étiquetage des données est partielambroise et govaert , 2000 . . c&apos; est le cas quand un modèle énonce qu&apos; une donnée n&apos; appartient pas à une classe a , mais peut-être à une classe b ou c ( a , b et c étant 3 maladies par exemple évoquées dans le cadre d&apos; un diagnostic différentiel ) . apprentissage par renforcementvoir template : langue , chap. 13 template : langue , template : p. . l&apos; algorithme apprend un comportement étant donné une observation . l&apos; action de l&apos; algorithme sur l&apos; environnement produit une valeur de retour qui guide l&apos; algorithme d&apos; apprentissage. ex. : l&apos; algorithme de q-learningvoir template : langue , template : p. . est un exemple classique . apprentissage par transferttemplate : article. les algorithmes génétiquesvoir machine learning , chap. 9 template : langue , template : p. . et la programmation génétique . ces méthodes sont souvent combinées pour obtenir diverses variantes d&apos; apprentissage . l&apos; utilisation de tel ou tel algorithme dépend fortement de la tâche à résoudre ( classification , estimation de valeurs … ) . la qualité de l&apos; apprentissage et de l&apos; analyse dépendent du besoin en amont et a priori de la compétence de l&apos; opérateur pour préparer l&apos; analyse . elle dépend aussi de la complexité du modèle ( spécifique ou généraliste ) , de son adéquation et de son adaptation au sujet à traiter . in fine , la qualité du travail dépendra aussi du mode ( de mise en évidence visuelle ) des résultats pour l&apos; utilisateur final ( un résultat pertinent pourrait être caché dans un schéma trop complexe , ou mal mis en évidence par une représentation graphique inappropriée ) . « bruit » : le nombre et la « localisation » des valeurs douteuses ( erreurs potentielles , valeurs aberrantes … ) ou naturellement non-conformes au pattern de distribution générale des « exemples » sur leur espace de distribution impacteront sur la qualité de l&apos; analyse . il est tentant de s&apos; inspirer des êtres vivants ( mais non de les copier naïvementcomputer science colloquium - march 28 , 2013 , anne menendez &amp; guy paillet &#93; ) pour concevoir des machines capables d&apos; apprendre . les notions de percept et de concept comme phénomènes neuronaux physiques ont d&apos; ailleurs été popularisés dans le monde francophone par jean-pierre changeux . même si l&apos; apprentissage automatique reste encore avant tout un sous-domaine de l&apos; informatique , il est étroitement lié opérationnellement aux sciences cognitives , aux neurosciences , à la biologie et à la psychologie , et pourrait à la croisée de ces domaines , nanotechnologies , biotechnologies , informatique et sciences cognitives , aboutir à des systèmes d&apos; intelligence artificielle ayant une assise plus vaste . deux professeurs actuels du collège de france y assurent un enseignement public sur le sujet : stanislas dehaenehttp : / / www.college-de-france.fr / site / stanislas-dehaene / _ course.htm orienté sur l&apos; aspect bayésien des neurosciences , et yann lecunhttps : / / www.college-de-france.fr / site / yann-lecun / recherches-sur-l-intelligence-artificielle.htm , pionnier de l&apos; apprentissage profond et depuis 2016 également directeur de facebook ai research ( fair ) , nouveau centre de recherche européen de facebook basé à paris et dédié à l ’ intelligence artificielle . ( en ) trevor hastie , robert tibshirani et jerome friedman , the elements of statistical learning : data mining , inference , and prediction , &lt; time &gt; 2009 &lt; / time &gt; , 2e éd.
