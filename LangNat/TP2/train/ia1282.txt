les premiers jalons historiques de l&apos; intelligence artificielle ( ou ia ) datent de la protohistoire , où mythes , légendes et rumeurs dotent des êtres artificiels , réalisés par des maîtres-artisans , d&apos; une intelligence ou d&apos; une conscience ; comme l&apos; écrit pamela mccorduck , l&apos; intelligence artificielle commence avec « le vieux souhait de jouer à dieutemplate : harvnb » . l&apos; intelligence artificielle comme nous l&apos; entendons aujourd&apos; hui a été initiée par les philosophes classiques , dont leibniz avec son calculus ratiocinator , qui essaient de décrire le processus de la pensée humaine comme la manipulation mécanique de symboles , sans pour autant vouloir fabriquer des spécimens . cette réflexion s&apos; est concrétisée avec l&apos; invention de l&apos; ordinateur programmable dans les années 1940 . cet instrument et les idées qu&apos; il sous-tend ont inspiré les scientifiques qui ont commencé à évoquer sérieusement la faisabilité d&apos; un « cerveau électronique » . la recherche en intelligence artificielle a vraiment commencé après une conférence tenue sur le campus de dartmouth college pendant l&apos; été 1956 . à la suite de cette réunion , certains participants se sont investis dans une recherche sur l&apos; intelligence artificielle . certains utopistes ont pronostiqué qu&apos; une machine aussi intelligente qu&apos; un être humain existerait en moins d&apos; une génération et des millions de dollars ont alors été investis pour réifier cette prédiction . avec le temps , il est apparu que les difficultés inhérentes à cette annonce avaient été grossièrement sous-estimées . en 1973 , en réponse aux critiques des scientifiques , notamment de james lighthill et aux pressions continuelles des parlementaires , les gouvernements britannique et américain stoppent les subventions à la recherche en intelligence artificielle sans orientation . sept ans plus tard , à la suite de l&apos; initiative prophétique du cabinet du japon , les gouvernements et l&apos; industrie réinvestissent dans l&apos; intelligence artificielle , mais à la fin des années 1980 les décideurs désabusés retirent à nouveau leurs fonds . on peut donc dire que ce cycle en dents de scie , où alternent périodes de gel et de dégel , caractérise le soutien à l&apos; intelligence artificielle . mais il reste toujours des idéalistes pour faire des prédictions oséespar exemple template : harvnb maintient que des machines ayant une intelligence comparable à celle de l&apos; homme existeront en 2029 . . quoi qu&apos; il en soit , malgré des hauts et des bas et malgré les réticences des technocrates et des investisseurs , l&apos; intelligence artificielle progresse . des problèmes qu&apos; on pensait inaccessibles en 1970 ont été résolus et leurs solutions sont distribuées commercialement . cela est aussi dû aux progrès de l&apos; algorithmique qui a permis de programmer des solutions que l&apos; on ne pouvait atteindre autrefois que par des heuristiques . néanmoins , aucune machine dotée d&apos; une intelligence artificielle forte n&apos; a encore été construite , contrairement aux prévisions optimistes de la première génération de chercheurs . « nous ne pouvons qu&apos; entrevoir le court terme » a concédé alan turing , dans un article célèbre de 1950 qui préfigure la recherche moderne sur les machines pensantes . « mais , » ajoute-t-il , « nous ne pouvons pas envisager l&apos; ampleur du travail qui reste à accomplirtemplate : harvnb » . au départ , deux approches se confrontent : l&apos; approche logiciste ou symbolique , qui vise à recréer les « lois universelles » de la pensée et s&apos; inspirent du concept de machine de turing , et l&apos; approche neuronale , incarnée par frank rosenblatt , qui essaie d&apos; imiter les processus biologiques cérébraux . si l&apos; approche logiciste , inspirée des travaux de russell , frege , du cercle de vienne , de logique mathématique , etc. , l&apos; emporte à la darpa , principal organisme finançant les recherches en intelligence artificielle , l&apos; approche neuronale refait surface dans les années 1980 , inspirant les travaux sur le connexionnisme . comme l&apos; intelligence artificielle s&apos; est développée surtout au départ aux états-unis , cet article se focalisera donc essentiellement sur ce pays . mccorduck 2004 écrit en 2004 que « l&apos; intelligence artificielle sous une forme ou une autre est une idée qui s&apos; est répandue dans l&apos; histoire de la pensée occidentale , un rêve au besoin pressant d&apos; être réalisé , » que l&apos; on retrouve dans les mythes , légendes , histoires , spéculations et automates anthropomorphes de l&apos; humanitétemplate : harvnb . les hommes mécaniques et les êtres artificiels sont présents dans la mythologie grecque , ainsi les robots dorés d&apos; héphaïstos et pygmalion et galatéetemplate : harvnb ; template : harvnb , tandis qu&apos; au moyen âge , circulent des rumeurs de secrets mystiques ou de techniques alchimiques pour imprégner des esprits , tels que le takwin de geber , les homoncules de paracelse et le golem de maharaltemplate : harvnb ; template : harvnb ( golem ) ; template : harvnb ( paracelse ) ; template : harvnb ( takwin ) . et des essais de spéculation , comme darwin among the machines de samuel butlertemplate : harvnb . l&apos; i.a. est un élément important de la science-fiction . article détaillé : automate anthropomorphe . des automates anthropomorphes réalistes ont été construits par des artisans de toutes les civilisations , dont yan shi qui travaillait pour ji mantemplate : harvnb , héron d&apos; alexandrietemplate : harvnb , al-djazaritemplate : harvnb et wolfgang von kempelentemplate : harvnb ; template : harvnb . les plus vieux automates sont les statues sacrées d&apos; ancienne égypte et de grèce antique . les croyants étaient persuadés que les artisans avaient imprégné ces statues avec des esprits réels , capables de sagesse et d&apos; émotion — hermès trismégiste a écrit qu &apos; « en découvrant la vraie nature des dieux , l&apos; homme a été capable de le reproduirecité dans template : harvnb . template : harvnb et template : harvnb traitent des statues sacrées . , d&apos; autres automates importants ont été construits par hâroun ar-rachîd template : harv , jacques de vaucanson template : harv et leonardo torres quevedo template : harv , sans oublier la compagnie de théâtre contemporaine royal de luxe . » . l&apos; automate de vaucanson du xviiie siècle qui représente un canard est une mise en œuvre saisissante d&apos; un être artificiel réalisant certaines fonctions du vivant , tandis que le turc joueur d&apos; échec de johann wolfgang von kempelen est une supercherie . l&apos; intelligence artificielle se fonde sur l&apos; hypothèse que le processus de pensée humaine peut être mécanisé . l&apos; étude du raisonnement mécanique — ou « formel » — a un long historique . les philosophes chinois , indiens et grecs ont tous développé des méthodes structurées de déduction formelle au cours du premier millénaire apr. j.-c. leurs idées ont été développées à travers les siècles par des philosophes comme aristote ( qui a donné une analyse formelle du syllogisme ) , euclide ( dont les éléments ont été un modèle de raisonnement formel ) , al-khawarizmi ( auquel on doit l&apos; algèbre et dont le nom a donné « algorithme » ) et les philosophes scolastiques européens comme guillaume d&apos; ockham et duns scottemplate : harvnb . le philosophe majorquin raymond lulle ( 1232 – 1315 ) a conçu plusieurs machines logiques dédiées à la production de connaissance par des moyens logiquestemplate : ouvrage ; lulle décrit ses machines en tant qu&apos; entités mécaniques qui pouvaient combiner des vérités fondamentales et indéniables via de simples opérations logiques , générées par la machine grâce à des mécanismes , de manière à produire tout le savoir possibletemplate : ouvrage . le travail de lulle a une grande influence sur gottfried leibniz , qui a redéveloppé ses idéestemplate : ouvrage . ces philosophes ont commencé à articuler les hypothèses d&apos; un système de symboles physiques qui deviendra par la suite l&apos; un des dogmes de la recherche en ia . on répondit à sa question par les théorèmes d&apos; incomplétude de gödel , la machine de turing et le lambda-calcul de church , le lambda-calcul est particulièrement important en ia , car il a inspiré le langage lisp ( le principal langage utilisé en ia ) . template : harvnb . leur réponse était surprenante à plusieurs titres . tout d&apos; abord , ils prouvèrent qu&apos; il y avait , en fait , des limitations dans ce que la logique mathématique pouvait accomplir . mais aussi ( et plus important encore pour l&apos; ia ) leurs travaux ont suggéré que , sous ces conditions , toute forme de raisonnement mathématique pouvait être mécanisée . la thèse de church impliquait qu&apos; un appareil mécanique , manipulant des symboles aussi simples que des 0 et des 1 , pouvait imiter tout processus concevable de déduction mathématique . cette notion-clé se traduisit par la machine de turing — une simple construction théorique qui capturait l&apos; essence de la manipulation de symboles abstraits . cette invention inspira une poignée de scientifiques qui commencèrent alors à discuter de la possibilité de machines pensantes , la machine de turing : template : harvnb , template : harvnb , template : harvnb et également template : harvnb . les machines à calculer sont apparues dès l&apos; antiquitépar exemple la machine d&apos; anticythère. et ont été améliorées tout au long de l&apos; histoire par de nombreux mathématiciens et ingénieurs , dont leibniz . au début du xixe siècle , charles babbage conçoit la machine à calculer programmable ( la machine analytique ) , sans jamais la construire . à sa suite , ada lovelace spécule que la machine « peut composer des pièces de musique élaborées et scientifiques de toutes complexité et longueurtemplate : harvnb , ada lovelace est généralement considérée comme le premier programmeur grâce aux notes qu&apos; elle a écrites qui détaillent complètement une méthode pour calculer les nombres de bernoulli avec la machine . » . les premiers ordinateurs modernes sont les machines massives de cryptanalyse de la seconde guerre mondiale ( telles que le z3 , l&apos; eniac et le colossus ) template : harvnb , template : harvnb , conçues , en ce qui concerne les deux dernières , à partir des fondements théoriques établis par alan turing et développés par john von neumannvon neumann : template : harvnb . une note sur les sections de cet articleles dates de début et de fin des sections de cet article correspondent à template : harvnb et template : harvnb . les thèmes , tendances et projets sont traités dans la période où le gros du travail a été effectué . . dans les années 1940 et 1950 , une poignée de scientifiques d&apos; une large gamme de domaines ( mathématiques , psychologie , ingénierie , économie et science politique ) ont commencé à discuter de la possibilité de créer un cerveau artificiel . ce domaine de recherche de l&apos; intelligence artificielle a été fondé en tant que discipline académique en 1956 . les toutes premières recherches dans le domaine des machines pensantes ont été inspirées par une convergence d&apos; idées qui se sont progressivement répandues de la fin des années 1930 au début des années 1950 . de récentes recherches en neurologie ont montré que le cerveau était un réseau électrique de neurones qui envoyaient des impulsions de type tout-ou-rien . la cybernétique de norbert wiener a décrit les contrôles et la stabilité dans les réseaux électriques . la théorie de l&apos; information de claude shannon détaille des signaux numériques ( i.e. , signaux tout-ou-rien ) . la théorie du calcul d&apos; alan turing montre que toute forme de calcul peut être représentée numériquement . les relations étroites entre ces idées suggèrent la possibilité de construire un cerveau artificieltemplate : harvnb , template : harvnb , template : harvnb , template : harvnb , template : harvnb . . on peut citer comme exemples de travaux de cette veine les robots tels que les tortues de bristol de william grey walter et la bête de johns hopkins ( en ) catégorie : article contenant un appel à traduction en anglais . ces machines n&apos; utilisent pas d&apos; ordinateurs , d&apos; électronique numérique ni de raisonnement symbolique ; elles étaient entièrement contrôlées par des circuits analogiquestemplate : harvnb , template : harvnb , template : harvnb , template : harvnb , template : harvnb . . walter pitts et warren mcculloch ont analysé des réseaux de neurones artificiels idéaux et ont montré comment ils pourraient effectuer de simples opérations logiques . ils ont été les premiers à évoquer ce que des chercheurs plus tard appelleraient un réseau neuronaltemplate : harvnb , template : harvnb , template : harvnb , template : harvnb et voir aussi template : harvnb . un des étudiants inspirés par pitts et mcculloch était marvin minsky , à l&apos; époque jeune étudiant de 24 ans . en 1951 ( avec dean edmonds ) , il construisit la première machine à réseau neuronal , le snarctemplate : harvnb , template : harvnb et template : harvnb . minsky allait devenir l&apos; un des plus importants leaders et innovateurs en ia des cinquante prochaines années . en 1951 , en utilisant la machine ferranti mark i de l&apos; université de manchester , christopher strachey a écrit un programme de jeu de dames et dietrich prinz un programme de jeu d&apos; échecscf . template : ena brief history of computing sur alanturing.net. . le jeu de dames d&apos; arthur samuel , développé au milieu des années 1950 et au début des années 1960 , a fini par acquérir un niveau suffisant pour défier un bon amateurtemplate : ouvrage . aujourd&apos; hui les programmes de jeux dames sont complets au sens où ils gagnent contre toute défense . . de fait , l&apos; intelligence artificielle dans les jeux sert d&apos; étalon des avancées de l&apos; intelligence artificielle . en 1950 alan turing publie un article mémorable dans lequel il spécule sur la possibilité de créer des machines dotées d&apos; une véritable intelligencetemplate : harvnb , template : harvnb , template : harvnb , template : harvnb , template : harvnb . voir aussi template : harvnb . il remarque qu&apos; il est difficile de définir l &apos; « intelligence » et imagine son célèbre test de turing . si une machine peut mener une conversation ( par téléscripteur interposé ) qu&apos; on ne puisse différencier d&apos; une conversation avec un être humain , alors la machine pouvait être qualifiée d &apos; « intelligente » . cette version simplifiée du problème a permis à turing d&apos; argumenter de manière convaincante qu&apos; une « machine pensante » était au-moins plausible , cet article répondant à toutes les objections classiques à cette propositiontemplate : harvnb déclare que turing répond à toutes les objections majeures à l&apos; ia qui sont apparues dans les années qui suivirent la publication de cet article . . le test de turing a été la première hypothèse sérieuse dans le domaine de la philosophie de l&apos; intelligence artificielle . quand l&apos; accès aux ordinateurs est devenu possible au milieu des années 1950 , des scientifiques , en petit nombre au début , ont compris qu&apos; une machine qui pouvait manipuler des nombres pouvait aussi manipuler des symboles et que cette manipulation de symboles pouvait potentiellement être l&apos; essence-même de la pensée humaine . cela a conduit à l&apos; élaboration des premières machines pensantestemplate : harvnb , template : harvnb . en 1955 , allen newell et ( le futur prix nobel ) herbert simon , avec l&apos; aide de cliff shaw , ont créé le « théoricien logique ( en ) catégorie : article contenant un appel à traduction en anglais » . le programme finira par démontrer 38 des 52 premiers théorèmes des principia mathematica de russell et whitehead , et a même trouvé des démonstrations inédites et élégantestemplate : harvnb , template : harvnb et template : harvnb . simon raconte qu&apos; ils ont « résolu le vénérable problème corps-esprit , expliquant comment un système composé de matière peut avoir des propriétés de l&apos; espritcité dans template : harvnb et template : harvnb » . c&apos; est l&apos; une des premières formulations d&apos; un mouvement philosophique que john searle appellera plus tard « intelligence artificielle forte » : comme les humains , les machines peuvent posséder un esprittemplate : harvnb . en 1949 , warren weaver publie son memorandum sur la traduction automatique des langues naturelles qui est à la fois visionnaire et optimiste sur le futur de ce problème fondamental de l&apos; intelligence artificielle . la conférence de dartmouth de 1956template : harvnb , template : harvnb et template : harvnb a été organisée par marvin minsky , john mccarthy et deux scientifiques seniors : claude shannon et nathan rochester d&apos; ibm . la thèse de la conférence incluait cette assertion : « chaque aspect de l&apos; apprentissage ou toute autre caractéristique de l&apos; intelligence peut être si précisément décrit qu&apos; une machine peut être conçue pour le simulervoir template : harvnb . voir également template : harvnb où crevier déclare que « &#91; cette thèse &#93; est devenue plus tard connue comme l ’ &apos; hypothèse des systèmes de symbole physique &apos; » . l&apos; hypothèse de système de symbole physique a été développée et nommée par newell et simon dans leur article sur le general problem solver . template : harvnb cela comporte une définition plus spécifique de la « machine » en tant qu&apos; agent qui manipule des symboles ( voir aussi la philosophie de l&apos; intelligence artificielle ) . » . parmi les participants on retrouve ray solomonoff , oliver selfridge , trenchard more , arthur samuel , allen newell et herbert simon , qui vont tous créer des programmes importants durant les premières décennies de la recherche en iatemplate : harvnb raconte comment les anciens de la conférence de dartmouth ont dominé les deux premières décennies de la recherche en ia , les surnommant la « faculté invisible » . . à la conférence , newell et simon ont débuté le « théoricien logique » et mccarthy a convaincu l&apos; auditoire d&apos; accepter l&apos; expression « intelligence artificielle » comme intitulé du domaine « je ne jurerai pas et je ne l&apos; avais pas encore vu avant » , mccarthy indique à pamela mccorduck en 1979 . template : harvnb cependant , mccarthy a aussi déclaré sans équivoque « j&apos; ai inventé le terme » dans une interview du cnet . template : harv . la conférence de dartmouth de 1956 a été le moment-clé où l&apos; ia a trouvé son nom , sa mission , ses premières réussites et ses acteurs importants , et est largement considérée comme la naissance de l&apos; iatemplate : harvnb écrit que « la conférence est généralement reconnue comme la date de naissance officielle de la nouvelle science . » . les années qui suivent la conférence de dartmouth sont une ère de découverte , de conquêtes effrénées de nouvelles contrées du savoir . les programmes développés à l&apos; époque sont considérés par la plupart des gens comme simplement « extraordinairesrussell et norvig ont écrit que « c&apos; était extraordinaire dès qu&apos; un ordinateur faisait quoi que ce soit de vaguement malin . » template : harvnb » : des ordinateurs résolvent des problèmes algébriques de mots , démontrent des théorèmes en géométrie et apprennent à parler anglais . à cette époque , peu croient que de tels comportements « intelligents » soient possibles pour des machinestemplate : harvnb , template : harvnb et template : harvnb . les chercheurs font preuve alors d&apos; un optimisme intense dans le privé comme dans leurs articles , ils prédisent qu&apos; une machine complètement intelligente sera construite dans les 20 ans à venirtemplate : harvnb , template : harvnb et template : harvnb . les agences gouvernementales comme la darpa investissent massivement dans ce nouveau domainetemplate : harvnb , template : harvnb . beaucoup de programmes sont couronnés de succès . ils sont nombreux parmi les premiers programmes d&apos; intelligence artificielle à utiliser le même algorithme fondamental . pour remplir certains objectifs ( comme gagner un jeu ou démontrer un théorème ) , ils procèdent pas à pas vers la solution ( en effectuant un mouvement ou une déduction à la fois ) comme s&apos; ils naviguent dans un labyrinthe , revenant en arrière dès qu&apos; ils se heurtent à une impasse . ce paradigme est appelé « raisonnement par tâtonnementsle raisonnement par tâtonnements : template : harvnb , template : harvnb » . la principale difficulté réside dans le fait que , pour beaucoup de problèmes , le nombre de chemins possibles vers la solution est astronomique , c&apos; est la fameuse « explosion combinatoire » . des chercheurs ont alors essayé de réduire l&apos; espace de recherche à l&apos; aide d&apos; heuristiques ou de « règles empiriques » qui éliminent la plupart des chemins dont il est peu probable qu&apos; ils mènent à une solutionheuristique : template : harvnb , template : harvnb . newell et simon essaient de capturer une version générale de cet algorithme dans un programme appelé le general problem solvergps : template : harvnb , template : harvnb , template : harvnb ( « solutionneur de problème général » ) . certains programmes de « recherche » sont capables d&apos; accomplir des tâches jugées à l&apos; époque impressionnantes comme la résolution de problèmes géométriques et algébriques , tels que le geometry theorem prover d&apos; herbert gelernter ( 1958 ) et le saint , écrit par james slagle , un des étudiants de minskytemplate : harvnb et template : harvnb ( 1961 ) . d&apos; autres programmes cherchent à travers des objectifs et sous-objectifs pour planifier des actions , comme le système strips développé à stanford pour contrôler le comportement de leur robot , shakeytemplate : harvnb , template : harvnb , template : harvnb . un but majeur de la recherche en ia est de permettre aux ordinateurs de communiquer en langage naturel comme l&apos; anglais . un des premiers succès était le programme student de bobrow , qui pouvait résoudre des problèmes algébriques rédigés pour lycéenstemplate : harvnb , template : harvnb , template : harvnb . un réseau sémantique représente des concepts ( par ex. « maison » , « porte » ) à l&apos; aide de nœuds et les relations entre les concepts ( par ex. « possède un » ) par des liaisons entre ces nœuds . le premier programme d&apos; ia à utiliser un réseau sémantique a été écrit par ross quilliantemplate : harvnb et la version la plus performante ( et controversée ) a été la conceptual dependency theory de roger schanktemplate : harvnb . eliza de joseph weizenbaum pouvait mener des conversations si réalistes que certains utilisateurs se sont laissé abuser en croyant communiquer avec un être humain et non un programme . en réalité , eliza n&apos; avait aucune idée de ce dont elle parlait . elle donnait simplement une « réponse-bateau » ou reformulait en réponse grâce à quelques règles de grammaire . eliza était le premier agent conversationneltemplate : harvnb , template : harvnb . à la fin des années 1960 , marvin minsky et seymour papert du laboratoire d&apos; ia du mit ont proposé que la recherche d&apos; ia se concentre sur des situations artificiellement simplifiées appelées aussi micro-mondes . ils ont mentionné à juste titre que dans les sciences performantes comme la physique , les principes fondamentaux étaient souvent mieux compris en utilisant des modèles simplifiés tels que des avions sans friction , ou des corps parfaitement rigides . la majorité de la recherche s&apos; est alors centrée sur un « monde-blocs » , qui consistait en un ensemble de blocs colorés de formes et tailles variées disposés sur une surface planetemplate : harvnb , template : harvnb , template : harvnb et template : harvnb . ce paradigme a permis des travaux innovants dans la vision industrielle de gerald sussman ( qui dirigeait l&apos; équipe ) , adolfo guzman , david waltz ( qui inventa la « propagation de contraintes » ) , et surtout patrick winston . au même moment , minsky et papert construisait un bras robotique qui empilait des blocs , insufflant la vie dans ces monde-blocs . la plus grande réussite de ces programmes micro-mondes a été le shrdlu de terry winograd . ce dernier pouvait communiquer en anglais à l&apos; aide de phrases ordinaires , planifier des opérations et les exécutertemplate : harvnb , template : harvnb , template : harvnb . en 1958 , h. simon et allen newell : « d&apos; ici dix ans un ordinateur sera le champion du monde des échecs » et « d&apos; ici dix ans , un ordinateur découvrira et résoudra un nouveau théorème mathématique majeurtemplate : harvnb quoted in template : harvnb . voir aussi template : harvnb » . en 1965 , h. simon : « des machines seront capables , d&apos; ici vingt ans , de faire tout travail que l&apos; homme peut fairetemplate : harvnb quoted in template : harvnb » . en 1967 , marvin minsky : « dans une génération &#91; ... &#93; le problème de la création d&apos; une &apos; intelligence artificielle &apos; en grande partie résolutemplate : harvnb cité dans template : harvnb » . en 1970 , marvin minsky ( dans le magazine life ) : « dans trois à huit ans nous aurons une machine avec l&apos; intelligence générale d&apos; un être humain ordinaireminsky croit fermement qu&apos; on l&apos; a mal cité . voir template : harvnb , template : harvnb et template : harvnb . » . en juin 1963 le mit reçoit une subvention de 2,2 millions de dollars de la toute jeune arpa ( « agence pour les projets de recherche avancée » , qui deviendra plus tard la darpa ) . l&apos; argent est utilisé pour financer le projet mac ( en ) catégorie : article contenant un appel à traduction en anglais qui englobe le « groupe ia » fondé par minsky et mccarthy cinq ans plus tôt . l&apos; arpa continue à fournir trois millions de dollars par an jusqu&apos; aux années 1970template : harvnb . l&apos; arpa fait des subventions similaires au programme de newell et simon à carnegie-mellon et au projet stanford i.a. ( fondé par john mccarthy en 1963 ) template : harvnb . un autre laboratoire important d&apos; ia est établi à l&apos; université d&apos; édimbourg par donald michie en 1965template : harvnb . ces quatre institutions continuent d&apos; être les principaux centres de recherche en ia au niveau académique pendant de nombreuses annéestemplate : harvnb , template : harvnb . mccorduck remarque également que les financements est pour la majeure partie focilisé sur les anciens de la conférence de dartmouth de 1956 . . l&apos; argent est distribué avec peu de contrôle . l&apos; ancien professeur de minsky à harvard , j. c. r. licklider , alors à la tête du « bureau des techniques de traitement de l&apos; information » ( ipto ) et directeur du programme command &amp; control de l&apos; arpa , pense que son organisation doit « financer des personnes , pas des projets ! » et autorise les chercheurs à poursuivre toutes les pistes qui leur semblent intéressantestemplate : harvnb . cela crée une atmosphère de liberté totale au mit qui donne ainsi naissance à la culture hackertemplate : harvnb , et template : harvnb . à licklider ( 1962-64 ) succèdent ivan sutherland ( 1964-66 ) , robert taylor ( 1966-69 ) et lawrence roberts ( 1969-1972 ) , tous proches du mit et dans la continuité de licklider vis-à-vis de l&apos; ia . néanmoins cette attitude non-interventionniste ne dure pas . dans les années 1970 , l&apos; intelligence subit critiques et revers budgétaires , car les chercheurs en intelligence artificielle n&apos; appréhendent pas les difficultés des problèmes auxquels ils sont confrontés . leur immense optimisme a engendré une attente excessive et quand les résultats promis ne se matérialisent pas , les investissements consacrés à l&apos; intelligence artificielle s&apos; étiolenttemplate : harvnb et template : harvnb . dans la même période , le connexionisme a été presque complètement mis sous le boisseau pour 10 ans par la critique dévastatrice de marvin minsky sur les perceptronstemplate : harvnb , template : harvnb , template : harvnb. et dans d&apos; autres directionstemplate : harvnb . au début des années soixante-dix , les capacités des programmes d&apos; ia sont limitées . les plus performants peinent à manipuler des versions simplistes des problèmes qu&apos; ils sont supposés résoudre et tous les problèmes sont , d&apos; une certaine manière , des « broutillestemplate : harvnb » . de fait , les chercheurs en ia font face à plusieurs limites fondamentales insurmontables et bien que certaines limites soient dépassées depuis , d&apos; autres demeurent de vrais obstaclestemplate : harvnb . la puissance et la mémoire de l&apos; époque étaient considérées à juste titre comme un véritable frein à des applications pratiques ; elles suffisaient à peine pour démontrer des modèles simplistes . ainsi , le travail de ross quillian sur le langage naturel est limité à un vocabulaire de vingt mots , car la mémoire ne peut pas en contenir plustemplate : harvnb , voir aussi template : harvnb : template : en template : citation étrangère . en outre , hans moravec se plaint en 1976 du fait que les ordinateurs soient des millions de fois trop faibles pour faire montre d&apos; une quelconque intelligence , qu&apos; ils sont loin d&apos; atteindre le seuil critique minimal . pour mieux faire comprendre ce qu&apos; il entend par seuil , il utilise l&apos; analogie suivante : « en dessous d&apos; un certain niveau de puissance , un avion reste plaqué au sol et ne peut pas décoller du tout , c&apos; est juste impossible » . néanmoins comme la puissance informatique augmente , ça finira par devenir possibletemplate : harvnb . mccarthy a toujours été opposé à moravec là-dessus , dès leurs premiers jours ensemble au laboratoire d&apos; ia de stanford . il a déclaré : « je dirais qu&apos; il y a cinquante ans , les capacités des machines étaient trop faibles , mais il y a trente ans , les capacités des machines n&apos; étaient plus le vrai problème » dans une interview sur cnet . template : harv , cette condition de puissance est bien nécessaire ici , mais pas suffisante , car les problèmes d&apos; ia sont intrinsèquement difficiles et complexes . . quant à la vision par ordinateur , moravec estime que le simple fait d&apos; égaler les capacités de la rétine humaine à détecter les mouvements et les contours en temps réel ( problème simple de nos jours ) nécessiterait un ordinateur générique capable de 109 opérations / seconde ( 1 000 mipstemplate : entemplate : citation étrangère = en ) . par comparaison , l&apos; ordinateur le plus rapide en 1976 , le cray-1 ( vendu entre 5 et 8 000 000 $ ) , est seulement capable d&apos; environ 80 à 130 mips , et un ordinateur de bureau typique de l&apos; époque n&apos; atteint même pas 1 mips . en fait , son estimation , impressionnante pour l&apos; époque , s&apos; est avérée trop optimiste : en 2011 , les applications de vision par ordinateur concrètes ont besoin de dix à mille fois plus de puissance , se situant plutôt entre 10 000 à 1 000 000 mips . en 1972 , à la suite du théorème de cook , richard karp a montré qu&apos; il y avait de nombreux problèmes très difficiles , pour lesquels trouver des solutions optimales était impensable , avec comme conséquence que les problèmes fondamentaux de l&apos; intelligence artificielle ne passeront pas à l&apos; échelletemplate : harvnb et template : harvnb . de nombreuses applications majeures d&apos; intelligence artificielle comme la vision ou le langage naturel ont simplement besoin d&apos; énormes quantités d&apos; information du monde réel : le programme doit avoir une idée de ce qu&apos; il est en train de regarder ou de parler . cela nécessite que le programme ait une connaissance du monde équivalente à celle d&apos; un enfant . les chercheurs découvrent rapidement que cela représente concrètement une large quantité d&apos; information . personne en 1970 ne pouvait construire une telle base de données et personne ne connaissait un programme qui pourrait intégrer autant d&apos; informationtemplate : harvnb , template : harvnb , template : harvnb , template : harvnb , template : harvnb . démontrer des théorèmes ou résoudre des problèmes géométriques est relativement faisable par les ordinateurs , mais une simple tâche comme reconnaître un visage ou traverser une pièce sans collision est extrêmement compliquée . cela explique pourquoi la recherche en vision et en robotique a fait si peu de progrès au milieu des années 1970template : harvnb , template : harvnb . les chercheurs en ia ( comme john mccarthy ) qui se sont servis de la logique ont découvert qu&apos; ils ne pouvaient pas représenter des déductions ordinaires qui impliquaient de la planification ou des raisonnements par défaut sans avoir à modifier la structure de la logique elle-même . ils ont dû développer de nouvelles logiques ( comme les logiques non-monotones et modales ) pour essayer de résoudre ces problèmestemplate : harvnb , template : harvnb . les agences qui ont investi dans la recherche en ia ( comme le gouvernement britannique , la darpa et le nrc , conseil américain de la recherche ) deviennent frustrées par le manque de progrès et finissent par couper pratiquement tous les fonds de recherche fondamentale en ia . ce comportement commence dès 1966 quand un rapport de l&apos; alpacl&apos; alpac ( automatic language processing advisory committee ) est le comité américain de sept scientifiques chargé de surveiller les progrès en matière de traitement du langage. paraît critiquer les efforts de traduction automatisée . après avoir dépensé 20 millions de dollars , le nrc décide de tout arrêtertemplate : harvnb , template : harvnb , template : harvnb et template : harvnb dans success in speech recognition ( reconnaissance en reconnaissance de la parole ) . . en 1973 , le rapport lighthill ( en ) catégorie : article contenant un appel à traduction en anglais sur l&apos; état de la recherche en ia en angleterre a critiqué l&apos; échec lamentable de l&apos; ia à atteindre ses « ambitieux objectifs » et a conduit au démantèlement de la recherche en ia dans ce paystemplate : harvnb , template : harvnb , template : harvnb et voir aussi template : harvnb . ( ce rapport mentionne en particulier le problème d&apos; explosion combinatoire comme une des raisons des échecs de l&apos; iatemplate : harvnb , template : harvnb , john mccarthy a répondu que « le problème de l&apos; explosion combinatoire était connu en ia depuis le départ » dans template : en review of lighthill report ) . quant à la darpa , elle a été extrêmement déçue par les chercheurs travaillant dans le programme speech understanding research à carnegie-mellon et a annulé une subvention annuelle de trois millions de dollarstemplate : harvnb ( où ce constat apparaît ) . d&apos; autres points de vue sont exposés dans template : harvnb et template : harvnb dans success in speech recognition . . vers 1974 , trouver des financements pour des projets d&apos; ia était donc chose rare . hans moravec a attribué la crise aux prédictions irréalistes de ses collègues . « beaucoup de chercheurs se sont retrouvés piégés dans un entrelacs d&apos; exagérations croissantestemplate : harvnb . moravec explique que « leurs promesses initiales à la darpa ont été bien trop optimistes . bien sûr , ce qu&apos; ils livraient derrière était bien loin du compte . mais ils sentaient qu&apos; ils ne pouvaient promettre moins pour leur prochain objectif , et donc ils promirent davantage » . . » un autre problème est apparu : le vote de l&apos; amendement mansfield en 1969 , a mis la darpa sous une pression croissante pour qu&apos; elle ne finance que des « recherches directement applicables , plutôt que des recherches exploratoires fondamentales » . un financement pour de l&apos; exploration créative , en roue libre , tel qu&apos; il avait cours dans les années soixante ne viendrait plus de la darpa . au lieu de cela , l&apos; argent était redirigé vers des projets spécifiques avec des objectifs précis , comme des chars de combat autonomes ou des systèmes de gestion de bataillestemplate : harvnb dans shift to applied research increases investment . bien que le tank autonome fut un échec , le système de gestion de batailles ( appelé « dynamic analysis and replanning tool » ) a été un énorme succès , économisant des milliards dans la première guerre du golfe , remboursant les investissements et justifiant la politique pragmatique de la darpa , au-moins à son niveau . . plusieurs philosophes émettent de fortes objections aux affirmations des chercheurs en ia . un des premiers opposants est john lucas , qui s&apos; appuie sur le théorème d&apos; incomplétude de gödel pour contester l&apos; aptitude des démonstrateurs automatiques de théorèmes à démontrer certaines affirmationscritique de l&apos; ia de lucas et penrose : template : harvnb , template : harvnb , template : harvnb et aussi template : harvnb . hubert dreyfus ridiculise les promesses non tenues des années soixante et critique les hypothèses de l&apos; ia , argumentant que le raisonnement humain avait en fait besoin de très peu de « traitement symbolique » mais surtout de sentiment d ’ embodiment , d&apos; instinct , d&apos; un « savoir-faire » inconscient « savoir-faire » est une expression de dreyfus . il distingue le « savoir-faire » de la « connaissance » ( classique ) , une version moderne de la distinction d&apos; heidegger entre l &apos; « étant disponible » ( template : lang en anglais , template : lang en allemand ) et l &apos; « étant subsistant » ( respectivement template : lang et template : lang ) . template : harv , template : lien : template : harvnb , template : harvnb , template : harvnb et également template : harvnb , template : harvnb , template : harvnb . l&apos; argument de la chambre chinoise avancé par john searle en 1980 , tente de montrer qu&apos; on ne peut pas dire qu&apos; un programme « comprend » les symboles qu&apos; il utilise ( une qualité appelée « intentionnalité » ) . si les symboles n&apos; ont aucun sens pour la machine , on ne peut , dixit searle , qualifier la machine de « pensantecritique de l&apos; ia de searle : template : harvnb , template : harvnb , template : harvnb ainsi que template : harvnb » . ces critiques ne sont pas vraiment prises en considération par les chercheurs en ia , tant certaines ne visent pas l&apos; essence du problème . les questions telles que l&apos; indécidabilité , la complexité inhérente ou la définition de la culture générale semblent beaucoup plus immédiates et graves . ils pensent que la différence entre le « savoir-faire » et l &apos; « intentionnalité » n&apos; apporte presque rien à un programme informatique . minsky dit de dreyfus et searle qu &apos; « ils ont mal compris la question et on devrait les ignorercité dans template : harvnb » . les critiques de dreyfus , qui enseigne au mit , sont accueillies fraîchement : il a plus tard avoué que les chercheurs en ia « n&apos; osaient pas manger avec moi de peur que nous soyons vus ensemblecité dans template : harvnb » . joseph weizenbaum , l&apos; auteur d&apos; eliza , considère , lui , que le comportement de ses collègues à l&apos; égard de dreyfus est non-professionnel et infantile . bien qu&apos; il critique ouvertement les positions de dreyfus , il fait clairement comprendre que ce n&apos; est pas &#91; comme cela &#93; qu&apos; il faut traiter quelqu&apos; un « j&apos; étais alors le seul membre de la communauté d&apos; ia qu&apos; on pouvait voir déjeuner avec dreyfus . et j&apos; ai clairement fait comprendre qu&apos; on ne traitait pas ainsi un autre être humain . » joseph weizenbaum , cité dans template : harvnb . . weizenbaum commence à avoir de sérieux doutes éthiques à propos de l&apos; ia quand kenneth colby écrit doctor , un agent conversationnel thérapeute . weizenbaum est gêné par le fait que colby voit en son programme sans esprit un outil thérapeutique sérieux . une querelle éclate alors , et la situation empire quand colby omet de mentionner la contribution de weizenbaum au programme . en 1976 , weizenbaum publie puissance informatique et raison humaine ( en ) catégorie : article contenant un appel à traduction en anglais qui explique que le mauvais usage de l&apos; intelligence artificielle peut potentiellement conduire à dévaloriser la vie humainecritique de l&apos; ia de weizenbaum : template : harvnb , template : harvnb , template : harvnb et aussi template : harvnb . un perceptron est un type de réseaux neuronaux introduit en 1958 par frank rosenblattfrank rosenblatt a été un condisciple de marvin minsky à la bronx high school of science . comme la plupart des chercheurs en ia de l&apos; époque , il est optimiste , prédisant qu &apos; « un perceptron pourra être capable d&apos; apprendre , de prendre des décisions , et de traduire les langues » . un programme de recherche dynamique sur ces concepts est mené dans les années soixante , mais il s&apos; arrête brutalement après la publication du livre de minsky et papert en 1969 intitulé perceptrons . ce livre constate plusieurs limites à ce que les perceptrons peuvent faire et note plusieurs exagérations dans les prédictions de frank rosenblatt . l&apos; effet du livre est dévastateur : aucune recherche dans le domaine du connexionnisme ne se fait pendant dix ans . ce n&apos; est qu&apos; après une décennie , qu&apos; une nouvelle génération de chercheurs se réattaque au problème , notamment en france , guy perennou et serge castantemplate : harvnb . . hélas ou heureusement rosenblatt , ne verra ni la stagnation , ni la résurgence de la recherche dans le domaine , car il décède lors d&apos; un accident de bateau peu après la publication du livre . john mccarthy introduit l&apos; usage de la logique en ia dès 1958 , dans son advice takeradvice taker ( « preneur de conseils » en français ) est un programme informatique hypothétique décrit par maccarthy dans son template : ouvrage . c&apos; est le premier programme à utiliser la logique en tant qu&apos; outil de représentation et non en tant que matière d&apos; étude . , template : harvnb , template : harvnb . en 1963 , j. alan robinson découvre une méthode relativement simple pour implémenter la déduction . pour cela il invente les concepts de résolution et d&apos; unification . en effet , des implémentations plus directes , comme celles essayées par mccarthy et ses étudiants à la fin des années soixante , se sont révélées particulièrement inefficaces , car les algorithmes requièrent un nombre astronomique d&apos; étapes pour démontrer des théorèmes très simplestemplate : harvnb , template : harvnb . une utilisation plus fructueuse de la logique a été développée dans les années 1970 par alain colmerauer et philippe roussel à l&apos; université de marseille-luminy et robert kowalski à l&apos; université d&apos; édimbourg qui ont créé le langage de programmation prologtemplate : harvnb . prolog utilise un sous-ensemble du calcul des prédicats , les clauses de horn , qui permet des calculs plus efficaces . d&apos; autres chercheurs utilisent des règles de production , notamment les systèmes experts d&apos; edward feigenbaum et les logiciels d&apos; allen newell et herbert simon qui conduit à soar et la théory unifiée de la cognition &#91; « unified theory of cognition » &#93; , &lt; time &gt; 1990 &lt; / time &gt; template : harvnb . l&apos; approche logique a été critiquée dès son apparition . ainsi hubert dreyfus note que les êtres humains se servent rarement de logique quand ils résolvent des problèmes . les expériences de psychologues tels que peter wason , eleanor rosch , amos tversky , daniel kahneman et d&apos; autres corroborent plus ou moins cet avistemplate : harvnb a montré que les humains éprouvent des difficultés sur des problèmes complètement abstraits , mais quand le problème est reformulé pour permettre l&apos; utilisation de l&apos; intelligence sociale plus intuitive , leurs performances augmentent considérablement . ( voir latâche de sélection de wason ) template : harvnb ont montré , eux , que les humains sont médiocres sur des problèmes élémentaires qui impliquent un raisonnement incertain . ( voir la liste de biais cognitifs pour plusieurs exemples ) . le travail d&apos; eleanor rosch est décrit dans template : harvnb . mccarthy a rétorqué que ce que les humains font n&apos; est pas pertinent , expliquant que le but est d&apos; avoir des machines qui peuvent résoudre des problèmes , pas des machines qui pensent comme des humainsune première occurrence de l&apos; opinion de mccathy apparait dans le journal science : « c&apos; est de l&apos; ia , donc peu importe que ce soit psychologiquement correct » template : harv , et il a confirmé 20 ans plus tard son opinion à la conférence ai @ 50 ( dartmouth artificial intelligence conference : the next fifty years ) de 2006 où il explique que « l&apos; intelligence artificielle n&apos; est pas , par définition , la simulation de l&apos; intelligence humaine » template : harv . . mais la critique la plus sévère de l&apos; approche fondée sur la déduction automatique vient du théoricien de l&apos; informatique stephen cook qui montre dans son célèbre article the complexity of theorem-proving procedures ( « la complexité des procédures de démonstration de théorèmes » ) qu&apos; il n&apos; y a pas de procédures automatiques efficaces de démonstration de théorèmes sauf si p = np . parmi les critiques de l&apos; approche de mccarthy on trouve ses collègues à travers le pays au mit marvin minsky , seymour papert et roger schank ont essayé de résoudre des problèmes comme la « compréhension d&apos; une histoire » et la « reconnaissance d&apos; objets » qui requièrent d&apos; une machine de penser comme une personne . pour manipuler des concepts ordinaires comme une « chaise » ou un « restaurant » , elles doivent faire toutes les mêmes hypothèses plus ou moins logiques que les gens font habituellement . malheureusement , de tels concepts imprécis sont difficiles à représenter en logique . gerald sussman observe qu &apos; « utiliser un langage précis pour décrire des concepts imprécis ne rend pas ces derniers plus précistemplate : harvnb » . schank décrit ces approches alogiques comme « brouillonnes ( en ) catégorie : article contenant un appel à traduction en anglais » , qu&apos; il oppose aux paradigmes « élégants ( en ) catégorie : article contenant un appel à traduction en anglais » utilisés par mccarthy , kowalski , feigenbaum , newell et simon « brouillons contre élégants » ( neat vs. scruffy ) : template : harvnb ( qui décrit l&apos; état du débat en 1984 ) . template : harvnb ( qui documente l&apos; usage initial du terme par schank ) . un autre aspect du conflit est intitulé « la distinction procédural / déclaratif » mais ne s&apos; est pas révélé important dans les recherches en ia ultérieures . . en 1975 , minsky remarque que beaucoup de ses pairs « brouillons » utilisent la même approche , à savoir un cadre de travail qui englobe toutes les hypothèses de culture générale ( en ) catégorie : article contenant un appel à traduction en anglais d&apos; un thème donné . par exemple , si on manipule le concept « oiseau » , une pléiade de faits viennent à l&apos; esprit , ainsi on peut prétendre qu&apos; il vole , qu&apos; il mange des vers , etc. . on sait que ces faits ne sont pas toujours vrais et que les déductions à partir de ces faits ne sont pas toutes « logiques » , mais ces ensembles structurés d&apos; hypothèses font partie du contexte de nos discussions ou de nos pensées . minsky appelle ces structures des « cadres » . schank , quant à lui , introduit une variante des cadres qu&apos; il appelle des « scripts » afin de répondre à des questions sur des romans anglophonestemplate : harvnb , template : harvnb et template : harvnb . l&apos; article de minsky sur les cadres : template : harvnb . . certains affirment que quelques années plus tard la programmation orientée objet empruntera aux cadres de l&apos; intelligence artificielle la notion d &apos; « héritage » . dans les années 1980 , des programmes d&apos; ia appelés « systèmes experts » sont adoptés par les entreprises et la connaissance devient le sujet central de la recherche en ia . au même moment , le gouvernement japonais finance massivement l&apos; ia à travers son initiative « ordinateurs de cinquième génération ( en ) catégorie : article contenant un appel à traduction en anglais » . un autre évènement est la renaissance du connexionnisme à travers les travaux de john hopfield et david rumelhart . un système expert est un programme qui répond à des questions ou résout des problèmes dans un domaine de connaissance donné , à l&apos; aide de règles logiques dérivées de la connaissance des experts humains de ce domaine . les tout premiers exemplaires sont développés par edward feigenbaum et ses étudiants . dendral , commencé en 1965 , identifie des composants chimiques à partir de relevés spectrométriques . mycin , développé en 1972 , permet de diagnostiquer des maladies infectieuses du sang . ces programmes confirment la viabilité de l&apos; approchetemplate : harvnb ( dendral ) , template : harvnb , template : harvnb . les systèmes experts se limitent volontairement à un petit domaine de connaissance spécifique ( esquivant ainsi le problème de culture générale ) et leur conception simple permet de construire ces logiciels relativement facilement et de les améliorer une fois déployés . finalement , ces programmes se révèlent utiles , car c&apos; est la première fois que l&apos; intelligence artificielle trouve une application pratiquetemplate : harvnb et template : harvnb . en 1980 , un système expert appelé xcon , dont l&apos; objectif est d&apos; optimiser la configuration des ordinateurs vax à livrer aux clients , est réalisé par carnegie-mellon pour dec . le succès est énorme , car l&apos; entreprise peut économiser dès 1986 jusqu&apos; à 40 millions de dollars par antemplate : harvnb . dès lors , les sociétés de par le monde commencent à développer et à déployer leurs systèmes experts et vers 1985 plus d&apos; un milliard de dollars est dépensé en intelligence artificielle , majoritairement dans les centres industriels de recherche et développement . tout un secteur industriel se crée autour des systèmes experts , dont des constructeurs de matériel informatique comme symbolics et lmi ( lisp machines , inc . ) et des éditeurs de logiciels tels que intellicorp et aiontemplate : harvnb , template : harvnb et template : harvnb . la puissance des systèmes experts vient de l&apos; expertise qu&apos; ils contiennent . ils font partie d&apos; une nouvelle direction de recherche en ia qui a gagné du terrain dans les années 1970 . « les chercheurs en ia commençaient à soupçonner — avec réticence , car ça allait contre le canon scientifique de parcimonie — que l&apos; intelligence puisse très bien être basée sur la capacité à utiliser une large quantité de savoirs divers de différentes manièrestemplate : harvnb » remarque pamela mccorduck . « la grande leçon des années soixante-dix a été que les comportements intelligents dépendaient énormément du traitement de la connaissance , parfois d&apos; une connaissance très avancée dans le domaine d&apos; une tâche donnéetemplate : harvnb . » les systèmes de bases de connaissance et l&apos; ingénierie des connaissances sont devenus centraux dans la recherche en intelligence artificielle des années 1980révolution de la connaissance : template : harvnb , template : harvnb . les années 1980 ont aussi vu la naissance de cyc , la première tentative d&apos; attaque frontale du problème de culture générale : une base de données gigantesque a été créée dans le but de contenir tous les faits triviaux qu&apos; une personne moyenne connait . douglas lenat , qui a démarré et dirigé le projet , argumente qu&apos; il n&apos; y a aucun raccourci ― le seul moyen pour des machines de connaître la signification de concepts humains était de leur apprendre , un concept à la fois , et manuellement . on s&apos; attend bien sûr à ce que le projet se déroule sur plusieurs décenniescyc : template : harvnb , template : harvnb , template : harvnb et template : harvnb . en 1981 , le ministère japonais de l&apos; économie , du commerce et de l&apos; industrie réserve 850 millions de dollars pour le projet des ordinateurs de cinquième génération ( en ) catégorie : article contenant un appel à traduction en anglais . leur objectif est d&apos; écrire des programmes et de construire des machines qui peuvent tenir des conversations , traduire , interpréter des images et raisonner comme des êtres humainstemplate : harvnb , template : harvnb , template : harvnb et voir également template : harvnb . au grand dam des tenants de l&apos; approche brouillonne ( en ) catégorie : article contenant un appel à traduction en anglais , ils choisissent prolog comme langage informatique principal de leur projettemplate : harvnb , qu&apos; ils modifient d&apos; ailleurs assez profondément pour qu&apos; il s&apos; adapte à leur besoin . d&apos; autres pays répondent avec de nouveaux programmes équivalents . le royaume-uni démarre le projet alvey ( en ) catégorie : article contenant un appel à traduction en anglais de 350 millions de livres . un consortium d&apos; entreprises américaines forment la microelectronics and computer technology corporation ( ou mcc ) pour financer des projets en informatique et en intelligence artificielle à grande échelletemplate : harvnb . , . la darpa a aussi réagi en fondant la strategic computing initiative ( initiative informatique stratégique ) et en triplant ses investissements en ia entre 1984 et 1988template : harvnb , template : harvnb dans shift to applied research increases investment . en 1982 , le physicien john hopfield a été capable de démontrer qu&apos; un certain type de réseau neuronal ( désormais appelé un « réseau de hopfield » ) pouvait apprendre et traiter de l&apos; information d&apos; une manière totalement inédite . au cours de la même période , david rumelhart a rendu populaire une nouvelle méthode de formation des réseaux neuronaux appelée « rétropropagation du gradient » ( découverte quelques années avant par paul werbos ) . ces deux nouvelles découvertes ont fait renaître le champ du connexionnisme qui avait été largement abandonné depuis 1970template : harvnb , template : harvnb . . le tout jeune domaine a été unifié et inspiré par l&apos; apparence du traitement parallèle distribué de 1986 — une collection d&apos; articles en deux volumes éditée par rumelhart et le psychologue mcclelland . les réseaux neuronaux deviendront un succès commercial dans les années 1990 , quand on commencera à les utiliser comme moteurs d&apos; applications telles que la reconnaissance optique de caractères et la reconnaissance vocale , template : harvnb . . la fascination de la communauté économique pour l&apos; intelligence artificielle a gonflé puis chuté dans les années 1980 en suivant le schéma classique d&apos; une bulle économique . l&apos; effondrement de l&apos; ia a eu lieu au niveau de la perception que les investisseurs et les agences gouvernementales en avaient — le domaine scientifique continue ses avancées malgré les critiques . rodney brooks et hans moravec , chercheurs dans le domaine voisin de la robotique , plaident pour une approche entièrement neuve de l&apos; intelligence artificielle . l&apos; expression « hiver de l&apos; ia » a circulé parmi les chercheurs qui , ayant déjà vécu les coupes de budget de 1974 , réalisent avec inquiétude que l&apos; excitation autour des systèmes experts est hors de contrôle et qu&apos; il y aurait sûrement de la déception derrièretemplate : harvnb . l ’ hiver de l&apos; ia est apparu pour la première fois dans le nom d&apos; un séminaire sur le sujet de l ’ association for the advancement of artificial intelligence . . leurs craintes sont effectivement fondées : entre la fin des années 1980 et le début des années 1990 , l&apos; intelligence artificielle a subi une série de coupes budgetaires . les premiers indices d&apos; une tempête à venir ont été le brusque effondrement du marché du matériel informatique spécialiste de l&apos; intelligence artificielle en 1987 . les ordinateurs de bureau d&apos; apple et ibm ont progressivement amélioré leur vitesse et leur puissance et en 1987 ils deviennent plus performants que les fleurons du marché , tels que la meilleure machine lisp de symbolics . il n&apos; y a donc plus aucune raison de les acheter . du jour au lendemain , une industrie d&apos; un demi-milliard de dollars disparait totalementtemplate : harvnb , template : harvnb . finalement , les premiers systèmes experts à succès comme le xcon ont un coût de maintenance trop élevé . ils sont difficiles à mettre à jour , ils ne peuvent pas apprendre , ils sont trop « fragiles ( en ) catégorie : article contenant un appel à traduction en anglais » ( ainsi , ils peuvent faire des erreurs grotesques quand les paramètres sortent des valeurs habituelles ) , et s&apos; empêtrent dans des problèmes ( tels que le problème de qualification ) . les systèmes experts se sont révélés utiles , mais uniquement dans des contextes très spécifiquestemplate : harvnb ( qui cite des raisons institutionnelles pour leur ultime échec ) , template : harvnb ( qui cite ici la difficulté de la maintenance du savoir , c&apos; est-à-dire apprentissage et mise à jour continus ) , template : harvnb ( qui met l&apos; accent sur l&apos; extrême sensibilité et l&apos; incapacité à manipuler des qualifications limites ) . à la fin des années 1980 , la strategic computing initiativela strategic computing initiative ( « initiative informatique stratégique » ) de la darpa finance pour plus d &apos; 1 milliard de $ de projets de recherche en matériel informatique de pointe et en intelligence artificielle sur la décennie 1983-1993 , depuis la conception et fabrication de puces à des logiciels d&apos; intelligence artificielle. de la darpa a complètement et abruptement coupé ses subsides à l&apos; intelligence artificielle . une nouvelle direction de la darpa ayant conclu que l&apos; intelligence artificielle n&apos; est plus de « dernière mode » , elle a redirigé les subventions vers des projets plus propices à des résultats rapidestemplate : harvnb . vers 1991 , les objectifs impressionnants listés en 1981 par le japon pour ses ordinateurs de cinquième génération n&apos; ont pas été atteints . d&apos; ailleurs certains d&apos; entre eux , comme le fait de « mener une conversation ordinaire » ne l&apos; ont toujours pas été vingt ans plus tardtemplate : harvnb , template : harvnb . mccorduck écrit à ce sujet : « deux décennies et demie plus tard , nous avons pu observer que le japon n&apos; a pas réussi à remplir tous ses objectifs ambitieux . » . comme pour d&apos; autres projets en intelligence artificielle , la barre a été placée beaucoup trop haut . l&apos; approche ravive des concepts nés de la cybernétique et de la régulation qui ont perdu de leur impact depuis les années soixante . un des précurseurs , david marr , est arrivé au mit à la fin des années 1970 fort de réussites passées en neuroscience théorique afin d&apos; y diriger le groupe étudiant la vision . il réfute toutes les approches symboliques ( à la fois la logique de mccarthy et les cadres de minsky ) , arguant que l&apos; intelligence artificielle a besoin de comprendre la machinerie physique de la vision par le bas avant qu&apos; un traitement symbolique puisse être mis en place . son travail a été brusquement interrompu par la leucémie qui l&apos; a frappé en 1980 . ) template : harvnb . . dans un article de 1990 intitulé elephants don&apos; t play chesstemplate : enelephants don&apos; t play chess ( pdf ) ( « les éléphants ne jouent pas aux échecs » ) , le chercheur en robotique rodney brooks vise directement l&apos; hypothèse de système symbolique physique , expliquant que les symboles ne sont pas toujours nécessaires car « le monde est son propre modèle et c&apos; est le meilleur . il est toujours parfaitement à jour . il contient toujours tous les détails nécessaires . ce qu&apos; il faut , c&apos; est le mesurer correctement de manière répétéetemplate : harvnb » . dans les années 1980 et 1990 , beaucoup de cogniticiens rejettent également le modèle de traitement symbolique de l&apos; esprit en expliquant que le corps est essentiel dans le raisonnement , une thèse appelée embodimentvoir , par exemple , template : harvnb . le champ de l&apos; intelligence artificielle , avec plus d&apos; un demi-siècle derrière lui , a finalement réussi à atteindre certains de ses plus anciens objectifs . on a commencé à s&apos; en servir avec succès dans le secteur technologique , même sans avoir vraiment été mise en avant . quelques réussites sont venues avec la montée en puissance des ordinateurs et d&apos; autres ont été obtenues en se concentrant sur des problèmes isolés spécifiques et en les approfondissant avec les plus hauts standards d&apos; intégrité scientifique . néanmoins , la réputation de l&apos; ia , dans le monde des affaires au-moins , est loin d&apos; être parfaite . en interne , on n&apos; arrive pas à vraiment expliquer les raisons de l&apos; échec de l&apos; intelligence artificielle à répondre au rêve d&apos; un niveau d&apos; intelligence équivalent à l&apos; homme qui a captivé l&apos; imagination du monde dans les années 1960 . tous ces facteurs expliquent la fragmentation de l&apos; ia en de nombreux sous-domaines concurrents dédiés à une problématique ou une voie précise , allant même parfois jusqu&apos; à choisir un nom qui évite l&apos; expression désormais souillée d &apos; « intelligence artificielletemplate : harvnb discute cet éclatement et la mise au ban des objectifs initiaux de l&apos; ia . » . l&apos; ia a du coup été à la fois plus prudente mais aussi plus fructueuse que jamais . le 11 mai 1997 , deep blue est devenu le premier système informatique de jeu d&apos; échecs à battre le champion du monde en titre , garry kasparovtemplate : harvnb . en 2005 , un robot de stanford a remporté le darpa grand challenge en conduisant de manière autonome pendant 131 milles sur une piste de désert sans avoir fait de reconnaissance préalabletemplate : en page d&apos; accueil de darpa grand challenge . deux ans plus tard , une équipe de carnegie-mellon remporte le darpa urban challenge , cette fois en navigant en autonome pendant 55 milles dans un environnement urbain tout en respectant les conditions de trafic et le code de la routetemplate : enarchive du darpa grand challenge . en février 2011 , dans un match de démonstration du jeu télévisé jeopardy ! , les deux plus grands champions de jeopardy ! , brad rutter et ken jennings ont été battus avec une marge confortable par le système de questions-réponses conçu par ibm , au centre de recherche watsontemplate : article . un nouveau paradigme , les « agents intelligents » , s&apos; est progressivement imposé au cours des années 1990template : harvnb , template : harvnb , où ils écrivent : « la notion d&apos; agent-entier est désormais largement acceptée dans le domaine . » on discute du paradigme de l&apos; agent intelligent dans les textes majeurs de l&apos; ia , comme template : harvnb , template : harvnb et template : harvnb . bien que les premiers chercheurs aient proposé des approches modulaires de type « diviser pour régner » en intelligence artificiellele modèle d&apos; acteur de carl hewitt est le précurseur de la définition moderne des agents intelligents . template : harv john doyle template : harv et le classique the society of mind de marvin minsky template : harv ont tous les deux utilisés le terme « agent » . parmi d&apos; autres propositions « modulaires » , on trouve l &apos; « architecture par prémisses » de rodney brook , la programmation orientée objettemplate : etc. . , l&apos; agent intelligent n&apos; a pas atteint sa forme moderne avant que judea pearl , allen newell et d&apos; autres n&apos; y amènent des concepts de théorie de la décision et d&apos; économietemplate : harvnb . quand la définition économique de l&apos; agent rationnel s&apos; est combinée à la définition informatique de l&apos; objet ou encore du module , le paradigme de l&apos; agent intelligent s&apos; installe . un agent intelligent est un système qui perçoit son environnement et entreprend des actions qui maximisent ses chances de réussite . grâce à cette définition , de simple programmes qui résolvent des problèmes spécifiques sont des « agents intelligents » , tout comme le sont des êtres humains et des organisations d&apos; êtres humains comme les entreprises . le paradigme de l&apos; agent intelligent définit l&apos; intelligence artificielle comme l &apos; « étude des agents intelligents » . c&apos; est une généralisation de certaines des premières définitions de l&apos; ia : elle va au-delà de l&apos; étude de l&apos; intelligence humaine ; elle étudie tout type d&apos; intelligencec&apos; est cette définition de l&apos; intelligence artificielle qui est globalement acceptée par tous les textes du template : s- , cf. template : harvnb et template : harvnb . . ce paradigme a ouvert aux chercheurs la voie vers l&apos; étude de problèmes isolés ; les solutions trouvées sont à la fois vérifiables et utiles . un langage commun permet de décrire les problèmes et partager leurs solutions entre les uns et les autres , et d&apos; autres domaines ont également utilisé ce concept d&apos; agents abstraits , comme l&apos; économie et la régulation . on pense qu&apos; une « architecture agent » ( comme la soar de newell ) permettrait un jour à des chercheurs de construire des systèmes plus polyvalents et intelligents à base d&apos; agents intelligents , template : harvnb . les chercheurs en intelligence artificielle développent et utilisent des outils mathématiques sophistiqués comme jamais auparavanttemplate : harvnb , template : harvnb . ils prennent conscience que de nombreux problèmes que l&apos; intelligence artificielle doit résoudre ont déjà été traités dans d&apos; autres domaines comme les mathématiques , l&apos; économie ou la recherche opérationnelle . en particulier , les mathématiques permettent à la fois d&apos; améliorer la collaboration avec des disciplines plus solidement fondées et conduisent à des fertilisations croisées et à la collecte de données mesurables et démontrables ; l&apos; intelligence artificielle progresse vers l &apos; « orthodoxie scientifique » . russell et norvig 2003 qualifie cela de rien de moins qu&apos; une « révolution » et de « victoire des élégants ( en ) catégorie : article contenant un appel à traduction en anglaistemplate : harvnb , template : harvnb : « au moment où j&apos; écris ces lignes , l&apos; intelligence artificielle bénéficie d&apos; une hégémonie élégante . » » . le livre-charnière de 1988 de judea pearltemplate : harvnb intègre les probabilités et la théorie de la décision avec les réseaux bayésiens , les modèles de markov cachés , la théorie de l&apos; information , le calcul stochastique et plus généralement l&apos; optimisation mathématique . des descriptions mathématiques s&apos; appliquent aux paradigmes primordiaux de l &apos; « intelligence computationnelle » comme les réseaux neuronaux et les algorithmes évolutionnistes. et le moteur de recherche de googletemplate : harvnb , template : harvnb . en 1968 , arthur c. clarke et stanley kubrick imaginent que dès l&apos; année 2001 , une machine aura une intelligence comparable , voire excédant les capacités des êtres humains . le personnage qu&apos; ils créent , hal 9000 , s&apos; appuie sur une opinion répandue chez nombre de chercheurs en intelligence artificielle à savoir qu&apos; une telle machine existera en 2001template : harvnb . marvin minsky s&apos; interroge : « pourquoi n&apos; avons-nous pas eu hal en 2001il continue ainsi : « la réponse est , je crois que l&apos; on aurait pu … j&apos; ai assisté une fois à une conférence internationale sur le &#91; s &#93; réseau &#91; x &#93; neurona &#91; ux &#93; . il y avait quarante mille inscrits … mais … si vous faisiez une conférence internationale sur , par exemple , les représentations multiples du raisonnement de culture générale , je n&apos; ai réussi à trouver que 6 ou 7 personnes dans le monde entier . » template : harvnb ? » et pense que des problèmes centraux comme le raisonnement de culture générale , sont négligés , car la plupart des chercheurs se concentrent sur des aspects tels que des applications commerciales des réseaux neuronaux ou des algorithmes génétiques . john mccarthy , d&apos; un autre côté , blâme encore le problème de qualificationtemplate : harvnb . pour ray kurzweil , le problème réside dans le manque de puissance de calcul et , en s&apos; appuyant sur la loi de moore , il prédit que les machines avec une intelligence comparable à l&apos; humain arriveront vers 2030template : harvnb . la recherche en intelligence artificielle en france débute vers la fin des années soixante dix , avec notamment le gr 22 ( appelé aussi groupe de recherche claude-françois picard où travaillent jacques pitrat et jean-louis laurière ) à paris , le gia ( sic ) ( autour d&apos; alain colmerauer ) à marseille , le limsi à orsay , le crin à nancy , le cerfia à toulouse et le laboria ( autour de gérard huet et dans un domaine très fondamental ) à rocquencourt . ( en ) cet article est partiellement ou en totalité issu de l ’ article de wikipédia en anglais intitulé « history of artificial intelligence » ( voir la liste des auteurs ) . ( en ) cnn , « ai set to exceed human brain power » , cnn.com , ‎ &lt; time class = &quot; nowrap &quot; datetime = &quot; 2006-07-26 &quot; &gt; 26 juillet 2006 &lt; / time &gt; ( lire en ligne ) . ( en ) jack copeland , micro-world ai , &lt; time &gt; 2000 &lt; / time &gt; ( lire en ligne ) . ( en ) patty tascarella , « robotics firms find fundraising struggle , with venture capital shy » , pittsburgh business times , ‎ &lt; time class = &quot; nowrap &quot; datetime = &quot; 2006-08-11 &quot; &gt; 11 août 2006 &lt; / time &gt; ( lire en ligne ) .
