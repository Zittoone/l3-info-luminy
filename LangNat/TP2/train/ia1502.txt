pour les articles homonymes , voir cbr . le raisonnement à partir de cas ( ràpc ) ( nommé en anglais case-based _ reasoning ( cbr ) ) est un type de raisonnement qui copie le comportement humain qui consiste à faire naturellement appel à l&apos; expérience pour résoudre les problèmes de la vie quotidienne , en se remémorant les situations semblables déjà rencontrées et en les comparant à la situation actuelle pour construire une nouvelle solution qui , à son tour , s ’ ajoutera à l&apos; expérience . ce type de raisonnement résout les problèmes en retrouvant des cas analogues dans sa base de connaissances et en les adaptant au cas considéré . cette technologie est apparue il y a une quinzaine d ’ années &#91; quand ? &#93; mais les travaux initiaux sur le sujet remontent cependant aux expériences de schank et abelson en 1977 à l&apos; université yale . elle reste pourtant encore assez méconnue par rapport à d ’ autres technologies appartenant au domaine des sciences cognitives comme le data mining . elle diffère de cette dernière par son approche . en effet , ici , on n ’ utilise qu ’ indirectement les données pour retrouver les cas proches , à partir desquels on va générer une solution . un système ràpc dispose d ’ une base de cas . chaque cas possède une description et une solution . pour utiliser ces informations , un moteur est aussi présent . celui-ci va retrouver les cas similaires au problème posé . après analyse , le moteur fournit une solution adaptée qui doit être validée . enfin le moteur ajoute le problème et sa solution dans la base de cas . pour développer un système de raisonnement par cas digne de ce nom , il est donc nécessaire de trouver une solution efficace à chacun de ces problèmes . la révision et l ’ apprentissage sont deux autres problèmes qui découlent des trois premiers . la représentation des cas prend une place importante dans la réalisation d ’ un système ràpc . en effet cette représentation va déterminer l ’ efficacité et la rapidité de la recherche des cas dans la base . il est donc nécessaire de choisir les informations à stocker dans chaque cas et de trouver sous quelle forme . tous les ràpc n ’ utilisent pas forcément chacun des types d ’ informations . la description du problème et la solution apportée sont des éléments indispensables . certaines caractéristiques ( les plus discriminantes ) seront utilisées en tant qu ’ index lors de la recherche et l ’ ajout de cas . les index doivent être suffisamment concrets et abstraits à la fois pour qu ’ ils concernent un maximum de cas et qu ’ ils soient réutilisables dans les raisonnements futurs . ils doivent aussi permettre de déduire rapidement les cas . types classiques : texte , entier , réel , booléen , date . type symbole : il permet d ’ énumérer une liste de symboles qui seront stockés dans un arbre . la racine de l ’ arbre contiendra le symbole le plus général et les feuilles les symboles les plus spécifiques . type cas : il permet de référencer des cas qui sont des sous parties du cas considéré . type formule : la valeur de cet attribut est le résultat du calcul d ’ une formule . type liste : ce type est une liste d ’ objets utilisant les types précédents . ensuite il faut construire un modèle d ’ organisation et d ’ indexation pour relier les cas entre eux . ce modèle doit posséder certaines qualités . tout d ’ abord il est nécessaire que l ’ ajout assure l ’ accessibilité aux anciens cas . la recherche de cas similaires doit conserver une complexité constante au fur et à mesure que la base de cas se remplit . un système de ràpc n ’ étant intéressant qu ’ avec une base importante de cas , il faut évidemment envisager une solution permettant de retrouver rapidement les cas similaires . généralement on utilise l ’ indexation pour cette raison . commençons tout d ’ abord par le modèle le plus simpliste : l ’ organisation linéaire . cette organisation n ’ est pas utilisée pour gérer l ’ ensemble de la mémoire des cas . cependant elle peut être implicitement combinée à d ’ autres modèles plus complexes au niveau de petits sous ensembles de cas . il est possible d ’ organiser la mémoire sous la forme d ’ un arbre de décision : chaque nœud correspond à une question sur l ’ un des index et les fils correspondent aux différentes réponses . pour être le plus efficace possible l ’ arbre doit poser les questions dans le bon ordre et être le moins profond possible . cet arbre doit être construit dynamiquement . la meilleure méthode pour le construire est d ’ utiliser le data mining . un autre modèle consiste à construire la mémoire sous la forme d ’ une hiérarchie de prototypes . un prototype permet de décrire des conditions sur des caractéristiques des cas . tous les cas vérifiant ces conditions sont associés à ce prototype . les prototypes sont organisés dans une hiérarchie d ’ héritage . on peut ainsi spécifier des prototypes généraux desquels héritent des prototypes plus spécifiques . en combinant les arbres de décision à cette hiérarchie de prototypes , on obtient une structure intéressante . les prototypes « terminaux » ne stockent alors plus leurs cas dans une liste mais dans un arbre de décision . la hiérarchie de prototype représente la connaissance a priori du système et les arbres de décision générés dynamiquement permettent une structure assez flexible . les normes : les caractéristiques communes à chacun des cas indexés sous l ’ épisode généralisé . les index : les éléments discriminant les cas contenus dans l ’ épisode généralisé . un index possède deux champs : son nom et sa valeur . il peut pointer vers un autre épisode ou simplement vers un cas . les cas : la connaissance du système . on y accède donc par l ’ intermédiaire d ’ index . le schéma donne une idée du modèle à mémoire dynamique . il possède une structure proche d ’ un arbre . on retrouve bien les trois types d ’ objets énoncés , à la différence près qu ’ une distinction est faite entre les index et les valeurs . on peut remarquer aussi qu ’ il est possible d ’ atteindre certains cas de différentes manières . ce modèle est donc redondant . la recherche des cas similaires s ’ effectue à partir du nœud racine . on va chercher l ’ épisode généralisé possédant le plus de caractéristiques en commun avec le problème courant . ensuite on parcourt les index , qui représentent les caractéristiques absentes de la norme de l ’ épisode généralisé sur lequel on travaille . le couple index-valeur sélectionné est celui qui est le plus similaire avec le problème . à partir de celui-ci , soit on arrive à un autre épisode généralisé , dans ce cas , on recommence le processus , soit on obtient un cas similaire au problème posé . la procédure d ’ ajout de nouveaux cas fonctionne d ’ une manière proche à la recherche de cas similaires . en effet le parcours du graphe est identique . lorsque l ’ on a trouvé l ’ épisode généralisé ayant le plus de normes en commun avec le cas courant , on effectue l ’ ajout . pour cela , il faut générer un couple index-valeur distinguant le nouveau cas aux autres fils de l ’ épisode généralisé . s ’ il existe déjà un cas possédant le même couple , on crée un nouvel épisode généralisé contenant ces deux cas . on obtient donc un réseau discriminant à l ’ aide des index qui permettent de retrouver les cas . les épisodes généralisés sont principalement des structures d ’ indexation . les normes permettent de représenter une connaissance générale des cas sous-jacents alors que les couples index-valeur définissent les spécificités . cependant , ce processus d ’ indexation peut mener à une croissance exponentielle du nombre d ’ index par rapport au nombre de cas . on adjoint donc généralement certaines limites dans le choix des index même si cela entraîne une baisse de performances . ce modèle est une alternative au modèle précédent . ici , un cas est aussi appelé exemple . l ’ idée directrice est que la réalité devrait être définie de manière extensive par des cas . les caractéristiques décrites généralement par un nom et une valeur , possèdent un niveau d ’ importance fonction de l ’ adhésion d ’ un cas à une catégorie . de rappel : reliant une caractéristique à une catégorie ou un cas . d ’ exemple : reliant une catégorie aux cas auxquels elle est associée . de différence : reliant deux cas ne différant que d ’ un nombre restreint de caractéristiques . le schéma ci-dessous illustre les différents types de liens disponibles . cependant il ne représente qu ’ une seule catégorie . il faut donc ajouter que les exemples peuvent appartenir à plusieurs catégories . la recherche des cas similaires consiste à retrouver la catégorie qui possède les caractéristiques les plus proches du nouveau problème . lorsqu ’ elle est trouvée , on retourne les cas les plus prototypiques . avant la recherche des cas similaires , il est nécessaire d ’ étudier le problème posé . il faut identifier ses caractéristiques mais aussi son contexte si cela est possible . si certaines informations sont manquantes , il est possible de négliger certaines caractéristiques ou d ’ interroger l ’ utilisateur . c ’ est au cours de cette étape , préambule à la recherche à proprement parler , que le système ràpc doit essayer de déterminer et corriger les données bruitées ou incohérentes . pour cela , on peut faire appel à des outils de datacleaning . il est aussi possible d ’ essayer de déduire des caractéristiques à partir d ’ autres à l ’ aide d ’ un modèle de connaissance . toutes ces opérations requièrent généralement l ’ approbation de l ’ utilisateur avant de passer à l ’ étape suivante . il est possible de choisir les index lors de la réalisation du système ràpc , on parle alors d ’ index statiques . lorsqu ’ ils sont sélectionnés automatiquement ou par l ’ intermédiaire d ’ une interface homme-machine , ils sont qualifiés de dynamiques . enfin certains ràpc donnent une importance aux différents index . l ’ étape de filtrage consiste à réduire au préalable le nombre de cas utilisés dans la recherche . cette étape peut être sautée pour passer directement à la sélection . il existe différents algorithmes mais ceux-ci sont souvent liés à un type de représentation des cas . par exemple pour la représentation en mop , c&apos; est-à-dire la représentation à mémoire dynamique , le filtrage va consister à réduire l ’ ensemble de cas à un mop proche du problème . on va l ’ atteindre en descendant successivement les index . à partir de l ’ ensemble de cas obtenus lors de l ’ étape de filtrage , on va construire un nouvel ensemble de cas similaires . pour cela , on peut utiliser l ’ algorithme des plus proches voisins ( nearest neighbour ) ou d ’ autres heuristiques qui vont nous permettre de mesurer la similarité entre le problème posé et les cas candidats . en fait , on ne va comparer le nouveau cas aux autres que par l ’ intermédiaire des index . à partir de la similarité sur chaque index , on obtiendra la similarité globale . il faut donc que chaque index dispose d ’ une fonction mesurant la similarité entre deux valeurs de son ensemble de recherche . ceci peut poser problème si les cas sont constitués de types complexes symboliques . mais ce problème n ’ est pas spécifique au ràpc , il est caractéristique des recherches en analogie . il existe donc souvent déjà une méthode pour calculer la similarité pour chaque type de données . généralement la fonction de calcul retourne une valeur appartenant à un intervalle . dans les systèmes ràpc simples , lorsque l ’ on a retrouvé un cas similaire , on réutilise directement la solution qu ’ il propose pour le problème courant . dans ce type de systèmes , on considère que les similarités sont suffisantes et que l ’ on peut négliger les différences entre le cas trouvé et le problème . cette façon de procéder est quand même peu satisfaisante . il est rare que l ’ on trouve un cas identique au problème , il est alors souvent nécessaire d ’ adapter les solutions préexistantes . l ’ adaptation consiste donc à construire une nouvelle solution à partir du problème courant et des cas similaires trouvés . cette phase met l ’ accent sur les différences entre les cas trouvés et le problème et sur l ’ information utile à transférer à la nouvelle solution . l ’ adaptation transformationnelle consiste à réutiliser directement les solutions des cas passés . ce type d ’ adaptation ne prend pas en compte la manière dont les solutions des cas similaires ont été générées . on utilise des lois d ’ adaptation pour transformer les anciennes solutions . ces lois sont dépendantes du domaine d ’ application du système ràpc . on peut utiliser ce type d ’ adaptation lorsque l ’ on dispose pour chaque cas stocké dans la base des étapes du raisonnement menant aux solutions . l ’ adaptation dérivative consiste à appliquer le même raisonnement au nouveau problème . lors de la construction de la nouvelle solution , on va privilégier les chemins pris par les anciennes solutions sélectionnés et éviter les chemins infructueux . cependant le nouveau cas est différent , de nouveaux sous-objectifs seront poursuivis . il existe d ’ autres types d ’ adaptations possibles . on peut par exemple faire appel à des cas d ’ adaptation . cela revient à considérer un système cbr dédié à l ’ adaptation en général . il ne serait spécialisé vers aucun domaine en particulier et contiendrait des cas assez abstraits d ’ adaptation . une autre approche est de classifier les cas dans une hiérarchie . cette approche permet à des cas d ’ être réutilisés avec un niveau d ’ abstraction le plus élevé possible , ce qui les rend facilement applicable à une nouvelle situation . pour adapter les sous parties d ’ une solution , le système se référera au contexte de la solution générale . après sa génération par le système , la solution du problème est testée . cette étape est généralement externe au ràpc . suivant le domaine , on peut faire appel à un logiciel de simulation ou à un expert . n ’ oublions pas que la durée d ’ une évaluation peut être très longue , notamment dans le domaine médical pour le test de traitements . si cette évaluation est concluante , on va retenir cette nouvelle expérience . c ’ est la phase d ’ apprentissage que nous étudierons par la suite . cependant si la solution n ’ est pas satisfaisante , il faut la réparer ou tout au moins expliquer les raisons de l ’ échec . c ’ est la phase de révision . la phase de révision va donc en premier lieu essayer de déterminer les raisons de l ’ échec . pour cela , on peut essayer d ’ expliquer pourquoi certains buts n ’ ont pas été atteints . les informations collectées vont enrichir une mémoire d ’ échec utilisée lors de la phase d ’ adaptation . ainsi lors des prochaines générations de solutions , le système ne répétera pas ses erreurs . lorsque le système a déterminé les raisons de l ’ échec de la solution , il est possible d ’ essayer de la réparer . cette étape de réparation peut être vue comme une autre fonction d ’ adaptation . la seule différence est que dans la réparation , on travaille à partir d ’ une solution incorrecte mais adaptée au problème au lieu de solutions correctes inadaptées . on va s ’ appuyer sur les explications de l ’ échec pour réaliser les modifications . c ’ est la dernière étape du cycle du ràpc . au cours de cette phase , le nouveau cas et sa solution validée vont être ajoutés à la base de cas . il faut donc déterminer quelles informations doivent être sauvegardées et sous quelle forme , et comment indexer ce nouveau cas dans la base . si le cas a été résolu sans l ’ aide des cas préexistants , par exemple à l ’ aide des connaissances d ’ un expert , il faut à coup sûr l ’ ajouter dans la base . par contre , si la solution a été générée à partir d ’ anciens cas , la procédure est plus complexe . en effet il ne sera alors pas forcément nécessaire de rajouter directement le nouveau cas . on peut par exemple généraliser le cas antérieur , origine de la nouvelle solution . d ’ une autre manière , ce nouveau cas peut être intégré à une catégorie ou un épisode généralisé . en ce qui concerne les informations à sauvegarder , il est évident que l ’ on doit sauvegarder les caractéristiques et la solution du problème . dans certains domaines , on peut tout de même faire l ’ impasse sur les caractéristiques qui sont facilement déductibles ou sans intérêt pour le problème . il est aussi possible d ’ enregistrer les explications du raisonnement ayant mené à la solution . ceci va nous permettre d ’ utiliser l ’ adaptation dérivative comme nous l ’ avons vu précédemment . il est aussi possible de sauvegarder les échecs comme nous l ’ avons vu dans le paragraphe précédent . on peut ajouter à la base les cas d ’ échecs ou les raisonnements incorrects . il s ’ agit ensuite de décider quel type d ’ index le système utilisera pour retrouver ce cas . la plupart des logiciels existants emploient la totalité des caractéristiques . d ’ autres méthodes vont parcourir la base pour trouver les caractéristiques les plus discriminantes avec le cas à ajouter . enfin il faut intégrer le nouveau cas dans la base . au cours de cette phase , on va modifier l ’ indexation des cas existants pour que le système détecte plus facilement les similitudes lors de la recherche des cas similaires . pratiquement on va augmenter le poids d ’ un index menant à un cas qui a permis d ’ atteindre un cas utile dans la construction de la solution . à l ’ inverse , le système va diminuer le poids d ’ un index menant à un cas qui conduit à un échec . en fin de compte , on privilégie certaines caractéristiques . il peut être intéressant à la fin de l ’ apprentissage de tester le système en lui reposant le problème qu ’ il vient de traiter . ainsi on peut voir si le système se comporte comme on l ’ attend . l&apos; utilisation du data mining se révèle avantageuse dans l&apos; indexation des données . l&apos; indexation est un point très important pour le ràpc . c&apos; est grâce à elle que le calcul de similarité est effectué . les index font référence à différents critères et le datamining va permettre d&apos; indiquer les critères les plus discriminants et donc les plus représentatifs pour la construction des index . de plus , le calcul de la distance entre les cas , effectué par la fonction de similarité intervient logiquement entre le nouveau cas et tous les anciens cas de la base . grâce au datamining , des classes vont être constituées pour ainsi directement exclure les cas qui n&apos; ont aucun rapport avec le cas actuel . le calcul des distances grâce à la fonction de similarité s&apos; effectuera ainsi uniquement à l&apos; intérieur d&apos; une même classe , ce qui réduira considérablement le temps d&apos; exécution . le datacleaning permet également d&apos; augmenter les performances d&apos; un système cbr . il va faire en sorte que les données enregistrées dans le ràpc soient justes et qu&apos; il n&apos; y ait pas de cas inexact qui pourrait entraîner des raisonnements totalement faux . néanmoins , il peut arriver qu&apos; un cbr possède dans sa base des cas contradictoires mais il ne doit pas pour autant ne plus être en mesure de tirer des conclusions , des expériences contradictoires existant dans la vie réelle . une meilleure gestion de l ’ imprécision : avec la logique classique , une imprécision peut conduire à ruiner un raisonnement , elle sera en revanche bien tolérée si on utilise la logique floue . la traduction des quantificateurs linguistiques en informations numériques utilisables par le système : si la description de cas est textuelle , il y a de fortes chances pour que des caractéristiques soient qualifiées par des quantificateurs tel que « très » , « un peu » , « environ » , etc. ils seront facilement traduits par une valeur entre 0 et 1 . la gestion des valeurs continues et réelles facilitées : l ’ indexation et la recherche de cas sera plus facile à mettre en œuvre . l ’ introduction des notions de confiance et de pertinence : pour chaque information stockée , ou pour chaque caractéristique du nouveau cas , on va utiliser le degré de confiance qu ’ on a dans l ’ information et la pertinence . par exemple , si les informations proviennent d ’ une source peu fiable , la confiance sera faible . d ’ une autre manière , la pertinence va représenter l ’ importance d ’ une information pour le problème . certains systèmes ràpc utilisent la logique floue dès le stockage des cas . ils gèrent des degrés de pertinence et de confiance pour chaque cas . mais la principale utilisation de la logique floue est faite au niveau de la recherche de cas similaires . là aussi , les systèmes utilisent les degrés de confiance et de pertinence pour calculer les similarités . enfin il est aussi possible d ’ optimiser l ’ adaptation à l ’ aide de cette technique . chef : ce logiciel se propose de réaliser des recettes de cuisine en utilisant la technique du ràpc . l&apos; utilisateur indique au programme les aliments dont il dispose et chef cherche à élaborer une recette à partir de ces ingrédients . pour ce faire , il opère comme tout ràpc : il possède une très grosse base de données de &quot; cas &quot; de recettes valides et cherche à créer , par mimétisme , une nouvelle recette contenant les ingrédients choisis . chef a la particularité de tenir compte des échecs et de les sauvegarder afin d&apos; éviter de les reproduire . lorsque les contraintes imposées par l&apos; utilisateur sont trop fortes et qu&apos; aucune solution n&apos; a été trouvée , chef donne une explication indiquant les raisons de l&apos; échec . persuader : persuader est un outil de gestion de conflits basé sur le raisonnement par cas . il fonctionne sur le principe de négociation / médiation . il est capable de fournir des solutions documentées pour la résolution de problèmes de groupe . persuader fait en sorte de pouvoir construire un règlement mutuellement convenu entre les différents acteurs de la dispute . swale : le projet swale cherche à fournir des explications à des situations anormales . il apporte notamment des explications sur les causes de la mort des animaux ou des hommes . le programme va par exemple comparer la mort inattendue d&apos; un cheval de course très connu en pleine force de l&apos; âge à la mort d&apos; un cycliste due à une consommation excessive de produits dopants . taaable : ce logiciel se propose de réaliser des recettes de cuisine en utilisant la technique du ràpc . il a été vice-champion du ccc 2008 et 2009 . l&apos; algorithme d&apos; induction dynamique a été développé dans le cadre du projet européen inreca .
