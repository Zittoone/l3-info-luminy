où f : \ mathbb { e } \ to \ mathbb { f } est une fonction différentiable entre les deux espaces vectoriels \ mathbb { e } et \ mathbb { f } et n : \ mathbb { e } \ multimap \ mathbb { f } est une multifonction entre les mêmes espaces . ce problème signifie que l&apos; on cherche x \ in \ mathbb { e } tel que l&apos; ensemble f ( x ) + n ( x ) contienne l&apos; élément nul de \ mathbb { f } ou encore tel que l&apos; ensemble n ( x ) contienne -f ( x ) . ce formalisme est suffisamment général pour englober les problèmes variationnels , les problèmes d&apos; inéquations variationnelles , les problèmes de complémentarité non linéaires et les conditions d&apos; optimalité du premier ordre des problèmes d&apos; optimisation . f ( x _ k ) + f &apos; ( x _ k ) ( x-x _ k ) + n ( x ) \ ni0 . on retrouve l&apos; algorithme de newton si n \ equiv \ { 0 \ } . le fait de maintenir n inchangé dans cette inclusion linéarisée , qui calcule le nouvel itéré , permet d&apos; avoir les mêmes résultats de convergence superlinéaire ou quadratique qu&apos; avec la méthode de newton résolvant un système non linéaire , sous des hypothèses de lissité et de régularité similaires . cependant , contrairement à l&apos; algorithme de newton , il ne suffit pas de résoudre un système linéaire à chaque itération pour calculer le nouvel itéré x _ { k + 1 } , car le système ci-dessus permettant de calculer celui-ci est une inclusion non linéaire , qui pourra demander beaucoup de temps de calcul. où m _ k : \ mathbb { e } \ to \ mathbb { f } est un opérateur linéaire valant f &apos; ( x _ k ) ou une approximation de cette dérivée ( on pense ici surtout à des approximations quasi-newtoniennes ) . on ne « linéarise » donc que le premier terme qui est supposé différentiable ; le second est laissé inchangé . sans hypothèse particulière , il se peut que l&apos; inclusion fonctionnelle linéarisée ( jn ) n&apos; ait pas de solution , auquel cas l&apos; algorithme ne peut pas calculer l&apos; itéré suivant x _ { k + 1 } et doit s&apos; arrêter . par ailleurs , si la multifonction n est complexe , l&apos; itération pourra requérir beaucoup de temps de calcul ( elle est toutefois plus simple que le problème initial ) , mais la convergence locale rapide peut laisser espérer qu&apos; une solution sera trouvée en très peu d&apos; itérations . il se peut aussi que l&apos; on ne connaisse pas de méthode pour résoudre ( jn ) , auquel cas il faudra se tourner vers d&apos; autres algorithmes de résolution . ce schéma algorithmique prenant en compte un grand nombre de situations a été introduit par josephy en 1979voir josephy ( 1979a ) pour la version newtonienne et josephy ( 1979b ) pour la version quasi-newtonienne . . examinons à présent quelques cas particuliers . k \ ni x \ perp f ( x ) \ in k ^ + . dans lequel on s&apos; est contenté de linéariser f en x _ k. article détaillé : optimisation quadratique successive . lorsque l&apos; algorithme de josephy-newton est appliqué aux conditions d&apos; optimalité d&apos; un problème d&apos; optimisation avec contraintes d&apos; égalité et d&apos; inégalité , on retrouve l&apos; optimisation quadratique successive . f _ i ( x _ k ) + f &apos; _ i ( x _ k ) ( x-x _ k ) \ leqslant 0 . celui-ci peut ne pas avoir de solution , même lorsque x _ k est proche d&apos; un point x vérifiant les égalités f _ e ( x ) = 0 et les inégalités f _ i ( x ) \ leqslant0 , auquel cas l&apos; algorithme doit s&apos; interrompre . les résultats de cette section sont repris de bonnans ( 1994 ) . la notion de semistabilité permet d&apos; avoir des conditions suffisantes de convergence superlinéaire et quadratique d&apos; une suite générée par l&apos; algorithme de josephy-newton. et quadratique — supposons que f soit c ^ 1 dans le voisinage d&apos; une solution semistable x _ * de ( p _ { if } ) et que la suite \ { x _ k \ } vérifie la récurrence ( jn ) de l&apos; algorithme de josephy-newton et converge vers x _ * . corollaire — supposons que f soit c ^ 1 dans le voisinage d&apos; une solution semistable x _ * de ( p _ { if } ) et que la suite \ { x _ k \ } vérifie la récurrence ( jn ) et converge vers x _ * . la semistabilité n&apos; assure en rien l&apos; existence d&apos; une solution de l&apos; équation linéarisée et donc d&apos; un nouvel itéré de l&apos; algorithme de josephy-newton , même si cet itéré est proche d&apos; une solution . c&apos; est la raison d&apos; être de la propriété d&apos; hémistabilité . en réalité , comme le montre le résultat suivant , c&apos; est à la fois la semistabilité et l&apos; hémistabilité d&apos; une solution de ( p _ { if } ) qui assurent le caractère bien posé de l&apos; algorithme de josephy-newton démarrant proche de cette solution et la convergence de la suite générée vers celle-ci . l&apos; algorithme de josephy-newton peut donc générer une suite convergeant vers x _ * si le premier itéré est assez proche d&apos; une solution semistable et hémistable x _ * , mais rien ne dit qu&apos; il en sera ainsi si la solution de l&apos; inclusion linéarisée n&apos; est pas choisie assez proche de x _ * à chaque itération . ( en ) j.ch. gilbert ( 2015 ) . advanced continuous optimization , planches du cours du m2 optimization à l&apos; université paris-saclay . ( en ) j.f. bonnans ( 1994 ) . local analysis of newton-type methods for variational inequalities and nonlinear programming . applied mathematics and optimization , 29 , 161 – 186 . ( en ) a.f. izmailov , m.v. solodov ( 2014 ) . newton-type methods for optimization and variational problems , springer series in operations research and financial engineering , springer . ( en ) n.h. josephy ( 1979a ) . newton ’ s method for generalized equations . technical summary report 1965 , mathematics research center , university of wisconsin , madison , wi , usa . ( en ) n.h. josephy ( 1979b ) . quasi-newton ’ s method for generalized equations . summary report 1966 , mathematics research center , university of wisconsin , madison , wi , usa .
