vous pouvez partager vos connaissances en l ’ améliorant ( comment ? ) selon les recommandations des projets correspondants . en apprentissage automatique , le terme de classifieur linéaire représente une famille d&apos; algorithmes de classement statistique . le rôle d&apos; un classifieur est de classer dans des groupes ( des classes ) les échantillons qui ont des propriétés similaires , mesurées sur des observations . un classifieur linéaire est un type particulier de classifieur , qui calcule la décision par combinaison linéaire des échantillons . classifieur linéaire est une traduction de l&apos; anglais linear classifier . en français , selon les pays , les communautés et les personnes , ce terme peut être remplacé par discrimination linéaire , ou apprentissage de surface séparatrice linéaire . pour les statisticiens , ces méthodes sont parfois classées en tant que méthodes d&apos; analyse discriminante. où \ vec w est un vecteur de poids , w _ 0 est le biais , et f est une fonction qui convertit le produit scalaire des deux vecteurs dans la sortie désirée . le vecteur de poids w est appris à partir d&apos; un ensemble d&apos; apprentissage étiqueté . la fonction f est souvent une simple fonction de seuillage , par exemple la fonction signe , la fonction de heaviside , ou des fonctions plus complexes comme la tangente hyperbolique , ou la fonction sigmoïde . une fonction de décision plus complexe pourrait donner la probabilité qu&apos; un certain échantillon appartienne à une certaine classe . pour un problème de discrimination à deux classes , l&apos; opération réalisée par un classifieur linéaire peut se voir comme la séparation d&apos; un espace de grande dimension par un hyperplan : tous les points d&apos; un côté de l&apos; hyperplan sont classés en tant que 1 , les autres sont classés en tant que -1 . cet hyperplan est appelé hyperplan séparateur , ou séparatrice . les classifieurs linéaires sont souvent employés dans les situations où une faible complexité est souhaitée , car ce sont les classifieurs les plus simples et donc les plus rapides , surtout lorsque le vecteur d&apos; observation x est creux . toutefois , les méthodes d&apos; arbre de décision peuvent s&apos; avérer plus rapides encore . les classifieurs linéaires obtiennent souvent de bons résultats lorsque n , le nombre de dimension de l&apos; espace des observations , est grand comme dans la fouille de textes , où chaque élément de x est le nombre de mots dans un document . il existe deux grandes familles de méthode pour estimer les paramètres du vecteur \ vec w d&apos; un classifieur linéairet . mitchell , generative and discriminative classifiers : naive bayes and logistic regression . draft version , 2005 download , a. y. ng and m. i. jordan . on discriminative vs. generative classifiers : a comparison of logistic regression and naive bayes. in nips 14 , 2002. download . analyse discriminante linéaire ( ou discriminant linéaire de fisher ) ( lda ) . elle implique l&apos; existence d&apos; un modèle discriminant basé sur une distribution de probabilité de type gaussienne . régression logistique un estimateur de maximum de vraisemblance est évalué d&apos; après \ vec w , en considérant que le jeu d&apos; entrainement a été généré par un modèle binomial . perceptron un algorithme qui cherche à corriger toutes les erreurs rencontrées dans le jeu d&apos; entrainement ( et ainsi améliorer l&apos; apprentissage et le modèle créé d&apos; après ce jeu d&apos; entrainement ) . machine à vecteurs de support un algorithme qui maximise la marge des hyperplans séparateurs du classifieur en utilisant le jeu d&apos; entrainement pour son apprentissage . on considère généralement que les modèles entrainés par une méthode discriminante ( svm , régression logistique ) sont plus précis que ceux de type génératifs entrainés avec des probabilités conditionnelles ( classifieur bayesiens naïfs ou linéaires ) . on considère que les classifieurs génératifs sont plus adaptés pour les processus de classification avec nombreuses données manquantes ( par exemple la classification de texte avec peu de données d&apos; apprentissage ) &#91; réf. nécessaire &#93; catégorie : article à référence nécessaire . tous les classifieurs linéaires cités peuvent opérer sur des données non linéairement séparables en opérant sur un espace de représentation transformé avec l&apos; astuce du noyau . cette technique consiste à appliquer une transformation aux données d&apos; entrées pour trouver dans un nouvel espace de grande dimension dans lequel elles sont projetées , un hyperplan séparateur optimal .
