en optimisation mathématique , la pénalisation est une technique permettant d&apos; analyser et de résoudre analytiquement ou numériquement des problèmes d&apos; optimisation avec contraintes . elle consiste à transformer le problème avec contraintes en un problème ( cas de la pénalisation exacte ) ou des problèmes ( cas de la pénalisation inexacte ) d&apos; optimisation sans contrainte ; le sens précis de cette phrase apparaîtra plus loin . c&apos; est un outil à la fois théorique et algorithmique . en théorie , on peut l&apos; utiliser pour démontrer l&apos; existence de solution des problèmes d&apos; optimisation avec contraintes , en étudier les propriétés , établir des conditions d&apos; optimalité , etc. en algorithmique , cette approche permet de résoudre des problèmes avec contraintes en n&apos; utilisant que des méthodes de l&apos; optimisation sans contrainte ; cependant , à moins que l&apos; on ne spécifie l&apos; algorithme de manière raffinée ( comme dans les algorithmes de points intérieurs en optimisation linéaire , quadratique et semi-définie positive — qui peuvent être interprétés comme des algorithmes de pénalisation ) , c&apos; est un peu la « méthode du pauvre » , permettant d&apos; obtenir des résultats peu précis mais avec peu d&apos; effort. f _ r ( x ) = f ( x ) + r \ , p ( x ) . est une fonction à spécifier , appelée fonction de pénalisation . à ce niveau de généralité , rien ne permet de dire que les problèmes ( p _ x ) et ( p _ r ) ont un lien entre eux ; cela dépend de la fonction de pénalisation et du facteur de pénalisation . de manière à rendre l&apos; approche plus concrète , donnons quelques exemples . + \ infty &amp; \ mbox { si } &amp; x \ notin x. \ end { array } \ right . dans cette pénalisation , le facteur r &gt; 0 ne joue aucun rôle ( il multiplie zéro ou l&apos; infini ) . par ailleurs , les problèmes ( p _ x ) et ( p _ r ) sont alors équivalents , dans le sens où ils ont les mêmes solutions et les mêmes valeurs optimales . on l&apos; utilise souvent dans certains développements théoriques pour prendre en compte simultanément les problèmes avec ( x \ ne \ mathbb { e } ) et sans ( x = \ mathbb { e } ) contraintes . numériquement , cette pénalisation n&apos; est guère utile , car si l&apos; itéré courant est en dehors de l&apos; adhérence de l&apos; ensemble admissible , l&apos; examen de f _ r dans le voisinage de cet itéré ( f _ r y est égale à + \ infty ) n&apos; apportera pas d&apos; information sur la direction à prendre pour trouver un point admissible. p _ 1 ( x ) : = - \ sum _ { i = 1 } ^ n \ log x _ i. cette pénalisation a été introduite par l&apos; économiste ragnar frisch en 1955template : en r. frisch ( 1955 , mai ) . the logarithmic potential method for convex programming with particular application to the dynamics of planning for national development . memorandum , institut d ’ économie , université d ’ oslo , oslo , norvège . . il s&apos; agit d&apos; une pénalisation inexacte intérieure . elle peut se généraliser , dans un sens bien précis ( et compliqué ) , à des ensembles convexes ( presque ) arbitraires , via la notion de fonction autoconcordante . la fonction p _ 3 est mieux adaptée à un espace de hilbert \ mathbb { f } ; elle porte le nom de pénalisation quadratique . ces deux fonctions de pénalisation conduisent à des propriétés très différentes : la première donne lieu à une pénalisation exacte , la seconde à une pénalisation inexacte extérieure . x : = \ { x \ in \ mathbb { e } : c ( x ) \ in g \ } . où \ operatorname { dist } ( y , g ) est la distance de y \ in \ mathbb { f } à l&apos; ensemble g. ici aussi , la pénalisation p _ 6 donne lieu à une pénalisation exacte , tandis que p _ 7 correspond à une pénalisation inexacte extérieure . la notion de pénalisation exacte est très utile , bien qu&apos; elle ne soit pas très précise ; plutôt , elle requiert des précisions supplémentaires dans les résultats qui la mentionne . le concept est attaché au lien que l&apos; on désire établir entre les problèmes ( p _ x ) et ( p _ r ) définis ci-dessus . une définition pourrait être la suivante . pénalisation exacte — on dit que la pénalisation réalisée dans ( p _ r ) est exacte si les solutions de ( p _ x ) sont solutions de ( p _ r ) . on dit que la pénalisation est inexacte dans le cas contraire . cette définition ne dit pas ce que l&apos; on entend par solution : est-ce un minimum global , local , un point-stationnaire ? aussi , faut-il que cette correspondance ait lieu entre toutes les solutions de ( p _ x ) et de ( p _ r ) ou pour une seule d&apos; entre elles ? les résultats qui affirment qu&apos; une pénalisation est exacte précisent les réponses à ces questions . ils précisent aussi les valeurs que doit prendre le facteur de pénalisation r pour que la propriété d&apos; exactitude soit vraie . il arrive aussi que les solutions de ( p _ r ) soient solutions de ( p _ x ) , mais cette propriété est plus rare , à moins que l&apos; on ne sélectionne parmi les solutions de ( p _ r ) , celles qui sont admissibles pour ( p _ x ) , c&apos; est-à-dire qui sont dans l&apos; ensemble admissible x. lorsque la pénalisation est exacte , le lien entre les problèmes d&apos; optimisation ( p _ x ) et ( p _ r ) est clair : ces problèmes ont des solutions en commun . dès lors , si l&apos; on veut résoudre le problème avec contrainte ( p _ x ) , il suffit parfois de résoudre le problème sans contrainte ( p _ r ) . cette propriété remarquable est contrebalancée par le fait qu&apos; une fonction de pénalisation exacte est souvent non-différentiable ( c&apos; est le cas des fonctions de pénalisation p _ 2 , p _ 4 et p _ 6 données en exemples ci-dessus ) ou contient des paramètres qui ne sont pas facilement calculables ( comme un multiplicateur optimal dans le lagrangien augmenté ) . lorsque le paramètre de pénalisation est proche de sa valeur limite , le problème ( p _ r ) est en général mal conditionné , si bien qu&apos; il est numériquement difficile d&apos; obtenir de la précision sur les minimiseurs de ( p _ r ) , à moins que le point de départ du processus de minimisation soit déjà proche d&apos; un tel minimiseur ; il est donc judicieux de se rapprocher d&apos; une solution de ( p _ x ) sans trop s&apos; écarter du chemin défini par les minimiseurs des problèmes ( p _ r ) ( méthode de suivi de chemin ) . une pénalisation inexacte peut être extérieure ou intérieure . dans une pénalisation extérieure , la fonction de pénalisation p est nulle sur , et uniquement sur , l&apos; ensemble admissible x. à l&apos; extérieur de cet ensemble , p prend des valeurs strictement positives . comme on cherche à minimiser f _ r : = f + r \ , p , cette pénalisation force le minimiseur à se rapprocher de l&apos; ensemble admissible , d&apos; autant plus que le facteur de pénalisation r est grand . dans cette approche , la fonction p pénalise donc la violation des contraintes , d&apos; autant plus que son argument est éloigné de l&apos; ensemble admissible x ; lorsque cet ensemble est défini par des contraintes fonctionnelles , cet éloignement est mesuré par la valeur de ces contraintes fonctionnelles . dans cette technique de pénalisation , les minimiseurs de f _ r sont en général extérieurs à l&apos; ensemble admissible x et on fait tendre r vers + \ infty pour trouver une solution de ( p _ x ) à partir de celles de ( p _ r ) . les fonctions p _ 3 , p _ 5 et p _ 7 données en exemples ci-dessus sont des fonctions de pénalisation extérieure . dans une pénalisation intérieure , ... j. ch . gilbert , éléments d&apos; optimisation différentiable — théorie et algorithmes , syllabus de cours à l&apos; ensta paristech , paris . ( en ) d. p. bertsekas ( 1995 ) , nonlinear programming . athena scientific . ( isbn 978-1-886529-14-4 ) . ( en ) j. f. bonnans , j. ch . gilbert , c. lemaréchal , c. sagastizábal ( 2006 ) , numerical optimization - theoretical and numerical aspects &#91; détail des éditions &#93; . ( en ) j. nocedal , s. j. wright ( 2006 ) , numerical optimization , springer . ( isbn 978-0-387-30303-1 ) .
